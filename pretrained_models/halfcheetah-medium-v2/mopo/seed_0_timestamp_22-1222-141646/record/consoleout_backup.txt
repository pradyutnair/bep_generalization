num rollout transitions: 250000, reward mean: 3.5513
----------------------------------------------------------------------------------
| alpha                              | 0.951    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.25     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -24.4    |
| loss/alpha                         | -0.502   |
| loss/critic1                       | 3.12     |
| loss/critic2                       | 3.08     |
| timestep                           | 1000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.6626
----------------------------------------------------------------------------------
| alpha                              | 0.861    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.25     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -50      |
| loss/alpha                         | -1.49    |
| loss/critic1                       | 4.66     |
| loss/critic2                       | 4.67     |
| timestep                           | 2000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.7453
----------------------------------------------------------------------------------
| alpha                              | 0.779    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.24     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -71.1    |
| loss/alpha                         | -2.43    |
| loss/critic1                       | 8.36     |
| loss/critic2                       | 8.36     |
| timestep                           | 3000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.7851
----------------------------------------------------------------------------------
| alpha                              | 0.707    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.24     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -87.9    |
| loss/alpha                         | -3.25    |
| loss/critic1                       | 11.7     |
| loss/critic2                       | 11.7     |
| timestep                           | 4000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.8557
----------------------------------------------------------------------------------
| alpha                              | 0.642    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.21     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -102     |
| loss/alpha                         | -3.87    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 5000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.8730
----------------------------------------------------------------------------------
| alpha                              | 0.585    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 5.05     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -114     |
| loss/alpha                         | -4.21    |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 6000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9037
----------------------------------------------------------------------------------
| alpha                              | 0.535    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.99     |
| eval/normalized_episode_reward_std | 4.12     |
| loss/actor                         | -126     |
| loss/alpha                         | -4.36    |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.7     |
| timestep                           | 7000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.8837
----------------------------------------------------------------------------------
| alpha                              | 0.489    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 0.195    |
| eval/normalized_episode_reward_std | 5.02     |
| loss/actor                         | -136     |
| loss/alpha                         | -4.45    |
| loss/critic1                       | 24.9     |
| loss/critic2                       | 24.9     |
| timestep                           | 8000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.8931
----------------------------------------------------------------------------------
| alpha                              | 0.448    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -0.968   |
| eval/normalized_episode_reward_std | 4.53     |
| loss/actor                         | -145     |
| loss/alpha                         | -4.48    |
| loss/critic1                       | 30.1     |
| loss/critic2                       | 30.1     |
| timestep                           | 9000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9084
----------------------------------------------------------------------------------
| alpha                              | 0.41     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -3.96    |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -153     |
| loss/alpha                         | -4.52    |
| loss/critic1                       | 36.7     |
| loss/critic2                       | 36.6     |
| timestep                           | 10000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9323
----------------------------------------------------------------------------------
| alpha                              | 0.375    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 3.39     |
| eval/normalized_episode_reward_std | 7.53     |
| loss/actor                         | -160     |
| loss/alpha                         | -4.54    |
| loss/critic1                       | 42.2     |
| loss/critic2                       | 41.8     |
| timestep                           | 11000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9509
----------------------------------------------------------------------------------
| alpha                              | 0.343    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -2.21    |
| eval/normalized_episode_reward_std | 5.27     |
| loss/actor                         | -165     |
| loss/alpha                         | -4.42    |
| loss/critic1                       | 46.8     |
| loss/critic2                       | 46.5     |
| timestep                           | 12000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9615
----------------------------------------------------------------------------------
| alpha                              | 0.313    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 3.42     |
| eval/normalized_episode_reward_std | 6.19     |
| loss/actor                         | -168     |
| loss/alpha                         | -4.33    |
| loss/critic1                       | 50.1     |
| loss/critic2                       | 49.6     |
| timestep                           | 13000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0154
----------------------------------------------------------------------------------
| alpha                              | 0.287    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 5.04     |
| eval/normalized_episode_reward_std | 6.77     |
| loss/actor                         | -172     |
| loss/alpha                         | -3.89    |
| loss/critic1                       | 52.6     |
| loss/critic2                       | 52.2     |
| timestep                           | 14000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9590
----------------------------------------------------------------------------------
| alpha                              | 0.265    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 4.9      |
| eval/normalized_episode_reward_std | 8.36     |
| loss/actor                         | -175     |
| loss/alpha                         | -3.21    |
| loss/critic1                       | 53       |
| loss/critic2                       | 52.4     |
| timestep                           | 15000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9887
----------------------------------------------------------------------------------
| alpha                              | 0.246    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.97     |
| eval/normalized_episode_reward_std | 5.26     |
| loss/actor                         | -178     |
| loss/alpha                         | -2.41    |
| loss/critic1                       | 55.1     |
| loss/critic2                       | 54.4     |
| timestep                           | 16000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9831
----------------------------------------------------------------------------------
| alpha                              | 0.232    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 3.11     |
| eval/normalized_episode_reward_std | 5.81     |
| loss/actor                         | -180     |
| loss/alpha                         | -1.42    |
| loss/critic1                       | 67.8     |
| loss/critic2                       | 66.8     |
| timestep                           | 17000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9788
----------------------------------------------------------------------------------
| alpha                              | 0.221    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 6.27     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -183     |
| loss/alpha                         | -0.769   |
| loss/critic1                       | 75.2     |
| loss/critic2                       | 74       |
| timestep                           | 18000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9993
----------------------------------------------------------------------------------
| alpha                              | 0.214    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 4.28     |
| eval/normalized_episode_reward_std | 7.76     |
| loss/actor                         | -186     |
| loss/alpha                         | -0.278   |
| loss/critic1                       | 76.9     |
| loss/critic2                       | 75.4     |
| timestep                           | 19000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9851
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 8.48     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -188     |
| loss/alpha                         | 0.0231   |
| loss/critic1                       | 81.3     |
| loss/critic2                       | 80.1     |
| timestep                           | 20000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0008
----------------------------------------------------------------------------------
| alpha                              | 0.215    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 13.2     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -190     |
| loss/alpha                         | 0.0391   |
| loss/critic1                       | 89.1     |
| loss/critic2                       | 87.8     |
| timestep                           | 21000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0393
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 3.89     |
| eval/normalized_episode_reward_std | 6.96     |
| loss/actor                         | -192     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 71.6     |
| loss/critic2                       | 71.4     |
| timestep                           | 22000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0318
----------------------------------------------------------------------------------
| alpha                              | 0.224    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 13.1     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -193     |
| loss/alpha                         | 0.199    |
| loss/critic1                       | 72.3     |
| loss/critic2                       | 71.4     |
| timestep                           | 23000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0503
----------------------------------------------------------------------------------
| alpha                              | 0.229    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 15.9     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -193     |
| loss/alpha                         | -0.0177  |
| loss/critic1                       | 81       |
| loss/critic2                       | 80.4     |
| timestep                           | 24000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0647
----------------------------------------------------------------------------------
| alpha                              | 0.229    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 35.1     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -195     |
| loss/alpha                         | 0.0455   |
| loss/critic1                       | 80       |
| loss/critic2                       | 79.4     |
| timestep                           | 25000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0777
----------------------------------------------------------------------------------
| alpha                              | 0.232    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 19.2     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -198     |
| loss/alpha                         | 0.0727   |
| loss/critic1                       | 78       |
| loss/critic2                       | 78       |
| timestep                           | 26000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0678
----------------------------------------------------------------------------------
| alpha                              | 0.233    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 12.8     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -201     |
| loss/alpha                         | -0.00815 |
| loss/critic1                       | 83.2     |
| loss/critic2                       | 83       |
| timestep                           | 27000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0712
----------------------------------------------------------------------------------
| alpha                              | 0.232    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 12.3     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -204     |
| loss/alpha                         | -0.0428  |
| loss/critic1                       | 77.7     |
| loss/critic2                       | 77.7     |
| timestep                           | 28000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0434
----------------------------------------------------------------------------------
| alpha                              | 0.228    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 14.5     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -207     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 70.1     |
| loss/critic2                       | 70.2     |
| timestep                           | 29000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1021
----------------------------------------------------------------------------------
| alpha                              | 0.227    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 12.5     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -211     |
| loss/alpha                         | 0.104    |
| loss/critic1                       | 73.7     |
| loss/critic2                       | 73.5     |
| timestep                           | 30000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1350
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 25       |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -214     |
| loss/alpha                         | 0.167    |
| loss/critic1                       | 85.2     |
| loss/critic2                       | 84.9     |
| timestep                           | 31000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1255
----------------------------------------------------------------------------------
| alpha                              | 0.24     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 23.7     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -217     |
| loss/alpha                         | 0.033    |
| loss/critic1                       | 81.5     |
| loss/critic2                       | 80.8     |
| timestep                           | 32000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1391
----------------------------------------------------------------------------------
| alpha                              | 0.247    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 33.4     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -220     |
| loss/alpha                         | 0.238    |
| loss/critic1                       | 82.4     |
| loss/critic2                       | 81.6     |
| timestep                           | 33000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1334
----------------------------------------------------------------------------------
| alpha                              | 0.26     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 27.1     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -224     |
| loss/alpha                         | 0.201    |
| loss/critic1                       | 85.5     |
| loss/critic2                       | 84.3     |
| timestep                           | 34000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1099
----------------------------------------------------------------------------------
| alpha                              | 0.27     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 37.1     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -226     |
| loss/alpha                         | 0.0987   |
| loss/critic1                       | 83.8     |
| loss/critic2                       | 83       |
| timestep                           | 35000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1266
----------------------------------------------------------------------------------
| alpha                              | 0.273    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 28.1     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -229     |
| loss/alpha                         | 0.0666   |
| loss/critic1                       | 72.6     |
| loss/critic2                       | 72.5     |
| timestep                           | 36000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1476
----------------------------------------------------------------------------------
| alpha                              | 0.282    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 11.3     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -232     |
| loss/alpha                         | 0.122    |
| loss/critic1                       | 71.9     |
| loss/critic2                       | 72       |
| timestep                           | 37000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1370
----------------------------------------------------------------------------------
| alpha                              | 0.288    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 23.8     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -234     |
| loss/alpha                         | 0.0553   |
| loss/critic1                       | 90.4     |
| loss/critic2                       | 90.2     |
| timestep                           | 38000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1227
----------------------------------------------------------------------------------
| alpha                              | 0.295    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 18.6     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -236     |
| loss/alpha                         | 0.0915   |
| loss/critic1                       | 89.7     |
| loss/critic2                       | 89.1     |
| timestep                           | 39000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1483
----------------------------------------------------------------------------------
| alpha                              | 0.3      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 25.1     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -239     |
| loss/alpha                         | 0.0215   |
| loss/critic1                       | 86.3     |
| loss/critic2                       | 86       |
| timestep                           | 40000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1308
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.3     |
| eval/normalized_episode_reward_std | 5.43     |
| loss/actor                         | -242     |
| loss/alpha                         | -0.0167  |
| loss/critic1                       | 84.9     |
| loss/critic2                       | 84.3     |
| timestep                           | 41000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1539
----------------------------------------------------------------------------------
| alpha                              | 0.301    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 28.7     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -244     |
| loss/alpha                         | 0.0762   |
| loss/critic1                       | 89.2     |
| loss/critic2                       | 88.5     |
| timestep                           | 42000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1368
----------------------------------------------------------------------------------
| alpha                              | 0.302    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 26.6     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -248     |
| loss/alpha                         | -0.0282  |
| loss/critic1                       | 63.1     |
| loss/critic2                       | 62.5     |
| timestep                           | 43000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1582
----------------------------------------------------------------------------------
| alpha                              | 0.305    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 42.3     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -251     |
| loss/alpha                         | 0.0502   |
| loss/critic1                       | 65.2     |
| loss/critic2                       | 65.1     |
| timestep                           | 44000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1627
----------------------------------------------------------------------------------
| alpha                              | 0.309    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 17.3     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -254     |
| loss/alpha                         | 0.0689   |
| loss/critic1                       | 66.9     |
| loss/critic2                       | 66.8     |
| timestep                           | 45000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1616
----------------------------------------------------------------------------------
| alpha                              | 0.316    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 29.7     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -256     |
| loss/alpha                         | 0.0385   |
| loss/critic1                       | 73.3     |
| loss/critic2                       | 72.6     |
| timestep                           | 46000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1632
----------------------------------------------------------------------------------
| alpha                              | 0.317    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 30.5     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -259     |
| loss/alpha                         | 0.0177   |
| loss/critic1                       | 71.8     |
| loss/critic2                       | 71.8     |
| timestep                           | 47000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1677
----------------------------------------------------------------------------------
| alpha                              | 0.318    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.8     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -262     |
| loss/alpha                         | 0.00204  |
| loss/critic1                       | 77.4     |
| loss/critic2                       | 76.9     |
| timestep                           | 48000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1822
----------------------------------------------------------------------------------
| alpha                              | 0.319    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 33.5     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -264     |
| loss/alpha                         | 0.0217   |
| loss/critic1                       | 72.8     |
| loss/critic2                       | 72.7     |
| timestep                           | 49000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1860
----------------------------------------------------------------------------------
| alpha                              | 0.319    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.3     |
| eval/normalized_episode_reward_std | 6.19     |
| loss/actor                         | -267     |
| loss/alpha                         | -0.0129  |
| loss/critic1                       | 70.7     |
| loss/critic2                       | 70.3     |
| timestep                           | 50000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1989
-----------------------------------------------------------------------------------
| alpha                              | 0.319     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 35.7      |
| eval/normalized_episode_reward_std | 24.3      |
| loss/actor                         | -270      |
| loss/alpha                         | -0.000843 |
| loss/critic1                       | 69.2      |
| loss/critic2                       | 68.8      |
| timestep                           | 51000     |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1992
----------------------------------------------------------------------------------
| alpha                              | 0.321    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 24       |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -272     |
| loss/alpha                         | 0.0575   |
| loss/critic1                       | 68.4     |
| loss/critic2                       | 68.5     |
| timestep                           | 52000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1734
----------------------------------------------------------------------------------
| alpha                              | 0.324    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 30.9     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -274     |
| loss/alpha                         | -0.00622 |
| loss/critic1                       | 70.7     |
| loss/critic2                       | 70.6     |
| timestep                           | 53000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1777
----------------------------------------------------------------------------------
| alpha                              | 0.323    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 37.2     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -277     |
| loss/alpha                         | 0.00102  |
| loss/critic1                       | 68.5     |
| loss/critic2                       | 68.1     |
| timestep                           | 54000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1772
----------------------------------------------------------------------------------
| alpha                              | 0.324    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 35.6     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -280     |
| loss/alpha                         | 0.0258   |
| loss/critic1                       | 67.8     |
| loss/critic2                       | 67.3     |
| timestep                           | 55000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1862
----------------------------------------------------------------------------------
| alpha                              | 0.322    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 29.7     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -282     |
| loss/alpha                         | -0.0659  |
| loss/critic1                       | 64.9     |
| loss/critic2                       | 64.6     |
| timestep                           | 56000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1950
----------------------------------------------------------------------------------
| alpha                              | 0.325    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 31       |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -284     |
| loss/alpha                         | 0.0612   |
| loss/critic1                       | 63.7     |
| loss/critic2                       | 63.5     |
| timestep                           | 57000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1997
----------------------------------------------------------------------------------
| alpha                              | 0.325    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 40.4     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -287     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 65.5     |
| loss/critic2                       | 65       |
| timestep                           | 58000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1970
----------------------------------------------------------------------------------
| alpha                              | 0.325    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 31.1     |
| eval/normalized_episode_reward_std | 24       |
| loss/actor                         | -289     |
| loss/alpha                         | 0.00196  |
| loss/critic1                       | 60       |
| loss/critic2                       | 59.5     |
| timestep                           | 59000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1959
----------------------------------------------------------------------------------
| alpha                              | 0.323    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.2     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -292     |
| loss/alpha                         | -0.0199  |
| loss/critic1                       | 60.3     |
| loss/critic2                       | 60.1     |
| timestep                           | 60000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1973
----------------------------------------------------------------------------------
| alpha                              | 0.322    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 39.4     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -294     |
| loss/alpha                         | -0.022   |
| loss/critic1                       | 58.2     |
| loss/critic2                       | 58       |
| timestep                           | 61000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1896
----------------------------------------------------------------------------------
| alpha                              | 0.321    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 30.5     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -297     |
| loss/alpha                         | 0.0091   |
| loss/critic1                       | 58.1     |
| loss/critic2                       | 57.6     |
| timestep                           | 62000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2002
----------------------------------------------------------------------------------
| alpha                              | 0.321    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 35.3     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -300     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 53.8     |
| loss/critic2                       | 53.6     |
| timestep                           | 63000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2070
----------------------------------------------------------------------------------
| alpha                              | 0.321    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.3     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -302     |
| loss/alpha                         | 0.00235  |
| loss/critic1                       | 54.9     |
| loss/critic2                       | 54.7     |
| timestep                           | 64000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2280
----------------------------------------------------------------------------------
| alpha                              | 0.323    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 38.9     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -305     |
| loss/alpha                         | 0.044    |
| loss/critic1                       | 55.3     |
| loss/critic2                       | 55.1     |
| timestep                           | 65000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2172
----------------------------------------------------------------------------------
| alpha                              | 0.325    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 32.5     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -307     |
| loss/alpha                         | -0.0252  |
| loss/critic1                       | 55.6     |
| loss/critic2                       | 55.3     |
| timestep                           | 66000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2117
----------------------------------------------------------------------------------
| alpha                              | 0.319    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 30.2     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -310     |
| loss/alpha                         | -0.0507  |
| loss/critic1                       | 58.7     |
| loss/critic2                       | 58.4     |
| timestep                           | 67000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2142
----------------------------------------------------------------------------------
| alpha                              | 0.318    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.1     |
| eval/normalized_episode_reward_std | 6.52     |
| loss/actor                         | -312     |
| loss/alpha                         | 0.0269   |
| loss/critic1                       | 57.5     |
| loss/critic2                       | 57.3     |
| timestep                           | 68000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2124
----------------------------------------------------------------------------------
| alpha                              | 0.32     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 39.5     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -315     |
| loss/alpha                         | -0.00283 |
| loss/critic1                       | 59.2     |
| loss/critic2                       | 59       |
| timestep                           | 69000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1915
----------------------------------------------------------------------------------
| alpha                              | 0.318    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.5     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -317     |
| loss/alpha                         | -0.0315  |
| loss/critic1                       | 54.9     |
| loss/critic2                       | 54.2     |
| timestep                           | 70000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2507
----------------------------------------------------------------------------------
| alpha                              | 0.317    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.1     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -320     |
| loss/alpha                         | -0.00885 |
| loss/critic1                       | 54.8     |
| loss/critic2                       | 54.6     |
| timestep                           | 71000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2184
----------------------------------------------------------------------------------
| alpha                              | 0.315    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 19.2     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -323     |
| loss/alpha                         | -0.0164  |
| loss/critic1                       | 52       |
| loss/critic2                       | 52.3     |
| timestep                           | 72000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2221
----------------------------------------------------------------------------------
| alpha                              | 0.314    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50       |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -325     |
| loss/alpha                         | -0.0219  |
| loss/critic1                       | 54.7     |
| loss/critic2                       | 54.6     |
| timestep                           | 73000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2244
----------------------------------------------------------------------------------
| alpha                              | 0.315    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.6     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -328     |
| loss/alpha                         | 0.0298   |
| loss/critic1                       | 53.6     |
| loss/critic2                       | 53.9     |
| timestep                           | 74000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1999
----------------------------------------------------------------------------------
| alpha                              | 0.314    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 38.1     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -331     |
| loss/alpha                         | -0.0171  |
| loss/critic1                       | 53.9     |
| loss/critic2                       | 53.7     |
| timestep                           | 75000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2334
----------------------------------------------------------------------------------
| alpha                              | 0.314    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 35.9     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -333     |
| loss/alpha                         | 0.00412  |
| loss/critic1                       | 49.4     |
| loss/critic2                       | 49       |
| timestep                           | 76000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2278
----------------------------------------------------------------------------------
| alpha                              | 0.314    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.1     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -335     |
| loss/alpha                         | -0.0204  |
| loss/critic1                       | 51.9     |
| loss/critic2                       | 51.9     |
| timestep                           | 77000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2118
----------------------------------------------------------------------------------
| alpha                              | 0.308    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 30.1     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -338     |
| loss/alpha                         | -0.0678  |
| loss/critic1                       | 44.7     |
| loss/critic2                       | 44.7     |
| timestep                           | 78000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2145
----------------------------------------------------------------------------------
| alpha                              | 0.308    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.3     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -341     |
| loss/alpha                         | 0.0232   |
| loss/critic1                       | 47.4     |
| loss/critic2                       | 47.1     |
| timestep                           | 79000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2287
----------------------------------------------------------------------------------
| alpha                              | 0.308    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.5     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -344     |
| loss/alpha                         | -0.00561 |
| loss/critic1                       | 45.7     |
| loss/critic2                       | 45.4     |
| timestep                           | 80000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2285
----------------------------------------------------------------------------------
| alpha                              | 0.308    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.8     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -346     |
| loss/alpha                         | -0.00962 |
| loss/critic1                       | 50.5     |
| loss/critic2                       | 50       |
| timestep                           | 81000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2356
----------------------------------------------------------------------------------
| alpha                              | 0.304    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 31.7     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -349     |
| loss/alpha                         | -0.0302  |
| loss/critic1                       | 50.9     |
| loss/critic2                       | 51       |
| timestep                           | 82000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2372
----------------------------------------------------------------------------------
| alpha                              | 0.303    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.3     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -352     |
| loss/alpha                         | -0.0142  |
| loss/critic1                       | 49.1     |
| loss/critic2                       | 48.3     |
| timestep                           | 83000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2524
----------------------------------------------------------------------------------
| alpha                              | 0.304    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.1     |
| eval/normalized_episode_reward_std | 9.83     |
| loss/actor                         | -355     |
| loss/alpha                         | -0.0097  |
| loss/critic1                       | 49.4     |
| loss/critic2                       | 49.2     |
| timestep                           | 84000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2330
----------------------------------------------------------------------------------
| alpha                              | 0.303    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57       |
| eval/normalized_episode_reward_std | 6.98     |
| loss/actor                         | -358     |
| loss/alpha                         | -0.00273 |
| loss/critic1                       | 47       |
| loss/critic2                       | 47.2     |
| timestep                           | 85000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2309
----------------------------------------------------------------------------------
| alpha                              | 0.303    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47.9     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -360     |
| loss/alpha                         | -0.0156  |
| loss/critic1                       | 45.3     |
| loss/critic2                       | 45.1     |
| timestep                           | 86000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2483
----------------------------------------------------------------------------------
| alpha                              | 0.302    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.6     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -362     |
| loss/alpha                         | 0.0225   |
| loss/critic1                       | 45.3     |
| loss/critic2                       | 45.3     |
| timestep                           | 87000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2305
----------------------------------------------------------------------------------
| alpha                              | 0.303    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.2     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -365     |
| loss/alpha                         | 0.0275   |
| loss/critic1                       | 47.4     |
| loss/critic2                       | 47.7     |
| timestep                           | 88000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2216
----------------------------------------------------------------------------------
| alpha                              | 0.302    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.3     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -367     |
| loss/alpha                         | -0.072   |
| loss/critic1                       | 44.6     |
| loss/critic2                       | 44.7     |
| timestep                           | 89000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2252
----------------------------------------------------------------------------------
| alpha                              | 0.299    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43       |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -369     |
| loss/alpha                         | -0.0107  |
| loss/critic1                       | 44       |
| loss/critic2                       | 44.1     |
| timestep                           | 90000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2374
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.6     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -371     |
| loss/alpha                         | 0.0104   |
| loss/critic1                       | 44.5     |
| loss/critic2                       | 44.5     |
| timestep                           | 91000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2339
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.3     |
| eval/normalized_episode_reward_std | 10.2     |
| loss/actor                         | -373     |
| loss/alpha                         | -0.00876 |
| loss/critic1                       | 44.6     |
| loss/critic2                       | 44.6     |
| timestep                           | 92000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2344
----------------------------------------------------------------------------------
| alpha                              | 0.297    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.3     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -375     |
| loss/alpha                         | -0.0119  |
| loss/critic1                       | 41.2     |
| loss/critic2                       | 41.4     |
| timestep                           | 93000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2354
----------------------------------------------------------------------------------
| alpha                              | 0.296    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.5     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -378     |
| loss/alpha                         | -0.051   |
| loss/critic1                       | 43.6     |
| loss/critic2                       | 43.9     |
| timestep                           | 94000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2698
----------------------------------------------------------------------------------
| alpha                              | 0.294    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 40.9     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -381     |
| loss/alpha                         | 0.0422   |
| loss/critic1                       | 42.5     |
| loss/critic2                       | 42.6     |
| timestep                           | 95000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2469
----------------------------------------------------------------------------------
| alpha                              | 0.296    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.4     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -383     |
| loss/alpha                         | -0.0267  |
| loss/critic1                       | 42.9     |
| loss/critic2                       | 43.1     |
| timestep                           | 96000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2506
----------------------------------------------------------------------------------
| alpha                              | 0.293    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 28.4     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -385     |
| loss/alpha                         | -0.0341  |
| loss/critic1                       | 41.3     |
| loss/critic2                       | 41.2     |
| timestep                           | 97000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2519
----------------------------------------------------------------------------------
| alpha                              | 0.291    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.5     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -388     |
| loss/alpha                         | -0.0431  |
| loss/critic1                       | 41       |
| loss/critic2                       | 40.8     |
| timestep                           | 98000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2427
----------------------------------------------------------------------------------
| alpha                              | 0.288    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.7     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -390     |
| loss/alpha                         | -0.0174  |
| loss/critic1                       | 44.3     |
| loss/critic2                       | 44.1     |
| timestep                           | 99000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2476
----------------------------------------------------------------------------------
| alpha                              | 0.284    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 39.8     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -392     |
| loss/alpha                         | -0.0653  |
| loss/critic1                       | 42       |
| loss/critic2                       | 41.7     |
| timestep                           | 100000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2320
----------------------------------------------------------------------------------
| alpha                              | 0.28     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.6     |
| eval/normalized_episode_reward_std | 6.84     |
| loss/actor                         | -395     |
| loss/alpha                         | -0.0262  |
| loss/critic1                       | 41.4     |
| loss/critic2                       | 41.3     |
| timestep                           | 101000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2386
----------------------------------------------------------------------------------
| alpha                              | 0.28     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.6     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -397     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 41.8     |
| loss/critic2                       | 42.3     |
| timestep                           | 102000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2321
----------------------------------------------------------------------------------
| alpha                              | 0.279    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.8     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -399     |
| loss/alpha                         | -0.0262  |
| loss/critic1                       | 40.2     |
| loss/critic2                       | 40.1     |
| timestep                           | 103000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2390
----------------------------------------------------------------------------------
| alpha                              | 0.28     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.3     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -401     |
| loss/alpha                         | 0.0158   |
| loss/critic1                       | 38.9     |
| loss/critic2                       | 38.4     |
| timestep                           | 104000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2697
----------------------------------------------------------------------------------
| alpha                              | 0.279    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50       |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -403     |
| loss/alpha                         | -0.0154  |
| loss/critic1                       | 37.4     |
| loss/critic2                       | 37.2     |
| timestep                           | 105000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2556
----------------------------------------------------------------------------------
| alpha                              | 0.28     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 16.2     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -405     |
| loss/alpha                         | 0.0452   |
| loss/critic1                       | 39.1     |
| loss/critic2                       | 39.1     |
| timestep                           | 106000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2317
----------------------------------------------------------------------------------
| alpha                              | 0.28     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.3     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -407     |
| loss/alpha                         | -0.0281  |
| loss/critic1                       | 53.4     |
| loss/critic2                       | 53       |
| timestep                           | 107000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2179
----------------------------------------------------------------------------------
| alpha                              | 0.278    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 42.8     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -409     |
| loss/alpha                         | 0.00938  |
| loss/critic1                       | 50.7     |
| loss/critic2                       | 50.3     |
| timestep                           | 108000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2470
----------------------------------------------------------------------------------
| alpha                              | 0.279    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.8     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -410     |
| loss/alpha                         | -0.0413  |
| loss/critic1                       | 44.6     |
| loss/critic2                       | 44.2     |
| timestep                           | 109000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2482
----------------------------------------------------------------------------------
| alpha                              | 0.274    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 2.64     |
| loss/actor                         | -411     |
| loss/alpha                         | -0.0629  |
| loss/critic1                       | 49.4     |
| loss/critic2                       | 49.1     |
| timestep                           | 110000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2595
----------------------------------------------------------------------------------
| alpha                              | 0.273    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.1     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -413     |
| loss/alpha                         | 0.00735  |
| loss/critic1                       | 44.3     |
| loss/critic2                       | 44.2     |
| timestep                           | 111000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2516
----------------------------------------------------------------------------------
| alpha                              | 0.272    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.1     |
| eval/normalized_episode_reward_std | 25.5     |
| loss/actor                         | -414     |
| loss/alpha                         | -0.0288  |
| loss/critic1                       | 36.1     |
| loss/critic2                       | 36.2     |
| timestep                           | 112000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2706
----------------------------------------------------------------------------------
| alpha                              | 0.272    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.9     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -416     |
| loss/alpha                         | 0.044    |
| loss/critic1                       | 35.7     |
| loss/critic2                       | 35.7     |
| timestep                           | 113000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2425
-----------------------------------------------------------------------------------
| alpha                              | 0.274     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 37.1      |
| eval/normalized_episode_reward_std | 24.1      |
| loss/actor                         | -418      |
| loss/alpha                         | -0.000851 |
| loss/critic1                       | 33.9      |
| loss/critic2                       | 33.7      |
| timestep                           | 114000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2568
----------------------------------------------------------------------------------
| alpha                              | 0.274    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 27.8     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -420     |
| loss/alpha                         | -0.0435  |
| loss/critic1                       | 33.7     |
| loss/critic2                       | 33.9     |
| timestep                           | 115000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2660
----------------------------------------------------------------------------------
| alpha                              | 0.271    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47.5     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -422     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 35       |
| loss/critic2                       | 35.1     |
| timestep                           | 116000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2399
----------------------------------------------------------------------------------
| alpha                              | 0.269    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.7     |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | -424     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 35.4     |
| loss/critic2                       | 35.6     |
| timestep                           | 117000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2453
----------------------------------------------------------------------------------
| alpha                              | 0.267    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.2     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -426     |
| loss/alpha                         | -0.0731  |
| loss/critic1                       | 36.7     |
| loss/critic2                       | 36.5     |
| timestep                           | 118000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2544
----------------------------------------------------------------------------------
| alpha                              | 0.264    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.7     |
| eval/normalized_episode_reward_std | 6.89     |
| loss/actor                         | -428     |
| loss/alpha                         | -0.00862 |
| loss/critic1                       | 36.4     |
| loss/critic2                       | 36.3     |
| timestep                           | 119000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2409
-----------------------------------------------------------------------------------
| alpha                              | 0.264     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 60.6      |
| eval/normalized_episode_reward_std | 3.01      |
| loss/actor                         | -430      |
| loss/alpha                         | -0.000135 |
| loss/critic1                       | 36.7      |
| loss/critic2                       | 36.6      |
| timestep                           | 120000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2557
----------------------------------------------------------------------------------
| alpha                              | 0.262    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.2     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -431     |
| loss/alpha                         | -0.0513  |
| loss/critic1                       | 37.7     |
| loss/critic2                       | 37.7     |
| timestep                           | 121000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2487
----------------------------------------------------------------------------------
| alpha                              | 0.26     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 29.8     |
| eval/normalized_episode_reward_std | 27.5     |
| loss/actor                         | -433     |
| loss/alpha                         | -0.0662  |
| loss/critic1                       | 35.2     |
| loss/critic2                       | 35.5     |
| timestep                           | 122000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2550
----------------------------------------------------------------------------------
| alpha                              | 0.257    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.4     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -435     |
| loss/alpha                         | 0.00631  |
| loss/critic1                       | 35.6     |
| loss/critic2                       | 35.2     |
| timestep                           | 123000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2532
----------------------------------------------------------------------------------
| alpha                              | 0.259    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.1     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -436     |
| loss/alpha                         | 0.0294   |
| loss/critic1                       | 36.4     |
| loss/critic2                       | 36.5     |
| timestep                           | 124000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2825
----------------------------------------------------------------------------------
| alpha                              | 0.261    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 45.7     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -438     |
| loss/alpha                         | 0.0396   |
| loss/critic1                       | 34.7     |
| loss/critic2                       | 34.6     |
| timestep                           | 125000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2601
----------------------------------------------------------------------------------
| alpha                              | 0.261    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.5     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -440     |
| loss/alpha                         | 0.00992  |
| loss/critic1                       | 37.5     |
| loss/critic2                       | 37.4     |
| timestep                           | 126000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2449
----------------------------------------------------------------------------------
| alpha                              | 0.261    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.5     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -441     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 37.2     |
| loss/critic2                       | 37.1     |
| timestep                           | 127000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2624
----------------------------------------------------------------------------------
| alpha                              | 0.26     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 37.9     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -443     |
| loss/alpha                         | -0.0441  |
| loss/critic1                       | 36.4     |
| loss/critic2                       | 36.4     |
| timestep                           | 128000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2576
----------------------------------------------------------------------------------
| alpha                              | 0.255    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.1     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -444     |
| loss/alpha                         | -0.0793  |
| loss/critic1                       | 33.9     |
| loss/critic2                       | 33.5     |
| timestep                           | 129000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2662
----------------------------------------------------------------------------------
| alpha                              | 0.253    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 45.8     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -446     |
| loss/alpha                         | -0.013   |
| loss/critic1                       | 35.1     |
| loss/critic2                       | 35.5     |
| timestep                           | 130000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2496
----------------------------------------------------------------------------------
| alpha                              | 0.253    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -448     |
| loss/alpha                         | -0.0203  |
| loss/critic1                       | 32.4     |
| loss/critic2                       | 32.1     |
| timestep                           | 131000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2726
----------------------------------------------------------------------------------
| alpha                              | 0.249    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58       |
| eval/normalized_episode_reward_std | 13.2     |
| loss/actor                         | -449     |
| loss/alpha                         | -0.0679  |
| loss/critic1                       | 31.4     |
| loss/critic2                       | 31.2     |
| timestep                           | 132000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2661
----------------------------------------------------------------------------------
| alpha                              | 0.246    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.5     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -451     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 33.5     |
| loss/critic2                       | 33.4     |
| timestep                           | 133000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2714
----------------------------------------------------------------------------------
| alpha                              | 0.245    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.7     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -453     |
| loss/alpha                         | -0.0468  |
| loss/critic1                       | 33.2     |
| loss/critic2                       | 32.8     |
| timestep                           | 134000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2522
----------------------------------------------------------------------------------
| alpha                              | 0.247    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -454     |
| loss/alpha                         | 0.0917   |
| loss/critic1                       | 34.4     |
| loss/critic2                       | 34.4     |
| timestep                           | 135000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2650
----------------------------------------------------------------------------------
| alpha                              | 0.248    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.2     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -456     |
| loss/alpha                         | -0.0436  |
| loss/critic1                       | 33.2     |
| loss/critic2                       | 33.1     |
| timestep                           | 136000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2605
----------------------------------------------------------------------------------
| alpha                              | 0.246    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.1     |
| eval/normalized_episode_reward_std | 6.09     |
| loss/actor                         | -458     |
| loss/alpha                         | -0.0414  |
| loss/critic1                       | 30.4     |
| loss/critic2                       | 30.2     |
| timestep                           | 137000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2606
----------------------------------------------------------------------------------
| alpha                              | 0.246    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 6.98     |
| loss/actor                         | -459     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 29.6     |
| loss/critic2                       | 29.7     |
| timestep                           | 138000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2732
----------------------------------------------------------------------------------
| alpha                              | 0.247    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.5     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -461     |
| loss/alpha                         | 0.043    |
| loss/critic1                       | 30.8     |
| loss/critic2                       | 30.8     |
| timestep                           | 139000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2648
----------------------------------------------------------------------------------
| alpha                              | 0.252    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.7     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -463     |
| loss/alpha                         | 0.0721   |
| loss/critic1                       | 33       |
| loss/critic2                       | 33.2     |
| timestep                           | 140000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2666
----------------------------------------------------------------------------------
| alpha                              | 0.25     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.1     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -464     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 33.2     |
| loss/critic2                       | 33.2     |
| timestep                           | 141000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2725
----------------------------------------------------------------------------------
| alpha                              | 0.247    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -465     |
| loss/alpha                         | -0.0286  |
| loss/critic1                       | 31.7     |
| loss/critic2                       | 32.3     |
| timestep                           | 142000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2494
----------------------------------------------------------------------------------
| alpha                              | 0.243    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.1     |
| eval/normalized_episode_reward_std | 9.48     |
| loss/actor                         | -466     |
| loss/alpha                         | -0.037   |
| loss/critic1                       | 34.2     |
| loss/critic2                       | 34.1     |
| timestep                           | 143000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2767
----------------------------------------------------------------------------------
| alpha                              | 0.245    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64       |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -467     |
| loss/alpha                         | 0.0808   |
| loss/critic1                       | 35.8     |
| loss/critic2                       | 36.2     |
| timestep                           | 144000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2694
----------------------------------------------------------------------------------
| alpha                              | 0.245    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -468     |
| loss/alpha                         | -0.091   |
| loss/critic1                       | 32.6     |
| loss/critic2                       | 32.6     |
| timestep                           | 145000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2432
----------------------------------------------------------------------------------
| alpha                              | 0.241    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.3     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -469     |
| loss/alpha                         | -0.0642  |
| loss/critic1                       | 31.5     |
| loss/critic2                       | 31.6     |
| timestep                           | 146000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2691
----------------------------------------------------------------------------------
| alpha                              | 0.239    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.5     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -471     |
| loss/alpha                         | -0.035   |
| loss/critic1                       | 30.9     |
| loss/critic2                       | 31       |
| timestep                           | 147000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2725
----------------------------------------------------------------------------------
| alpha                              | 0.236    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -472     |
| loss/alpha                         | -0.0607  |
| loss/critic1                       | 31.5     |
| loss/critic2                       | 31.6     |
| timestep                           | 148000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.234    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.2     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -473     |
| loss/alpha                         | 0.0142   |
| loss/critic1                       | 32.5     |
| loss/critic2                       | 32.3     |
| timestep                           | 149000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2733
----------------------------------------------------------------------------------
| alpha                              | 0.237    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -475     |
| loss/alpha                         | 0.0571   |
| loss/critic1                       | 32.7     |
| loss/critic2                       | 32.4     |
| timestep                           | 150000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2719
----------------------------------------------------------------------------------
| alpha                              | 0.236    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65       |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -476     |
| loss/alpha                         | -0.0803  |
| loss/critic1                       | 32.6     |
| loss/critic2                       | 32.5     |
| timestep                           | 151000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2810
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 6.47     |
| loss/actor                         | -478     |
| loss/alpha                         | 0.0432   |
| loss/critic1                       | 32.4     |
| loss/critic2                       | 32.5     |
| timestep                           | 152000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2810
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -479     |
| loss/alpha                         | -0.0219  |
| loss/critic1                       | 29.6     |
| loss/critic2                       | 29.6     |
| timestep                           | 153000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2751
----------------------------------------------------------------------------------
| alpha                              | 0.238    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -480     |
| loss/alpha                         | 0.0876   |
| loss/critic1                       | 29.6     |
| loss/critic2                       | 29.6     |
| timestep                           | 154000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2717
----------------------------------------------------------------------------------
| alpha                              | 0.239    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -482     |
| loss/alpha                         | -0.0389  |
| loss/critic1                       | 30.4     |
| loss/critic2                       | 30.1     |
| timestep                           | 155000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2819
----------------------------------------------------------------------------------
| alpha                              | 0.239    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.8     |
| eval/normalized_episode_reward_std | 6.79     |
| loss/actor                         | -483     |
| loss/alpha                         | 0.0462   |
| loss/critic1                       | 30.4     |
| loss/critic2                       | 30.1     |
| timestep                           | 156000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2608
----------------------------------------------------------------------------------
| alpha                              | 0.239    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.8     |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -484     |
| loss/alpha                         | -0.00807 |
| loss/critic1                       | 29.9     |
| loss/critic2                       | 29.9     |
| timestep                           | 157000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.238    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -486     |
| loss/alpha                         | -0.0166  |
| loss/critic1                       | 30.8     |
| loss/critic2                       | 30.7     |
| timestep                           | 158000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2778
----------------------------------------------------------------------------------
| alpha                              | 0.237    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.1     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -487     |
| loss/alpha                         | -0.0395  |
| loss/critic1                       | 31.1     |
| loss/critic2                       | 30.7     |
| timestep                           | 159000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2801
----------------------------------------------------------------------------------
| alpha                              | 0.236    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.4     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -488     |
| loss/alpha                         | -0.00951 |
| loss/critic1                       | 29       |
| loss/critic2                       | 29       |
| timestep                           | 160000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2858
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 2.59     |
| loss/actor                         | -490     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 27.7     |
| loss/critic2                       | 27.9     |
| timestep                           | 161000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2777
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.5     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -491     |
| loss/alpha                         | 0.0081   |
| loss/critic1                       | 29.9     |
| loss/critic2                       | 29.9     |
| timestep                           | 162000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2797
----------------------------------------------------------------------------------
| alpha                              | 0.236    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -492     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 29.3     |
| loss/critic2                       | 29.2     |
| timestep                           | 163000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2744
----------------------------------------------------------------------------------
| alpha                              | 0.234    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.1     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -493     |
| loss/alpha                         | -0.0149  |
| loss/critic1                       | 30.8     |
| loss/critic2                       | 30.7     |
| timestep                           | 164000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2903
----------------------------------------------------------------------------------
| alpha                              | 0.234    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.1     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -494     |
| loss/alpha                         | -0.0035  |
| loss/critic1                       | 27.5     |
| loss/critic2                       | 27.6     |
| timestep                           | 165000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2744
----------------------------------------------------------------------------------
| alpha                              | 0.231    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -495     |
| loss/alpha                         | -0.0828  |
| loss/critic1                       | 28       |
| loss/critic2                       | 27.9     |
| timestep                           | 166000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.23     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 11.9     |
| loss/actor                         | -496     |
| loss/alpha                         | -0.01    |
| loss/critic1                       | 28.3     |
| loss/critic2                       | 28.4     |
| timestep                           | 167000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.229    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -497     |
| loss/alpha                         | 0.0281   |
| loss/critic1                       | 28.5     |
| loss/critic2                       | 28.4     |
| timestep                           | 168000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2641
----------------------------------------------------------------------------------
| alpha                              | 0.233    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 5.57     |
| loss/actor                         | -498     |
| loss/alpha                         | 0.0814   |
| loss/critic1                       | 27.8     |
| loss/critic2                       | 27.7     |
| timestep                           | 169000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2694
----------------------------------------------------------------------------------
| alpha                              | 0.233    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -498     |
| loss/alpha                         | -0.0634  |
| loss/critic1                       | 28       |
| loss/critic2                       | 27.8     |
| timestep                           | 170000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2642
----------------------------------------------------------------------------------
| alpha                              | 0.231    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.8     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -499     |
| loss/alpha                         | -0.0336  |
| loss/critic1                       | 26.6     |
| loss/critic2                       | 26.3     |
| timestep                           | 171000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.23     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -500     |
| loss/alpha                         | 0.00275  |
| loss/critic1                       | 27.6     |
| loss/critic2                       | 27.4     |
| timestep                           | 172000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2740
----------------------------------------------------------------------------------
| alpha                              | 0.228    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.3     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -500     |
| loss/alpha                         | -0.083   |
| loss/critic1                       | 26.6     |
| loss/critic2                       | 26.5     |
| timestep                           | 173000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2726
----------------------------------------------------------------------------------
| alpha                              | 0.224    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -501     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 25.1     |
| loss/critic2                       | 24.8     |
| timestep                           | 174000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2752
----------------------------------------------------------------------------------
| alpha                              | 0.224    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.3     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -503     |
| loss/alpha                         | -0.046   |
| loss/critic1                       | 24.7     |
| loss/critic2                       | 24.5     |
| timestep                           | 175000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2901
----------------------------------------------------------------------------------
| alpha                              | 0.223    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -504     |
| loss/alpha                         | 0.0298   |
| loss/critic1                       | 27.1     |
| loss/critic2                       | 26.9     |
| timestep                           | 176000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2915
----------------------------------------------------------------------------------
| alpha                              | 0.224    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -505     |
| loss/alpha                         | 0.045    |
| loss/critic1                       | 27.3     |
| loss/critic2                       | 27.1     |
| timestep                           | 177000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2713
----------------------------------------------------------------------------------
| alpha                              | 0.226    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -506     |
| loss/alpha                         | -0.00117 |
| loss/critic1                       | 28.2     |
| loss/critic2                       | 27.8     |
| timestep                           | 178000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2674
----------------------------------------------------------------------------------
| alpha                              | 0.226    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -507     |
| loss/alpha                         | -0.0205  |
| loss/critic1                       | 28.6     |
| loss/critic2                       | 28.5     |
| timestep                           | 179000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.225    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -508     |
| loss/alpha                         | 0.0136   |
| loss/critic1                       | 29       |
| loss/critic2                       | 28.7     |
| timestep                           | 180000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2821
----------------------------------------------------------------------------------
| alpha                              | 0.225    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -509     |
| loss/alpha                         | -0.0584  |
| loss/critic1                       | 27.4     |
| loss/critic2                       | 27.2     |
| timestep                           | 181000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2763
----------------------------------------------------------------------------------
| alpha                              | 0.223    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -510     |
| loss/alpha                         | 0.0613   |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 25       |
| timestep                           | 182000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2837
----------------------------------------------------------------------------------
| alpha                              | 0.228    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.8     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -510     |
| loss/alpha                         | 0.0873   |
| loss/critic1                       | 25.1     |
| loss/critic2                       | 25       |
| timestep                           | 183000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2927
----------------------------------------------------------------------------------
| alpha                              | 0.231    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -512     |
| loss/alpha                         | 0.0302   |
| loss/critic1                       | 28.5     |
| loss/critic2                       | 28.5     |
| timestep                           | 184000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2798
----------------------------------------------------------------------------------
| alpha                              | 0.229    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -513     |
| loss/alpha                         | -0.0961  |
| loss/critic1                       | 26.8     |
| loss/critic2                       | 27       |
| timestep                           | 185000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2679
----------------------------------------------------------------------------------
| alpha                              | 0.225    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -514     |
| loss/alpha                         | -0.0328  |
| loss/critic1                       | 26.2     |
| loss/critic2                       | 26.3     |
| timestep                           | 186000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2877
----------------------------------------------------------------------------------
| alpha                              | 0.224    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.6     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -515     |
| loss/alpha                         | -0.0636  |
| loss/critic1                       | 26.5     |
| loss/critic2                       | 26.4     |
| timestep                           | 187000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2747
----------------------------------------------------------------------------------
| alpha                              | 0.222    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -515     |
| loss/alpha                         | -0.0299  |
| loss/critic1                       | 26.4     |
| loss/critic2                       | 26.4     |
| timestep                           | 188000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2725
----------------------------------------------------------------------------------
| alpha                              | 0.22     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -516     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 25       |
| loss/critic2                       | 24.8     |
| timestep                           | 189000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2905
----------------------------------------------------------------------------------
| alpha                              | 0.219    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -517     |
| loss/alpha                         | -0.0135  |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 25.1     |
| timestep                           | 190000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2580
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -518     |
| loss/alpha                         | -0.0436  |
| loss/critic1                       | 26.8     |
| loss/critic2                       | 26.4     |
| timestep                           | 191000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2922
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -519     |
| loss/alpha                         | 0.0388   |
| loss/critic1                       | 26.1     |
| loss/critic2                       | 25.9     |
| timestep                           | 192000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2841
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -520     |
| loss/alpha                         | -0.0775  |
| loss/critic1                       | 23.7     |
| loss/critic2                       | 23.7     |
| timestep                           | 193000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2762
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -521     |
| loss/alpha                         | 0.0735   |
| loss/critic1                       | 23.8     |
| loss/critic2                       | 23.8     |
| timestep                           | 194000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2853
----------------------------------------------------------------------------------
| alpha                              | 0.22     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -522     |
| loss/alpha                         | 0.0574   |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 23.9     |
| timestep                           | 195000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.221    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -523     |
| loss/alpha                         | 0.00827  |
| loss/critic1                       | 24.6     |
| loss/critic2                       | 24.5     |
| timestep                           | 196000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.222    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -524     |
| loss/alpha                         | 0.0269   |
| loss/critic1                       | 24       |
| loss/critic2                       | 23.7     |
| timestep                           | 197000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.223    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -525     |
| loss/alpha                         | 0.0267   |
| loss/critic1                       | 24.2     |
| loss/critic2                       | 24       |
| timestep                           | 198000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2838
----------------------------------------------------------------------------------
| alpha                              | 0.223    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64       |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -527     |
| loss/alpha                         | -0.0167  |
| loss/critic1                       | 24.9     |
| loss/critic2                       | 24.5     |
| timestep                           | 199000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2653
----------------------------------------------------------------------------------
| alpha                              | 0.222    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -527     |
| loss/alpha                         | -0.0182  |
| loss/critic1                       | 26.6     |
| loss/critic2                       | 26.4     |
| timestep                           | 200000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2735
----------------------------------------------------------------------------------
| alpha                              | 0.223    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -528     |
| loss/alpha                         | 0.00369  |
| loss/critic1                       | 24.9     |
| loss/critic2                       | 24.9     |
| timestep                           | 201000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.22     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -529     |
| loss/alpha                         | -0.0786  |
| loss/critic1                       | 25.5     |
| loss/critic2                       | 25.1     |
| timestep                           | 202000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
-----------------------------------------------------------------------------------
| alpha                              | 0.218     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 59        |
| eval/normalized_episode_reward_std | 21.9      |
| loss/actor                         | -530      |
| loss/alpha                         | -0.000562 |
| loss/critic1                       | 25.3      |
| loss/critic2                       | 25.3      |
| timestep                           | 203000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2794
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -530     |
| loss/alpha                         | -0.0226  |
| loss/critic1                       | 25.4     |
| loss/critic2                       | 25.5     |
| timestep                           | 204000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2788
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 3.72     |
| loss/actor                         | -531     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 33.6     |
| loss/critic2                       | 34.3     |
| timestep                           | 205000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2786
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -532     |
| loss/alpha                         | -0.0179  |
| loss/critic1                       | 26.4     |
| loss/critic2                       | 26.3     |
| timestep                           | 206000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2751
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 2.59     |
| loss/actor                         | -533     |
| loss/alpha                         | -0.00243 |
| loss/critic1                       | 26.4     |
| loss/critic2                       | 26.3     |
| timestep                           | 207000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2773
----------------------------------------------------------------------------------
| alpha                              | 0.215    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -534     |
| loss/alpha                         | -0.0146  |
| loss/critic1                       | 25.1     |
| loss/critic2                       | 25       |
| timestep                           | 208000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2861
----------------------------------------------------------------------------------
| alpha                              | 0.215    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -534     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 26.5     |
| loss/critic2                       | 26.4     |
| timestep                           | 209000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3009
----------------------------------------------------------------------------------
| alpha                              | 0.214    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -535     |
| loss/alpha                         | -0.0167  |
| loss/critic1                       | 24.2     |
| loss/critic2                       | 24.1     |
| timestep                           | 210000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2787
----------------------------------------------------------------------------------
| alpha                              | 0.212    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -536     |
| loss/alpha                         | -0.06    |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 24.5     |
| timestep                           | 211000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -537     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 24.3     |
| loss/critic2                       | 24.4     |
| timestep                           | 212000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -538     |
| loss/alpha                         | -0.0129  |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.6     |
| timestep                           | 213000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2757
-----------------------------------------------------------------------------------
| alpha                              | 0.211     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 72.6      |
| eval/normalized_episode_reward_std | 3.63      |
| loss/actor                         | -538      |
| loss/alpha                         | -5.86e-05 |
| loss/critic1                       | 23.9      |
| loss/critic2                       | 23.9      |
| timestep                           | 214000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.209    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -539     |
| loss/alpha                         | -0.0644  |
| loss/critic1                       | 24       |
| loss/critic2                       | 24.3     |
| timestep                           | 215000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2768
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63       |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -540     |
| loss/alpha                         | -0.0226  |
| loss/critic1                       | 23.8     |
| loss/critic2                       | 23.7     |
| timestep                           | 216000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2714
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -540     |
| loss/alpha                         | -0.047   |
| loss/critic1                       | 26.8     |
| loss/critic2                       | 27.1     |
| timestep                           | 217000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2790
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -541     |
| loss/alpha                         | 0.0453   |
| loss/critic1                       | 25.4     |
| loss/critic2                       | 25.4     |
| timestep                           | 218000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2904
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -542     |
| loss/alpha                         | 0.0256   |
| loss/critic1                       | 25.7     |
| loss/critic2                       | 25.6     |
| timestep                           | 219000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2738
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.5     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -542     |
| loss/alpha                         | 0.012    |
| loss/critic1                       | 26.2     |
| loss/critic2                       | 26.3     |
| timestep                           | 220000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2825
----------------------------------------------------------------------------------
| alpha                              | 0.209    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -542     |
| loss/alpha                         | 0.0172   |
| loss/critic1                       | 25.5     |
| loss/critic2                       | 25.5     |
| timestep                           | 221000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2801
----------------------------------------------------------------------------------
| alpha                              | 0.21     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -543     |
| loss/alpha                         | 0.0244   |
| loss/critic1                       | 25.4     |
| loss/critic2                       | 25       |
| timestep                           | 222000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -543     |
| loss/alpha                         | 0.0243   |
| loss/critic1                       | 23.4     |
| loss/critic2                       | 23.4     |
| timestep                           | 223000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2958
----------------------------------------------------------------------------------
| alpha                              | 0.212    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -544     |
| loss/alpha                         | 0.00869  |
| loss/critic1                       | 24.6     |
| loss/critic2                       | 24.3     |
| timestep                           | 224000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.21     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -544     |
| loss/alpha                         | -0.115   |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 24.1     |
| timestep                           | 225000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -545     |
| loss/alpha                         | 0.0235   |
| loss/critic1                       | 22.2     |
| loss/critic2                       | 21.9     |
| timestep                           | 226000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 6.73     |
| loss/actor                         | -545     |
| loss/alpha                         | -0.0216  |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.2     |
| timestep                           | 227000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2914
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -546     |
| loss/alpha                         | 0.087    |
| loss/critic1                       | 24.2     |
| loss/critic2                       | 24       |
| timestep                           | 228000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2991
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -547     |
| loss/alpha                         | -0.0141  |
| loss/critic1                       | 24.7     |
| loss/critic2                       | 24.7     |
| timestep                           | 229000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2789
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -547     |
| loss/alpha                         | -0.0855  |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.4     |
| timestep                           | 230000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2968
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -548     |
| loss/alpha                         | 0.000343 |
| loss/critic1                       | 23.6     |
| loss/critic2                       | 23.9     |
| timestep                           | 231000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2815
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -549     |
| loss/alpha                         | -0.00292 |
| loss/critic1                       | 22.2     |
| loss/critic2                       | 22       |
| timestep                           | 232000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.207    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.5     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -550     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.7     |
| timestep                           | 233000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.207    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -551     |
| loss/alpha                         | -0.0496  |
| loss/critic1                       | 23.6     |
| loss/critic2                       | 23.5     |
| timestep                           | 234000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -552     |
| loss/alpha                         | 0.0052   |
| loss/critic1                       | 23.1     |
| loss/critic2                       | 22.9     |
| timestep                           | 235000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3010
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -553     |
| loss/alpha                         | -0.00826 |
| loss/critic1                       | 23.7     |
| loss/critic2                       | 23.8     |
| timestep                           | 236000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2864
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.1     |
| eval/normalized_episode_reward_std | 25       |
| loss/actor                         | -553     |
| loss/alpha                         | -0.0422  |
| loss/critic1                       | 24.8     |
| loss/critic2                       | 24.7     |
| timestep                           | 237000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2890
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -554     |
| loss/alpha                         | -0.0146  |
| loss/critic1                       | 23.3     |
| loss/critic2                       | 23.4     |
| timestep                           | 238000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2858
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -555     |
| loss/alpha                         | 0.0623   |
| loss/critic1                       | 23.4     |
| loss/critic2                       | 23.2     |
| timestep                           | 239000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2822
----------------------------------------------------------------------------------
| alpha                              | 0.207    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -555     |
| loss/alpha                         | 0.0395   |
| loss/critic1                       | 23.4     |
| loss/critic2                       | 23.4     |
| timestep                           | 240000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.207    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 4.23     |
| loss/actor                         | -556     |
| loss/alpha                         | -0.0601  |
| loss/critic1                       | 24.5     |
| loss/critic2                       | 24.5     |
| timestep                           | 241000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3033
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -556     |
| loss/alpha                         | 0.0444   |
| loss/critic1                       | 23.3     |
| loss/critic2                       | 23.4     |
| timestep                           | 242000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3057
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -557     |
| loss/alpha                         | -0.0167  |
| loss/critic1                       | 24       |
| loss/critic2                       | 24.1     |
| timestep                           | 243000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2938
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -558     |
| loss/alpha                         | -0.0249  |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.3     |
| timestep                           | 244000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -558     |
| loss/alpha                         | -0.0843  |
| loss/critic1                       | 23.1     |
| loss/critic2                       | 23       |
| timestep                           | 245000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2714
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -559     |
| loss/alpha                         | -0.0571  |
| loss/critic1                       | 24.7     |
| loss/critic2                       | 24.7     |
| timestep                           | 246000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -559     |
| loss/alpha                         | -0.024   |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 23.9     |
| timestep                           | 247000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2943
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -560     |
| loss/alpha                         | -0.0152  |
| loss/critic1                       | 24.5     |
| loss/critic2                       | 24.3     |
| timestep                           | 248000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
-----------------------------------------------------------------------------------
| alpha                              | 0.198     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 67.3      |
| eval/normalized_episode_reward_std | 12.2      |
| loss/actor                         | -560      |
| loss/alpha                         | -0.000469 |
| loss/critic1                       | 23.9      |
| loss/critic2                       | 23.9      |
| timestep                           | 249000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2841
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -561     |
| loss/alpha                         | -0.00209 |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.3     |
| timestep                           | 250000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -562     |
| loss/alpha                         | 0.0847   |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.3     |
| timestep                           | 251000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2739
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -563     |
| loss/alpha                         | 0.0473   |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.4     |
| timestep                           | 252000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -564     |
| loss/alpha                         | 0.0329   |
| loss/critic1                       | 25.1     |
| loss/critic2                       | 25       |
| timestep                           | 253000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2914
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -564     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 24.3     |
| loss/critic2                       | 24.4     |
| timestep                           | 254000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2947
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -565     |
| loss/alpha                         | 0.00617  |
| loss/critic1                       | 25       |
| loss/critic2                       | 25       |
| timestep                           | 255000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2944
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -565     |
| loss/alpha                         | -0.0899  |
| loss/critic1                       | 23.2     |
| loss/critic2                       | 23.2     |
| timestep                           | 256000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3028
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.1     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -566     |
| loss/alpha                         | 0.0161   |
| loss/critic1                       | 23.6     |
| loss/critic2                       | 23.7     |
| timestep                           | 257000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2834
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -566     |
| loss/alpha                         | 0.0233   |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.3     |
| timestep                           | 258000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -567     |
| loss/alpha                         | -0.0251  |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.8     |
| timestep                           | 259000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2909
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 10.3     |
| loss/actor                         | -567     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.7     |
| timestep                           | 260000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2965
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -568     |
| loss/alpha                         | 0.0166   |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.8     |
| timestep                           | 261000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -568     |
| loss/alpha                         | 0.0177   |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.3     |
| timestep                           | 262000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2918
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -569     |
| loss/alpha                         | 0.0251   |
| loss/critic1                       | 23       |
| loss/critic2                       | 22.9     |
| timestep                           | 263000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -569     |
| loss/alpha                         | -0.0191  |
| loss/critic1                       | 23.3     |
| loss/critic2                       | 23       |
| timestep                           | 264000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -570     |
| loss/alpha                         | -0.0964  |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.8     |
| timestep                           | 265000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -570     |
| loss/alpha                         | 0.0252   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.8     |
| timestep                           | 266000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2999
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -571     |
| loss/alpha                         | 0.0331   |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.6     |
| timestep                           | 267000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -571     |
| loss/alpha                         | 0.0369   |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.8     |
| timestep                           | 268000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2781
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -572     |
| loss/alpha                         | -0.0174  |
| loss/critic1                       | 23.6     |
| loss/critic2                       | 23.5     |
| timestep                           | 269000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2903
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -573     |
| loss/alpha                         | -0.0127  |
| loss/critic1                       | 23.9     |
| loss/critic2                       | 23.7     |
| timestep                           | 270000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3015
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -573     |
| loss/alpha                         | 0.0272   |
| loss/critic1                       | 23.3     |
| loss/critic2                       | 23.3     |
| timestep                           | 271000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3093
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.88     |
| loss/actor                         | -573     |
| loss/alpha                         | 0.0704   |
| loss/critic1                       | 24.2     |
| loss/critic2                       | 24.2     |
| timestep                           | 272000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3020
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -574     |
| loss/alpha                         | -0.0914  |
| loss/critic1                       | 24.3     |
| loss/critic2                       | 24.2     |
| timestep                           | 273000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3019
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -574     |
| loss/alpha                         | 0.0148   |
| loss/critic1                       | 24.3     |
| loss/critic2                       | 24.2     |
| timestep                           | 274000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -575     |
| loss/alpha                         | 0.0279   |
| loss/critic1                       | 25.2     |
| loss/critic2                       | 25.2     |
| timestep                           | 275000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3083
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -575     |
| loss/alpha                         | -0.0023  |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 24.2     |
| timestep                           | 276000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3061
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.5     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -576     |
| loss/alpha                         | -0.0505  |
| loss/critic1                       | 22.5     |
| loss/critic2                       | 22.6     |
| timestep                           | 277000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2891
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.64     |
| loss/actor                         | -576     |
| loss/alpha                         | 0.0182   |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22       |
| timestep                           | 278000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2882
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 8.39     |
| loss/actor                         | -576     |
| loss/alpha                         | 0.0579   |
| loss/critic1                       | 23.2     |
| loss/critic2                       | 23.1     |
| timestep                           | 279000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2988
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -577     |
| loss/alpha                         | -0.0473  |
| loss/critic1                       | 22       |
| loss/critic2                       | 22.1     |
| timestep                           | 280000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -577     |
| loss/alpha                         | -0.0203  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.6     |
| timestep                           | 281000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3022
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.9     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -578     |
| loss/alpha                         | -0.0367  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22.2     |
| timestep                           | 282000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2898
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -578     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 23.8     |
| loss/critic2                       | 23.7     |
| timestep                           | 283000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2855
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -578     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 23.4     |
| loss/critic2                       | 23.5     |
| timestep                           | 284000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -578     |
| loss/alpha                         | -0.0571  |
| loss/critic1                       | 23.7     |
| loss/critic2                       | 23.7     |
| timestep                           | 285000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2791
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -578     |
| loss/alpha                         | -0.0843  |
| loss/critic1                       | 23       |
| loss/critic2                       | 23       |
| timestep                           | 286000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -577     |
| loss/alpha                         | -0.0748  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22.1     |
| timestep                           | 287000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 5.41     |
| loss/actor                         | -577     |
| loss/alpha                         | 0.00588  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.3     |
| timestep                           | 288000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 2.63     |
| loss/actor                         | -578     |
| loss/alpha                         | 0.00643  |
| loss/critic1                       | 22.7     |
| loss/critic2                       | 22.8     |
| timestep                           | 289000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2930
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -578     |
| loss/alpha                         | -0.0428  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22.1     |
| timestep                           | 290000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2991
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -578     |
| loss/alpha                         | 0.00151  |
| loss/critic1                       | 22.8     |
| loss/critic2                       | 22.8     |
| timestep                           | 291000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2825
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -578     |
| loss/alpha                         | -0.0481  |
| loss/critic1                       | 23.1     |
| loss/critic2                       | 23.2     |
| timestep                           | 292000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3008
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -578     |
| loss/alpha                         | -0.0952  |
| loss/critic1                       | 23.1     |
| loss/critic2                       | 22.9     |
| timestep                           | 293000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2956
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -579     |
| loss/alpha                         | -0.0189  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.7     |
| timestep                           | 294000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -579     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 21       |
| loss/critic2                       | 21.1     |
| timestep                           | 295000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2897
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -580     |
| loss/alpha                         | 0.00635  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 296000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3022
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -580     |
| loss/alpha                         | 0.0997   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 297000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3150
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -581     |
| loss/alpha                         | 0.07     |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.2     |
| timestep                           | 298000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -582     |
| loss/alpha                         | 0.0129   |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.9     |
| timestep                           | 299000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3029
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.9      |
| loss/actor                         | -582     |
| loss/alpha                         | -0.032   |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.8     |
| timestep                           | 300000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -583     |
| loss/alpha                         | 0.0665   |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.5     |
| timestep                           | 301000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2956
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.6      |
| loss/actor                         | -583     |
| loss/alpha                         | 0.00359  |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.3     |
| timestep                           | 302000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2845
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 2.61     |
| loss/actor                         | -584     |
| loss/alpha                         | 0.0456   |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.6     |
| timestep                           | 303000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -584     |
| loss/alpha                         | -0.0283  |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.7     |
| timestep                           | 304000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2887
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -585     |
| loss/alpha                         | -0.0448  |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.7     |
| timestep                           | 305000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2889
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -585     |
| loss/alpha                         | 0.0295   |
| loss/critic1                       | 22.7     |
| loss/critic2                       | 22.6     |
| timestep                           | 306000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3040
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -585     |
| loss/alpha                         | -0.0434  |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.2     |
| timestep                           | 307000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2854
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -586     |
| loss/alpha                         | -0.124   |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.3     |
| timestep                           | 308000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -586     |
| loss/alpha                         | 0.0351   |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.9     |
| timestep                           | 309000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3097
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -586     |
| loss/alpha                         | 0.051    |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.5     |
| timestep                           | 310000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 4.56     |
| loss/actor                         | -587     |
| loss/alpha                         | -0.0386  |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.6     |
| timestep                           | 311000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -587     |
| loss/alpha                         | 0.00639  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.3     |
| timestep                           | 312000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3124
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -588     |
| loss/alpha                         | 0.0301   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.1     |
| timestep                           | 313000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3046
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 25.2     |
| loss/actor                         | -588     |
| loss/alpha                         | 0.0343   |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.5     |
| timestep                           | 314000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3038
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 6.63     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.0294  |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.5     |
| timestep                           | 315000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3058
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.00973 |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.9     |
| timestep                           | 316000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.71     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.0125  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.3     |
| timestep                           | 317000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -590     |
| loss/alpha                         | 0.0792   |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.9     |
| timestep                           | 318000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.4     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -590     |
| loss/alpha                         | -0.0041  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22.3     |
| timestep                           | 319000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3091
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -590     |
| loss/alpha                         | 0.0424   |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.7     |
| timestep                           | 320000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2977
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -590     |
| loss/alpha                         | -0.0517  |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.5     |
| timestep                           | 321000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -591     |
| loss/alpha                         | -0.0391  |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.5     |
| timestep                           | 322000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -591     |
| loss/alpha                         | 0.00502  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.1     |
| timestep                           | 323000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2961
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -592     |
| loss/alpha                         | -0.0108  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.3     |
| timestep                           | 324000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2835
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 6.08     |
| loss/actor                         | -592     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 20.1     |
| timestep                           | 325000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3112
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61       |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -593     |
| loss/alpha                         | 0.0211   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.6     |
| timestep                           | 326000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2988
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -593     |
| loss/alpha                         | 0.00771  |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.3     |
| timestep                           | 327000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3000
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -594     |
| loss/alpha                         | -0.0186  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.2     |
| timestep                           | 328000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -594     |
| loss/alpha                         | 0.0922   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 21       |
| timestep                           | 329000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3010
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -594     |
| loss/alpha                         | 0.0825   |
| loss/critic1                       | 22       |
| loss/critic2                       | 22.1     |
| timestep                           | 330000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3136
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -595     |
| loss/alpha                         | -0.00808 |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.1     |
| timestep                           | 331000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2901
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -595     |
| loss/alpha                         | -0.0341  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 21.9     |
| timestep                           | 332000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3085
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -595     |
| loss/alpha                         | -0.0363  |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.5     |
| timestep                           | 333000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3015
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -595     |
| loss/alpha                         | -0.0968  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 334000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2862
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -595     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.8     |
| timestep                           | 335000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 6.72     |
| loss/actor                         | -596     |
| loss/alpha                         | -0.00484 |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.5     |
| timestep                           | 336000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2795
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 4.27     |
| loss/actor                         | -596     |
| loss/alpha                         | 0.0636   |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 21.2     |
| timestep                           | 337000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3046
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -597     |
| loss/alpha                         | 0.00283  |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.4     |
| timestep                           | 338000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -597     |
| loss/alpha                         | 0.0243   |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.5     |
| timestep                           | 339000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2757
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -598     |
| loss/alpha                         | -0.142   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.1     |
| timestep                           | 340000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -598     |
| loss/alpha                         | 0.0124   |
| loss/critic1                       | 20       |
| loss/critic2                       | 20.1     |
| timestep                           | 341000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2922
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -598     |
| loss/alpha                         | 0.0664   |
| loss/critic1                       | 22       |
| loss/critic2                       | 22.1     |
| timestep                           | 342000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2737
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -598     |
| loss/alpha                         | 0.0377   |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.7     |
| timestep                           | 343000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -598     |
| loss/alpha                         | -0.00665 |
| loss/critic1                       | 21       |
| loss/critic2                       | 21       |
| timestep                           | 344000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3010
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -598     |
| loss/alpha                         | 0.0318   |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.2     |
| timestep                           | 345000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2854
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -598     |
| loss/alpha                         | -0.0735  |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 21.1     |
| timestep                           | 346000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -598     |
| loss/alpha                         | -0.0215  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 347000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -599     |
| loss/alpha                         | 0.00816  |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.7     |
| timestep                           | 348000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3010
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62       |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -599     |
| loss/alpha                         | -0.00142 |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22       |
| timestep                           | 349000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 8.05     |
| loss/actor                         | -600     |
| loss/alpha                         | -0.0168  |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.7     |
| timestep                           | 350000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -600     |
| loss/alpha                         | 0.0838   |
| loss/critic1                       | 22       |
| loss/critic2                       | 22.2     |
| timestep                           | 351000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -600     |
| loss/alpha                         | 0.00914  |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 21.3     |
| timestep                           | 352000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3100
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -600     |
| loss/alpha                         | -0.0784  |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.2     |
| timestep                           | 353000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3099
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -601     |
| loss/alpha                         | -0.01    |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.9     |
| timestep                           | 354000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2851
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -600     |
| loss/alpha                         | -0.00566 |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.2     |
| timestep                           | 355000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2948
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -601     |
| loss/alpha                         | 0.0489   |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.9     |
| timestep                           | 356000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -601     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.3     |
| timestep                           | 357000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3015
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -601     |
| loss/alpha                         | -0.062   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.6     |
| timestep                           | 358000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3100
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -601     |
| loss/alpha                         | 0.0158   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.7     |
| timestep                           | 359000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3016
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -601     |
| loss/alpha                         | -0.0777  |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 360000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3006
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -601     |
| loss/alpha                         | -0.0924  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.2     |
| timestep                           | 361000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2835
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -602     |
| loss/alpha                         | -0.0058  |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.2     |
| timestep                           | 362000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3048
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -603     |
| loss/alpha                         | -0.0629  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.8     |
| timestep                           | 363000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2948
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.5     |
| eval/normalized_episode_reward_std | 27.3     |
| loss/actor                         | -603     |
| loss/alpha                         | 0.0227   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.2     |
| timestep                           | 364000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3009
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.2     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.0492   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.1     |
| timestep                           | 365000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.0155   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.4     |
| timestep                           | 366000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 5.36     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.0728   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.7     |
| timestep                           | 367000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3054
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -604     |
| loss/alpha                         | -0.0239  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 368000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3052
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.0172   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.2     |
| timestep                           | 369000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -604     |
| loss/alpha                         | -0.0983  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.1     |
| timestep                           | 370000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3061
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -604     |
| loss/alpha                         | -0.0396  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 20       |
| timestep                           | 371000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3118
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -605     |
| loss/alpha                         | -0.0686  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.3     |
| timestep                           | 372000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3049
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -605     |
| loss/alpha                         | 0.0315   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.6     |
| timestep                           | 373000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3002
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -606     |
| loss/alpha                         | 0.0754   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 374000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3054
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 7.79     |
| loss/actor                         | -606     |
| loss/alpha                         | 0.0418   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.4     |
| timestep                           | 375000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -606     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.2     |
| timestep                           | 376000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2935
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -606     |
| loss/alpha                         | 0.0428   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.8     |
| timestep                           | 377000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -607     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.5     |
| timestep                           | 378000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3089
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -607     |
| loss/alpha                         | 0.0202   |
| loss/critic1                       | 20       |
| loss/critic2                       | 20.1     |
| timestep                           | 379000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3077
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -607     |
| loss/alpha                         | -0.0793  |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 380000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2838
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -607     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20       |
| timestep                           | 381000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3055
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -608     |
| loss/alpha                         | 0.014    |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20       |
| timestep                           | 382000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2878
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -608     |
| loss/alpha                         | 0.00129  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.9     |
| timestep                           | 383000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2822
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.1     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -609     |
| loss/alpha                         | 0.023    |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 384000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -609     |
| loss/alpha                         | -0.0083  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20.2     |
| timestep                           | 385000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3024
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -609     |
| loss/alpha                         | -0.0848  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 386000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2720
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.9     |
| eval/normalized_episode_reward_std | 28.1     |
| loss/actor                         | -609     |
| loss/alpha                         | 0.0107   |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.5     |
| timestep                           | 387000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3005
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -609     |
| loss/alpha                         | 0.0705   |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.6     |
| timestep                           | 388000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3171
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.0301  |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 21.1     |
| timestep                           | 389000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2975
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.0304  |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 390000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2977
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.0223  |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.9     |
| timestep                           | 391000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2788
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -610     |
| loss/alpha                         | 0.0946   |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.5     |
| timestep                           | 392000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.0263  |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.2     |
| timestep                           | 393000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.0096  |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 24.3     |
| timestep                           | 394000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 7.62     |
| loss/actor                         | -610     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 23.7     |
| loss/critic2                       | 23.8     |
| timestep                           | 395000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2874
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -610     |
| loss/alpha                         | 0.0289   |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.9     |
| timestep                           | 396000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2759
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -610     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 25.6     |
| loss/critic2                       | 25.5     |
| timestep                           | 397000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2914
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -609     |
| loss/alpha                         | 0.00627  |
| loss/critic1                       | 23.6     |
| loss/critic2                       | 23.7     |
| timestep                           | 398000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3000
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -609     |
| loss/alpha                         | -0.14    |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.4     |
| timestep                           | 399000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -609     |
| loss/alpha                         | -0.0239  |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.7     |
| timestep                           | 400000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3032
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -610     |
| loss/alpha                         | 0.00516  |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 22.1     |
| timestep                           | 401000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.6     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.0961  |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 402000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 5.21     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.134    |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.7     |
| timestep                           | 403000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2881
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0442   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 404000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2867
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -611     |
| loss/alpha                         | -0.0387  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.8     |
| timestep                           | 405000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2767
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0786   |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.5     |
| timestep                           | 406000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2909
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0143   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.7     |
| timestep                           | 407000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3029
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -611     |
| loss/alpha                         | -0.13    |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.5     |
| timestep                           | 408000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.5     |
| eval/normalized_episode_reward_std | 26.7     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0082   |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.7     |
| timestep                           | 409000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.0658  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20       |
| timestep                           | 410000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2750
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.6     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -612     |
| loss/alpha                         | 0.0762   |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20.1     |
| timestep                           | 411000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2822
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -612     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 21.1     |
| timestep                           | 412000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2834
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.0222  |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.8     |
| timestep                           | 413000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3021
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -612     |
| loss/alpha                         | 0.0124   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 21.1     |
| timestep                           | 414000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3015
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -612     |
| loss/alpha                         | 0.00831  |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.3     |
| timestep                           | 415000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.1     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.8     |
| timestep                           | 416000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3035
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.9     |
| eval/normalized_episode_reward_std | 27.6     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.0222  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.7     |
| timestep                           | 417000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3016
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -613     |
| loss/alpha                         | 0.0327   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.2     |
| timestep                           | 418000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3022
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -613     |
| loss/alpha                         | -0.054   |
| loss/critic1                       | 20       |
| loss/critic2                       | 20       |
| timestep                           | 419000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3147
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -613     |
| loss/alpha                         | -0.0449  |
| loss/critic1                       | 19       |
| loss/critic2                       | 19       |
| timestep                           | 420000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3021
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -613     |
| loss/alpha                         | -0.0572  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.9     |
| timestep                           | 421000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2988
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56       |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -613     |
| loss/alpha                         | -0.0692  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.4     |
| timestep                           | 422000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2785
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -613     |
| loss/alpha                         | 0.0452   |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.5     |
| timestep                           | 423000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2896
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -614     |
| loss/alpha                         | 0.0235   |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.3     |
| timestep                           | 424000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -614     |
| loss/alpha                         | 0.0951   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.5     |
| timestep                           | 425000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2914
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -614     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.7     |
| timestep                           | 426000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -614     |
| loss/alpha                         | 0.0684   |
| loss/critic1                       | 20       |
| loss/critic2                       | 20       |
| timestep                           | 427000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2913
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -614     |
| loss/alpha                         | -0.0118  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 428000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3119
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -614     |
| loss/alpha                         | 0.0444   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 429000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2963
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.4     |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.6     |
| timestep                           | 430000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2985
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.0559  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.8     |
| timestep                           | 431000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2989
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.00954 |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.9     |
| timestep                           | 432000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2893
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.0488   |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.5     |
| timestep                           | 433000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.0834  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.9     |
| timestep                           | 434000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3042
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -616     |
| loss/alpha                         | -0.0109  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 20       |
| timestep                           | 435000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.9     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -616     |
| loss/alpha                         | 0.0163   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.9     |
| timestep                           | 436000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -616     |
| loss/alpha                         | -0.0434  |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.3     |
| timestep                           | 437000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -616     |
| loss/alpha                         | -0.0474  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.9     |
| timestep                           | 438000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3063
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -616     |
| loss/alpha                         | 0.0652   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.4     |
| timestep                           | 439000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3003
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -617     |
| loss/alpha                         | -0.0333  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 20       |
| timestep                           | 440000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 5.62     |
| loss/actor                         | -617     |
| loss/alpha                         | -0.00152 |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.6     |
| timestep                           | 441000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3059
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -617     |
| loss/alpha                         | -0.00424 |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 442000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3080
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -617     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 443000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -617     |
| loss/alpha                         | 0.0716   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.3     |
| timestep                           | 444000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -618     |
| loss/alpha                         | 0.0273   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 445000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2886
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0215  |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.6     |
| timestep                           | 446000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 21       |
| loss/critic2                       | 21.1     |
| timestep                           | 447000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2928
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 6.22     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0183  |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.3     |
| timestep                           | 448000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3009
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.4     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0151   |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 21.4     |
| timestep                           | 449000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2891
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0534   |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.5     |
| timestep                           | 450000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -620     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.2     |
| timestep                           | 451000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2947
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.158    |
| loss/critic1                       | 22.2     |
| loss/critic2                       | 22       |
| timestep                           | 452000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2880
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0994   |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.4     |
| timestep                           | 453000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0211   |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.3     |
| timestep                           | 454000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2786
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0569  |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.7     |
| timestep                           | 455000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2814
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.00225  |
| loss/critic1                       | 22.9     |
| loss/critic2                       | 22.8     |
| timestep                           | 456000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2886
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0959  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22.4     |
| timestep                           | 457000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.8     |
| timestep                           | 458000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0248   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.6     |
| timestep                           | 459000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2768
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0433   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.9     |
| timestep                           | 460000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 9.86     |
| loss/actor                         | -621     |
| loss/alpha                         | -0.0749  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.4     |
| timestep                           | 461000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3132
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 8.33     |
| loss/actor                         | -622     |
| loss/alpha                         | -0.00841 |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.7     |
| timestep                           | 462000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2925
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -622     |
| loss/alpha                         | 0.0304   |
| loss/critic1                       | 22.5     |
| loss/critic2                       | 22.8     |
| timestep                           | 463000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3001
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -622     |
| loss/alpha                         | -0.104   |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.3     |
| timestep                           | 464000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3000
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -623     |
| loss/alpha                         | 0.0848   |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.8     |
| timestep                           | 465000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3058
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -623     |
| loss/alpha                         | -0.0715  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.5     |
| timestep                           | 466000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2981
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 8.49     |
| loss/actor                         | -623     |
| loss/alpha                         | -0.0482  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.8     |
| timestep                           | 467000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2982
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 7.22     |
| loss/actor                         | -623     |
| loss/alpha                         | 0.0421   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.4     |
| timestep                           | 468000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2867
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 24       |
| loss/actor                         | -623     |
| loss/alpha                         | 0.107    |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.1     |
| timestep                           | 469000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2853
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -623     |
| loss/alpha                         | 0.0104   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.4     |
| timestep                           | 470000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3106
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.3     |
| eval/normalized_episode_reward_std | 30       |
| loss/actor                         | -623     |
| loss/alpha                         | 0.00204  |
| loss/critic1                       | 20       |
| loss/critic2                       | 20.1     |
| timestep                           | 471000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2963
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -623     |
| loss/alpha                         | 0.0644   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.2     |
| timestep                           | 472000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3079
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -624     |
| loss/alpha                         | -0.0448  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.9     |
| timestep                           | 473000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2896
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -624     |
| loss/alpha                         | -0.0713  |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 474000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 9.46     |
| loss/actor                         | -624     |
| loss/alpha                         | -0.0283  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.7     |
| timestep                           | 475000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2917
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 7.91     |
| loss/actor                         | -625     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.7     |
| timestep                           | 476000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2893
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.0332  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.3     |
| timestep                           | 477000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2982
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -624     |
| loss/alpha                         | 0.0892   |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.9     |
| timestep                           | 478000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2793
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -624     |
| loss/alpha                         | -0.0753  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.8     |
| timestep                           | 479000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -624     |
| loss/alpha                         | -0.0312  |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 18.9     |
| timestep                           | 480000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -625     |
| loss/alpha                         | 0.0979   |
| loss/critic1                       | 19       |
| loss/critic2                       | 19       |
| timestep                           | 481000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.0473  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.6     |
| timestep                           | 482000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.154   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 483000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2826
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -625     |
| loss/alpha                         | 0.0763   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 18.9     |
| timestep                           | 484000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.0377  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.1     |
| timestep                           | 485000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3096
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.00848 |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.5     |
| timestep                           | 486000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3001
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.00873  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 487000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -627     |
| loss/alpha                         | 0.0726   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 18.9     |
| timestep                           | 488000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2914
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -627     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 489000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -627     |
| loss/alpha                         | 0.00964  |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 490000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.0172   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.3     |
| timestep                           | 491000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2882
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0666  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.2     |
| timestep                           | 492000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2736
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.59     |
| loss/actor                         | -629     |
| loss/alpha                         | 5.23e-05 |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 19       |
| timestep                           | 493000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3117
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0415  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 494000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0424   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 495000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2776
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0588  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.5     |
| timestep                           | 496000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3063
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0459   |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.8     |
| timestep                           | 497000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.037    |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.3     |
| timestep                           | 498000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.00214  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.4     |
| timestep                           | 499000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2862
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0114  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.7     |
| timestep                           | 500000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3089
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0201  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.5     |
| timestep                           | 501000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2878
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0591   |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.6     |
| timestep                           | 502000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0553  |
| loss/critic1                       | 20       |
| loss/critic2                       | 20       |
| timestep                           | 503000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2954
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.00946 |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.6     |
| timestep                           | 504000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3021
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.9     |
| timestep                           | 505000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2862
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.1     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.00837 |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.4     |
| timestep                           | 506000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2676
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.9     |
| eval/normalized_episode_reward_std | 25.6     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0155   |
| loss/critic1                       | 20       |
| loss/critic2                       | 20.1     |
| timestep                           | 507000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2852
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 508000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3042
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 6.59     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.00631 |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.2     |
| timestep                           | 509000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0228  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.5     |
| timestep                           | 510000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.00282  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.4     |
| timestep                           | 511000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3017
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.4     |
| timestep                           | 512000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2980
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.00598  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 513000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3088
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.88     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0568  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.7     |
| timestep                           | 514000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3053
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0151  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 515000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3078
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0112   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.6     |
| timestep                           | 516000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.00929 |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.1     |
| timestep                           | 517000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3005
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.00651  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.1     |
| timestep                           | 518000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3060
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -630     |
| loss/alpha                         | 0.00306  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 519000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3130
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.00966  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 520000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3137
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0442   |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.6     |
| timestep                           | 521000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3115
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.079   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 522000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3039
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0423   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 523000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3077
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.5     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0613  |
| loss/critic1                       | 18       |
| loss/critic2                       | 18.1     |
| timestep                           | 524000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2999
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0905   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.6     |
| timestep                           | 525000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 7.42     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0506  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.8     |
| timestep                           | 526000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3155
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0238  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.3     |
| timestep                           | 527000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0256  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.6     |
| timestep                           | 528000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3062
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0105  |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.8     |
| timestep                           | 529000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3052
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0285  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.1     |
| timestep                           | 530000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3092
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0752   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.7     |
| timestep                           | 531000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3066
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.00798 |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 532000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0384  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.6     |
| timestep                           | 533000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2954
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0107   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.6     |
| timestep                           | 534000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3177
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.000476 |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.1     |
| timestep                           | 535000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3092
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0176   |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.5     |
| timestep                           | 536000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0697   |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.6     |
| timestep                           | 537000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2938
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.98     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0767  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.8     |
| timestep                           | 538000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2854
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.041    |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.3     |
| timestep                           | 539000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2878
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0258  |
| loss/critic1                       | 20       |
| loss/critic2                       | 20.2     |
| timestep                           | 540000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2992
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.065    |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.4     |
| timestep                           | 541000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3093
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0733  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.9     |
| timestep                           | 542000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3061
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0169   |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.8     |
| timestep                           | 543000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3109
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.5     |
| timestep                           | 544000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -635     |
| loss/alpha                         | -0.0653  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 545000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.95     |
| loss/actor                         | -635     |
| loss/alpha                         | 0.0468   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 19.1     |
| timestep                           | 546000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -635     |
| loss/alpha                         | -0.0662  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.4     |
| timestep                           | 547000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2973
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -635     |
| loss/alpha                         | -0.0221  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.8     |
| timestep                           | 548000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3114
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -635     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 549000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2817
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -635     |
| loss/alpha                         | -0.0434  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.8     |
| timestep                           | 550000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3077
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -635     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 18       |
| timestep                           | 551000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3096
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.0385  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.5     |
| timestep                           | 552000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3170
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.0478   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 553000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3092
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -636     |
| loss/alpha                         | -0.0333  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.4     |
| timestep                           | 554000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3017
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 6.7      |
| loss/actor                         | -636     |
| loss/alpha                         | 0.077    |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.5     |
| timestep                           | 555000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.014    |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.9     |
| timestep                           | 556000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2991
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.00846 |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.2     |
| timestep                           | 557000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3127
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0341   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.9     |
| timestep                           | 558000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2922
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 2.61     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0111  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 559000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2958
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0383  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.7     |
| timestep                           | 560000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3029
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -638     |
| loss/alpha                         | 0.0605   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.5     |
| timestep                           | 561000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2879
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 8.51     |
| loss/actor                         | -638     |
| loss/alpha                         | 0.0352   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 18       |
| timestep                           | 562000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -638     |
| loss/alpha                         | -0.0173  |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 563000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3076
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.108    |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 564000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -639     |
| loss/alpha                         | -0.088   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.2     |
| timestep                           | 565000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3104
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.096    |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.1     |
| timestep                           | 566000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3027
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0773  |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 567000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3129
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 11.2     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0635  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.4     |
| timestep                           | 568000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0354   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.9     |
| timestep                           | 569000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2855
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0139   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 570000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2943
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 8.53     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 571000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3069
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.031    |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 572000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0885  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.2     |
| timestep                           | 573000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3162
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0207  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.3     |
| timestep                           | 574000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3004
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0318   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.5     |
| timestep                           | 575000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2913
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 9.67     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0752   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.2     |
| timestep                           | 576000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0231   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.8     |
| timestep                           | 577000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3046
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.00788  |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.8     |
| timestep                           | 578000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 9.64     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.8     |
| timestep                           | 579000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3104
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.043   |
| loss/critic1                       | 20       |
| loss/critic2                       | 20.2     |
| timestep                           | 580000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3229
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0968   |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 20.1     |
| timestep                           | 581000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2965
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.00104 |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.4     |
| timestep                           | 582000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3000
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.00237 |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.9     |
| timestep                           | 583000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2944
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0788  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 584000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3085
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.68     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0418   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.9     |
| timestep                           | 585000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0623   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.7     |
| timestep                           | 586000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.165   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.9     |
| timestep                           | 587000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2898
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0304  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.3     |
| timestep                           | 588000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3099
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.00782 |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.4     |
| timestep                           | 589000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3107
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0441   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.1     |
| timestep                           | 590000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.64     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 591000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3078
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0138   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.8     |
| timestep                           | 592000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0277   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.1     |
| timestep                           | 593000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3090
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0406  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.4     |
| timestep                           | 594000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2877
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0568   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.5     |
| timestep                           | 595000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3171
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0822  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 19.1     |
| timestep                           | 596000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2837
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0191  |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.9     |
| timestep                           | 597000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3142
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.1     |
| timestep                           | 598000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0302   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.4     |
| timestep                           | 599000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3087
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0456   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.9     |
| timestep                           | 600000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0221  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20.1     |
| timestep                           | 601000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0222  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.6     |
| timestep                           | 602000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0669   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.4     |
| timestep                           | 603000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3149
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0211   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 20       |
| timestep                           | 604000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2959
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0836  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.6     |
| timestep                           | 605000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3111
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.00915 |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 606000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3077
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.00732  |
| loss/critic1                       | 19       |
| loss/critic2                       | 19.1     |
| timestep                           | 607000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3027
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0615  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 608000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3125
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0374  |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 609000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3030
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.061    |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.9     |
| timestep                           | 610000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0886  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.2     |
| timestep                           | 611000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3116
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.103    |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.6     |
| timestep                           | 612000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0657  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.5     |
| timestep                           | 613000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3196
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0103   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.9     |
| timestep                           | 614000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3104
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -641     |
| loss/alpha                         | -0.026   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 19       |
| timestep                           | 615000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3003
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 6.45     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0728   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 616000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2950
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0509  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.6     |
| timestep                           | 617000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.8     |
| timestep                           | 618000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2918
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0733  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.8     |
| timestep                           | 619000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3074
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.00674  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.7     |
| timestep                           | 620000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2936
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.00982  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.5     |
| timestep                           | 621000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3040
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.118    |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 21       |
| timestep                           | 622000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0761  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.4     |
| timestep                           | 623000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3014
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0189   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.5     |
| timestep                           | 624000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3202
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 6.18     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.00694  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 625000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3006
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.00619  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.5     |
| timestep                           | 626000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0832  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 627000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3087
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.012    |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.3     |
| timestep                           | 628000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3062
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0273   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.6     |
| timestep                           | 629000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3001
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0971  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.7     |
| timestep                           | 630000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3117
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0306   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.2     |
| timestep                           | 631000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.64     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0525  |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.3     |
| timestep                           | 632000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3073
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -642     |
| loss/alpha                         | -0.00133 |
| loss/critic1                       | 20       |
| loss/critic2                       | 20       |
| timestep                           | 633000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3152
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.62     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0426   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.4     |
| timestep                           | 634000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0294   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.6     |
| timestep                           | 635000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3119
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0328  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.6     |
| timestep                           | 636000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3122
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0108   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 637000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3088
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 638000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3052
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.081    |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.7     |
| timestep                           | 639000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3054
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0329  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 640000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3002
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0878   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 641000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2985
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.00831 |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.2     |
| timestep                           | 642000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.088   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 643000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3140
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62       |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -643     |
| loss/alpha                         | 0.093    |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.7     |
| timestep                           | 644000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0634  |
| loss/critic1                       | 18       |
| loss/critic2                       | 18.1     |
| timestep                           | 645000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3066
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0191  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 646000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3038
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.00104  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 647000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3181
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0811   |
| loss/critic1                       | 19       |
| loss/critic2                       | 19.3     |
| timestep                           | 648000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3149
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0874  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.6     |
| timestep                           | 649000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3072
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 650000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2964
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0764   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.1     |
| timestep                           | 651000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3025
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0411  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 652000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.061   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.3     |
| timestep                           | 653000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.159    |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.7     |
| timestep                           | 654000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0542  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.7     |
| timestep                           | 655000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3056
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0233  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.3     |
| timestep                           | 656000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3049
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0357  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.5     |
| timestep                           | 657000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3100
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0269  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.4     |
| timestep                           | 658000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3109
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -645     |
| loss/alpha                         | -0.106   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.2     |
| timestep                           | 659000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3019
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.4     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0416  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.8     |
| timestep                           | 660000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3029
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.137    |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.8     |
| timestep                           | 661000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.00332  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.5     |
| timestep                           | 662000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3090
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0764  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.6     |
| timestep                           | 663000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3057
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 6.89     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0263   |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20.1     |
| timestep                           | 664000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2927
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0539  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 19       |
| timestep                           | 665000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3055
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -645     |
| loss/alpha                         | 0.024    |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.3     |
| timestep                           | 666000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3225
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0405   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.6     |
| timestep                           | 667000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0733  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 19.1     |
| timestep                           | 668000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0443   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.4     |
| timestep                           | 669000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3146
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 2.64     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.00382  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.1     |
| timestep                           | 670000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2986
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0442  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.9     |
| timestep                           | 671000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.00419  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 672000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3086
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0839   |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.5     |
| timestep                           | 673000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0263  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.2     |
| timestep                           | 674000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3054
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0408  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.4     |
| timestep                           | 675000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3149
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0195  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.5     |
| timestep                           | 676000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3059
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0479   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.5     |
| timestep                           | 677000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3152
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0134  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 678000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3179
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0731   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.7     |
| timestep                           | 679000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.16    |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.3     |
| timestep                           | 680000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3177
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.162    |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.7     |
| timestep                           | 681000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3124
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0193  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.9     |
| timestep                           | 682000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3022
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.00161  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.6     |
| timestep                           | 683000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3080
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0215  |
| loss/critic1                       | 20       |
| loss/critic2                       | 20.1     |
| timestep                           | 684000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0874  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.8     |
| timestep                           | 685000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3122
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.033   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 686000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3213
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0284   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 18       |
| timestep                           | 687000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3325
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0341   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.7     |
| timestep                           | 688000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3152
-----------------------------------------------------------------------------------
| alpha                              | 0.168     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 60.5      |
| eval/normalized_episode_reward_std | 27.1      |
| loss/actor                         | -647      |
| loss/alpha                         | -0.000728 |
| loss/critic1                       | 18.2      |
| loss/critic2                       | 18.3      |
| timestep                           | 689000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3016
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -647     |
| loss/alpha                         | 0.00869  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.6     |
| timestep                           | 690000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3098
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0162   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 20.1     |
| timestep                           | 691000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3034
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 8.21     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0554  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.8     |
| timestep                           | 692000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0208  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.1     |
| timestep                           | 693000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3096
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0275   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.8     |
| timestep                           | 694000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2975
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 27.1     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0408   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 695000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3198
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0361   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.7     |
| timestep                           | 696000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3138
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0289  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 697000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3222
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0682  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 698000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3067
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0298   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.6     |
| timestep                           | 699000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0483  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.6     |
| timestep                           | 700000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3166
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.4     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0206  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.5     |
| timestep                           | 701000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2893
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 8.41     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0277   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.7     |
| timestep                           | 702000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2980
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0589   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 703000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3089
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0258  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 18.2     |
| timestep                           | 704000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3042
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17.1     |
| timestep                           | 705000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3167
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0684   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 706000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3109
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.00546 |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 707000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3167
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0836  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 708000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3098
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0447   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.5     |
| timestep                           | 709000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3071
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0866   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.7     |
| timestep                           | 710000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3130
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0795  |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 711000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3082
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0519   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.2     |
| timestep                           | 712000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3045
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.00191  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.4     |
| timestep                           | 713000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2986
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0607  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.2     |
| timestep                           | 714000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3074
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0384   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.5     |
| timestep                           | 715000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3143
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.131   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 716000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2936
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0214  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 717000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3088
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0191   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 718000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3073
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0301   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 719000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.00722 |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 720000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3025
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0301   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 721000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3061
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0388   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 722000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3115
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.043   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.8     |
| timestep                           | 723000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3020
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0167   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 724000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3003
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 4.94     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0684   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 725000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0651  |
| loss/critic1                       | 19       |
| loss/critic2                       | 19.1     |
| timestep                           | 726000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3104
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 19       |
| timestep                           | 727000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3048
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0669   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.4     |
| timestep                           | 728000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3043
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0238   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.2     |
| timestep                           | 729000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0572   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.6     |
| timestep                           | 730000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3042
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.4     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0643   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.9     |
| timestep                           | 731000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 732000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3090
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0313  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.7     |
| timestep                           | 733000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0669  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 734000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3138
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0743  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 735000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3091
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.5     |
| timestep                           | 736000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3035
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0718  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.5     |
| timestep                           | 737000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3117
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0337  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 738000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3067
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -651     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 739000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0654   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 740000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0592  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.4     |
| timestep                           | 741000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0154  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 742000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.022   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 743000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.113   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 744000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2921
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0466  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 745000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3015
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.12     |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 746000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3086
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.00138  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.8     |
| timestep                           | 747000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3001
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 7.5      |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0425   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.4     |
| timestep                           | 748000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3002
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 3.71     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0507   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.3     |
| timestep                           | 749000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3001
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0176   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 750000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3186
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.74     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0848  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 751000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3128
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0176  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 752000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3081
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0515   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 753000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3094
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0323  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 754000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3098
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0142   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 755000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0125  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 756000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3260
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0207   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.2     |
| timestep                           | 757000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3123
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0581  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 758000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2862
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.58     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0996   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.4     |
| timestep                           | 759000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3099
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0379  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 760000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3021
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0524  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 761000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0553  |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 762000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0247  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 763000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3116
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 5.12     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.095    |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 764000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3030
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0916   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.8     |
| timestep                           | 765000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3035
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -654     |
| loss/alpha                         | -0.056   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.4     |
| timestep                           | 766000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0437  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.2     |
| timestep                           | 767000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3102
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0205  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.5     |
| timestep                           | 768000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0641  |
| loss/critic1                       | 18       |
| loss/critic2                       | 18.2     |
| timestep                           | 769000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3096
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0415  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.6     |
| timestep                           | 770000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3057
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0836   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 771000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0905   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 772000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 773000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3079
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00924 |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 774000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3163
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0612   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 775000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3053
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0519   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 776000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3050
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0617  |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 777000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3053
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.039   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 778000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2999
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0451   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 779000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3090
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 11.2     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0566  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 780000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0549  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.4     |
| timestep                           | 781000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3202
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.077   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 782000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3048
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0272  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 783000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0276   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 784000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3096
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0313   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 785000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3110
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0321  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.7     |
| timestep                           | 786000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00718 |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 787000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0622   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 788000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3119
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.9     |
| eval/normalized_episode_reward_std | 28.1     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0436  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 789000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2826
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0136   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.9     |
| timestep                           | 790000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.6     |
| timestep                           | 791000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3112
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0496   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 18       |
| timestep                           | 792000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3062
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0491  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.2     |
| timestep                           | 793000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3128
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.096    |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.2     |
| timestep                           | 794000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0686  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 795000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3107
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 796000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3118
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0448  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.2     |
| timestep                           | 797000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
-----------------------------------------------------------------------------------
| alpha                              | 0.163     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 77.1      |
| eval/normalized_episode_reward_std | 2.84      |
| loss/actor                         | -652      |
| loss/alpha                         | -0.000775 |
| loss/critic1                       | 16.8      |
| loss/critic2                       | 16.8      |
| timestep                           | 798000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3143
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0431   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 799000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3182
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0734  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 800000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3162
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.00175 |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 801000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0841  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.3     |
| timestep                           | 802000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3064
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.00489  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 803000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0319   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 804000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0115   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 805000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3128
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 4.47     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.00359 |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.5     |
| timestep                           | 806000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.117    |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 807000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3186
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.8     |
| timestep                           | 808000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0841  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 809000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3167
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 2.62     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.032    |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 810000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3088
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.084   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.4     |
| timestep                           | 811000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 812000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3045
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 5.98     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.104    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.7     |
| timestep                           | 813000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00685  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 16       |
| timestep                           | 814000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3078
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.017   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.8     |
| timestep                           | 815000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0895   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.4     |
| timestep                           | 816000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0242   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 817000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0163  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.5     |
| timestep                           | 818000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.00442 |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 819000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3143
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0317  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 820000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3057
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0544   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 821000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3162
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0419  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 822000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3195
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0114   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.6     |
| timestep                           | 823000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3085
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0384  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 824000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3283
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.9      |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0356  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 825000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3105
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00942  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 826000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0411   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 827000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3035
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 828000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3155
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 4.03     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00583 |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 829000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3062
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.89     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0328  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 830000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3101
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0813   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 831000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00972  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 832000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3020
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0414  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 833000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3110
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0364   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 834000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3104
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0117  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 835000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3050
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -655     |
| loss/alpha                         | 1.4e-05  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 836000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0919   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.7     |
| timestep                           | 837000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3144
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0515  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 838000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3225
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0439  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 839000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3044
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0441  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 840000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2981
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 841000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3030
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0011  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 842000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3170
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0757   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 843000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3057
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0639   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.8     |
| timestep                           | 844000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3073
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0384   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 845000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3123
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 846000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3093
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0135   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 847000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0198  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.8     |
| timestep                           | 848000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3160
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0926   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 849000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3090
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 7.49     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.101   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.4     |
| timestep                           | 850000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3160
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0394   |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 851000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3240
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0183  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 852000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3066
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0523  |
| loss/critic1                       | 17       |
| loss/critic2                       | 17.2     |
| timestep                           | 853000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3152
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0159   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.6     |
| timestep                           | 854000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3148
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0382  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 855000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3114
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0459  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 856000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3158
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0731   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 19       |
| timestep                           | 857000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2875
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.12    |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.6     |
| timestep                           | 858000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3057
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0221  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.9     |
| timestep                           | 859000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3102
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0884   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.2     |
| timestep                           | 860000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3138
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.22     |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 861000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0245  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 862000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0217  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 863000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3254
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0636  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 864000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3084
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0785  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 865000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3097
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0336   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 866000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3189
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.00259 |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 867000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3102
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0131   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 868000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3224
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0164   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 869000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3093
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0247   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.7     |
| timestep                           | 870000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3021
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0533  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 871000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3311
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0666  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 872000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2850
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.8      |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0296   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.8     |
| timestep                           | 873000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2928
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0735   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 874000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3098
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0341   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 875000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3146
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0701   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.3     |
| timestep                           | 876000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3161
-----------------------------------------------------------------------------------
| alpha                              | 0.168     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 73.4      |
| eval/normalized_episode_reward_std | 3.3       |
| loss/actor                         | -657      |
| loss/alpha                         | -0.000953 |
| loss/critic1                       | 18.7      |
| loss/critic2                       | 18.8      |
| timestep                           | 877000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3146
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.00107  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.2     |
| timestep                           | 878000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3075
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0119   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 879000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3152
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.4     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.073   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 880000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3155
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 881000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3206
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0465   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.5     |
| timestep                           | 882000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3088
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0477  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.9     |
| timestep                           | 883000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0667  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 18       |
| timestep                           | 884000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3159
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0142   |
| loss/critic1                       | 18       |
| loss/critic2                       | 18.1     |
| timestep                           | 885000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3107
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 886000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0226   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 887000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3206
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.152    |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 888000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3240
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0568  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 17       |
| timestep                           | 889000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.00448 |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 890000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3190
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0253   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.9     |
| timestep                           | 891000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3059
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.032   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 892000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3033
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0472  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 893000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3136
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -658     |
| loss/alpha                         | 0.125    |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 894000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.071    |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 895000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3019
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.00975  |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 896000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3062
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0722  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 897000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3052
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0279   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 898000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3018
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0107   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 899000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3151
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0218   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 900000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3057
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.117   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.7     |
| timestep                           | 901000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3048
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 6.97     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0123  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 902000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3206
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62       |
| eval/normalized_episode_reward_std | 26.7     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0597   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 903000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2966
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0628  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 904000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3081
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0692  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 905000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3123
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0217   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 906000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0398   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 907000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -658     |
| loss/alpha                         | 0.00767  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17       |
| timestep                           | 908000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3329
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.00267 |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17       |
| timestep                           | 909000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3120
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0118  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 910000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3163
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.9     |
| timestep                           | 911000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.94     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0733   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 912000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3110
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0171  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.5     |
| timestep                           | 913000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3005
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.00963 |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.7     |
| timestep                           | 914000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 6.29     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0879  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 915000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3038
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0444  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 916000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3212
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0092  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 917000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3201
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0465  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 918000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3093
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.147   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.5     |
| timestep                           | 919000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3035
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0187  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 920000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3192
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0269  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 921000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3049
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0645   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17.1     |
| timestep                           | 922000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3080
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0364   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.5     |
| timestep                           | 923000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3268
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.00685 |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 924000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2960
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0831   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 925000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3124
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0438  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 926000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0477  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.5     |
| timestep                           | 927000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3125
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 928000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3028
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0458   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 929000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3123
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0426  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 930000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3182
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.69     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.00483  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 931000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3141
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0435  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 932000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3241
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0443   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 933000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 5.84     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0494  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 934000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0907   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 935000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3153
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0283  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.2     |
| timestep                           | 936000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0609  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.8     |
| timestep                           | 937000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3100
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.133   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 938000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0885   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 18       |
| timestep                           | 939000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3300
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.106    |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.4     |
| timestep                           | 940000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3167
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0334   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 941000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3022
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.035   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 942000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3039
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17.1     |
| timestep                           | 943000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3089
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0434   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 944000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2982
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.059   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.6     |
| timestep                           | 945000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3111
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.021   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 946000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.00239  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 947000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3145
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.00947 |
| loss/critic1                       | 17       |
| loss/critic2                       | 17.1     |
| timestep                           | 948000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.00657 |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17       |
| timestep                           | 949000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0259   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17       |
| timestep                           | 950000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3122
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0628   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 951000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3192
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0476  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 952000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3201
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0743  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 953000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0752   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 954000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3233
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.00603 |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 955000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3138
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0612   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.8     |
| timestep                           | 956000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2968
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0648   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 957000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0254   |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.8     |
| timestep                           | 958000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3185
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0218   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.7     |
| timestep                           | 959000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3137
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.045   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 960000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0622  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 961000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3134
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 962000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3124
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0943  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 963000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3027
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0202  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.4     |
| timestep                           | 964000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.00357  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.6     |
| timestep                           | 965000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0467  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 966000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3253
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0678  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.9     |
| timestep                           | 967000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3110
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 4.04     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0766   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 968000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3326
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.7     |
| timestep                           | 969000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3193
-----------------------------------------------------------------------------------
| alpha                              | 0.162     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 71.8      |
| eval/normalized_episode_reward_std | 12.8      |
| loss/actor                         | -660      |
| loss/alpha                         | -0.000267 |
| loss/critic1                       | 20.1      |
| loss/critic2                       | 20.2      |
| timestep                           | 970000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0708   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 971000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3047
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0825  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.7     |
| timestep                           | 972000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3013
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.00728  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.5     |
| timestep                           | 973000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3161
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0868   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 974000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2992
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0339  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.4     |
| timestep                           | 975000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3383
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.03    |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 976000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3291
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0915  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 19       |
| timestep                           | 977000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3269
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.032   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 978000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.9     |
| timestep                           | 979000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0559  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.7     |
| timestep                           | 980000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3115
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.172    |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 981000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3079
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.00233 |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 982000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0209   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 983000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3075
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0291  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 984000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0203   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.3     |
| timestep                           | 985000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3238
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0102   |
| loss/critic1                       | 23.6     |
| loss/critic2                       | 23.9     |
| timestep                           | 986000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3099
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.052   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.4     |
| timestep                           | 987000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3304
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 9.74     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0696   |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 22.2     |
| timestep                           | 988000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3072
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0562  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 19       |
| timestep                           | 989000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3325
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.2     |
| timestep                           | 990000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -660     |
| loss/alpha                         | -0.097   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 991000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3109
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0413  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 992000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3020
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.00341 |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 993000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.5     |
| timestep                           | 994000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0443   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17.1     |
| timestep                           | 995000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3072
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0162  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 996000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 6.29     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00341 |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 997000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3099
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 4.02     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0332  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 998000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3020
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 9.89     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0653   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 999000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3093
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0421   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1000000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0652   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.4     |
| timestep                           | 1001000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3215
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0461   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 1002000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3115
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0412  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1003000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3078
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0594  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.4     |
| timestep                           | 1004000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3047
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0281  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 1005000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3210
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0866  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.7     |
| timestep                           | 1006000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3041
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0344  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1007000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0195   |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 1008000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3121
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00463 |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1009000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3129
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0971   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 1010000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3158
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.75     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0317   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 1011000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3174
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.00984  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1012000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2986
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0869  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 1013000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3079
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0892   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 1014000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.035    |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.6     |
| timestep                           | 1015000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3198
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0124   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.6     |
| timestep                           | 1016000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3096
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00589 |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1017000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3206
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0373  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1018000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3368
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 25.5     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0121   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1019000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3132
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 7.28     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0743  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1020000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3181
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0437   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.9     |
| timestep                           | 1021000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0837  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 1022000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3129
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0465  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 1023000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0211   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1024000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3042
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0367   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 16       |
| timestep                           | 1025000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0201   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.3     |
| timestep                           | 1026000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3252
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0366   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 1027000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0375   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 1028000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3159
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1029000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3150
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.00906  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 1030000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3063
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.059   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.3     |
| timestep                           | 1031000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 8.91     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0638  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.7     |
| timestep                           | 1032000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3065
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.09     |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 1033000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3358
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0267   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1034000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3154
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.139   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.5     |
| timestep                           | 1035000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3192
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0736   |
| loss/critic1                       | 17       |
| loss/critic2                       | 17.1     |
| timestep                           | 1036000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.00392  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.6     |
| timestep                           | 1037000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3181
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.00169  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1038000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3044
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0904   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 1039000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1040000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0353  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1041000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0493  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.7     |
| timestep                           | 1042000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0333  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1043000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1044000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3124
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0826  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1045000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3082
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0892   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1046000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3144
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0315  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 1047000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3303
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0807   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1048000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.021    |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1049000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3118
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0686   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.6     |
| timestep                           | 1050000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3001
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.02     |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 1051000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1052000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2982
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.166   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1053000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3086
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0039  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1054000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3007
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0684   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 1055000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 4.22     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0326   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1056000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0514   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.5     |
| timestep                           | 1057000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0728  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1058000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3108
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00417 |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1059000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.083   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1060000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1061000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3119
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.00347  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1062000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0401   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1063000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3136
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0997   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1064000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0668  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1065000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3063
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0545   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 1066000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 25.5     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0491   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1067000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3079
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00615 |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.7     |
| timestep                           | 1068000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3108
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0771   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1069000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0172  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1070000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0428  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1071000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3186
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0893   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1072000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3044
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0946  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1073000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3159
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.103    |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1074000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3066
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0423   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1075000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3081
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.121   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1076000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3092
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0859  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1077000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0831  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1078000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3142
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00582  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1079000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3161
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0328  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 1080000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.056    |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1081000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3124
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.067    |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 1082000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3019
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0181   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1083000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0403  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1084000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3215
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.9      |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1085000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3116
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 9.38     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0626   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1086000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3096
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.76     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.00174 |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 1087000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3198
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 6.08     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.00156 |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.3     |
| timestep                           | 1088000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3032
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0159   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1089000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3080
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.78     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0153  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1090000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3231
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0687  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1091000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3129
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0348  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1092000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3151
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0807   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1093000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00069  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1094000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3032
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0147  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1095000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3258
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0509   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1096000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3313
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00776  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1097000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3151
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0156  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1098000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0682   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1099000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3114
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00446  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1100000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3015
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.64     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1101000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3143
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.004   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1102000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3127
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0323   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1103000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3231
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -664     |
| loss/alpha                         | -0.049   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.7     |
| timestep                           | 1104000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.2     |
| eval/normalized_episode_reward_std | 25.8     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.122    |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.5     |
| timestep                           | 1105000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0688  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.7     |
| timestep                           | 1106000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.013   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1107000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3174
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 5.08     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0197  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1108000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3003
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.023   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 1109000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0608  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1110000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0455  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1111000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3165
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.1     |
| eval/normalized_episode_reward_std | 25       |
| loss/actor                         | -664     |
| loss/alpha                         | 0.128    |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1112000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3178
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0791   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 1113000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3206
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0593   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 1114000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3116
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0162   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.1     |
| timestep                           | 1115000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3240
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0387  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 1116000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3078
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 1117000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0373   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 1118000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3134
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0269  |
| loss/critic1                       | 17       |
| loss/critic2                       | 17.1     |
| timestep                           | 1119000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0649  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1120000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3052
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0641  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1121000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3079
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0654   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.8     |
| timestep                           | 1122000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3081
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0692   |
| loss/critic1                       | 17       |
| loss/critic2                       | 17.1     |
| timestep                           | 1123000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.79     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0157   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 1124000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0505   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1125000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 17       |
| loss/critic2                       | 17.1     |
| timestep                           | 1126000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3111
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0314   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 1127000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3155
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 5.99     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1128000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3164
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0586  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 1129000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0401  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1130000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3101
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.00731 |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1131000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3100
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0286  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1132000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3185
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1133000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 9.47     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0044   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 1134000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 9.25     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00276 |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1135000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3020
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0209  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1136000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3078
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0168  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1137000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0321  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.7     |
| timestep                           | 1138000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3194
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0243   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.3     |
| timestep                           | 1139000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2977
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0373  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1140000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3117
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0535  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1141000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
-----------------------------------------------------------------------------------
| alpha                              | 0.159     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 67.1      |
| eval/normalized_episode_reward_std | 20.7      |
| loss/actor                         | -663      |
| loss/alpha                         | -0.000875 |
| loss/critic1                       | 16.8      |
| loss/critic2                       | 16.7      |
| timestep                           | 1142000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3101
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0073   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1143000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0889   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1144000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3121
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00659 |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1145000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3210
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.05    |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1146000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3140
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0856   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1147000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3176
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0203   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1148000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3203
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0246   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 1149000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3190
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.105   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.3     |
| timestep                           | 1150000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3260
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0636  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1151000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3154
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0277  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1152000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3224
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0488   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1153000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.00622 |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 1154000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3156
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0321  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1155000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3222
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0193   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 1156000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3026
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 5.7      |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0903  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.7     |
| timestep                           | 1157000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3153
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0787  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1158000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.064    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.7     |
| timestep                           | 1159000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.169    |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1160000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3069
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.00436 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1161000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3032
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0176   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1162000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3195
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 6.44     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0181   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1163000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3077
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0365  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1164000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3137
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 5.94     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0842  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1165000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0957   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 1166000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3086
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0179  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.8     |
| timestep                           | 1167000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3092
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00601  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1168000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3119
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.99     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.046    |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 1169000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0524  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1170000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3234
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.103    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1171000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.131   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1172000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3230
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.00481 |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1173000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3030
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 9.41     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0251  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 1174000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3253
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0568   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1175000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0581   |
| loss/critic1                       | 18       |
| loss/critic2                       | 18.1     |
| timestep                           | 1176000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3091
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0219  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1177000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3190
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1178000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0219   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1179000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3099
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.075    |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 1180000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.085   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1181000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3165
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00132 |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1182000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3110
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.7     |
| timestep                           | 1183000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3066
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00604 |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17.1     |
| timestep                           | 1184000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3097
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79       |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0846  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 1185000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3296
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.103    |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1186000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3167
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.6      |
| loss/actor                         | -662     |
| loss/alpha                         | 0.000401 |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1187000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.00275  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1188000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3124
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0278   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 1189000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3163
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0725  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1190000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3187
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.026    |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.7     |
| timestep                           | 1191000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0597  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.3     |
| timestep                           | 1192000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3224
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0227  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 1193000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3172
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0454  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1194000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3177
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0461   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1195000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0724   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1196000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3234
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.031   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1197000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3114
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0586   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 1198000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2896
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0257   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1199000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3057
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0264  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 1200000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3127
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00749 |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.3     |
| timestep                           | 1201000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0357  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1202000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3125
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0333  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1203000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3152
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0824   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 1204000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3033
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0457   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 1205000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0441   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1206000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00733  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.5     |
| timestep                           | 1207000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3067
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.101   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17.1     |
| timestep                           | 1208000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3070
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 8.52     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00163  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.5     |
| timestep                           | 1209000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3075
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0912   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 1210000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3092
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0687  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.3     |
| timestep                           | 1211000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3229
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 4.16     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0762  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 1212000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3070
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.013    |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1213000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.93     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00613 |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1214000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3242
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0268  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1215000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0212  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1216000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3136
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00389  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1217000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0729   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1218000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3155
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0133   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1219000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2986
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 4.86     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.105   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1220000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3084
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0576  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1221000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.129    |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17       |
| timestep                           | 1222000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3324
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 4.44     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.6     |
| timestep                           | 1223000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3092
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0388  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 1224000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3061
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 5.11     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.039   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1225000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3118
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0229   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1226000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3421
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.073    |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 1227000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3429
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0355   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1228000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3164
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0719  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1229000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00353 |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 1230000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3083
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -664     |
| loss/alpha                         | -0.134   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1231000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0492   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1232000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3430
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0137   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1233000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0191   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1234000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.3     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0529   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1235000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1236000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3150
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 9.29     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0131  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1237000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3184
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00711  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 1238000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.073   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1239000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3259
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0136   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1240000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3172
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00911  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1241000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3061
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0175   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1242000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3070
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17.1     |
| timestep                           | 1243000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.5     |
| timestep                           | 1244000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0314   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 1245000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3051
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0724  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.7     |
| timestep                           | 1246000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0886   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1247000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3053
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0121   |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 1248000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3358
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 1249000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 6.72     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.098   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1250000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3024
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0319   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1251000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3064
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0313   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1252000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3106
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0779   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1253000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3264
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0423  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1254000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3185
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0211   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 1255000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3293
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0458   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1256000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3303
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0612   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1257000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3189
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0913   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1258000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0294   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1259000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0954  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1260000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3130
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0592   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1261000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.018   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 1262000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3152
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.83     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.051   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1263000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.6     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.107   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1264000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.143    |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1265000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0346  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1266000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3252
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.061   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1267000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3211
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0161  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1268000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3124
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.000307 |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1269000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3190
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 7.92     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0246   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1270000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3155
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0503   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 1271000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0581  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1272000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3182
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0533   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1273000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3086
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0378  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1274000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3093
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0887  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.2     |
| timestep                           | 1275000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3122
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 6.14     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0498   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1276000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.034   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 1277000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3088
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0672   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1278000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3164
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00278 |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1279000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3088
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0593   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.2     |
| timestep                           | 1280000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3213
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0465  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1281000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3300
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0487  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1282000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3098
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0147  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 1283000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00372 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1284000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3319
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0103   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1285000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.108    |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1286000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3320
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 4.46     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0594  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1287000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3327
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0523  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1288000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0712   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1289000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3213
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0211   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1290000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0254  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1291000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3193
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0646   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.2     |
| timestep                           | 1292000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3212
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.052   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1293000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3073
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.047   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1294000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3078
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0289  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1295000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0609  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1296000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0142  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1297000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3209
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0128   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.8     |
| timestep                           | 1298000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3206
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0478   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1299000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 7.52     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0219  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1300000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3246
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0102   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1301000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0244   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1302000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3060
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.073    |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1303000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3093
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0115   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1304000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 9.91     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0428  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1305000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3373
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00409 |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1306000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3159
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.124   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1307000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3147
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0636   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.6     |
| timestep                           | 1308000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3098
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0255   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 1309000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3394
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.145   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1310000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3248
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0394   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.4     |
| timestep                           | 1311000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0744   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.6     |
| timestep                           | 1312000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0182  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1313000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3187
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0311   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1314000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3201
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.118    |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1315000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00666 |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1316000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3078
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0379  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1317000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3125
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0141  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1318000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3335
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1319000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0396  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1320000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3245
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.146   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.3     |
| timestep                           | 1321000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3177
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0321  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1322000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3404
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0689   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1323000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3152
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0226  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1324000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1325000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3125
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0304   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.7     |
| timestep                           | 1326000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.94     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0827   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1327000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3077
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0711   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1328000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3091
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0202  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1329000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3194
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00278 |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1330000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0039   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 1331000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0287   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1332000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.1     |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1333000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
-----------------------------------------------------------------------------------
| alpha                              | 0.153     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 74.9      |
| eval/normalized_episode_reward_std | 2.68      |
| loss/actor                         | -663      |
| loss/alpha                         | -0.000612 |
| loss/critic1                       | 14.9      |
| loss/critic2                       | 14.9      |
| timestep                           | 1334000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0869  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1335000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3258
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0297   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1336000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3062
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0534   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1337000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3128
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0444  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1338000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3215
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0355   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1339000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3230
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0784   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1340000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00047  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1341000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3063
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.142   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1342000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3430
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00294  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1343000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3057
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.3     |
| eval/normalized_episode_reward_std | 25.5     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.13     |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.6     |
| timestep                           | 1344000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2966
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.121    |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1345000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3108
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.087    |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 1346000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3166
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.186   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1347000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3154
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 8.04     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00966 |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 1348000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3130
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.017   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 16       |
| timestep                           | 1349000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3201
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0266  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1350000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3148
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00771 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1351000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.118    |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1352000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3243
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0927  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1353000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0205  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1354000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.092   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1355000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3163
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0427   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1356000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3161
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0718   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1357000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3034
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 8.07     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0824   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1358000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1359000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3293
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00401 |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1360000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3222
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00468 |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1361000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3078
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0679  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1362000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3032
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0592  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.2     |
| timestep                           | 1363000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.84     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00206 |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1364000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3098
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.4     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0988   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 1365000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3143
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0489   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1366000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3165
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1367000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3075
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0146  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1368000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3190
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.00474 |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1369000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3185
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0893  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1370000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3166
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 6.41     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0388  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1371000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3141
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.02    |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1372000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3052
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1373000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3055
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0697   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1374000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3098
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0314  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1375000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3033
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0872  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1376000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 1377000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3031
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0921   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1378000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3073
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1379000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0621   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1380000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3268
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0566  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1381000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3072
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0918   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 1382000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3176
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0669  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1383000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3012
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0961   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1384000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0235  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1385000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3344
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0586  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1386000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3181
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0143   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1387000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3193
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0386  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1388000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3233
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.104   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1389000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.161    |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1390000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.64     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.000356 |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1391000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3189
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 10.2     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0339   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1392000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0178  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1393000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3198
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0234   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1394000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3117
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0537  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1395000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3028
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 28.3     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0822  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1396000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3161
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.045    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 1397000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3062
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0503   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1398000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3132
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0462  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1399000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3120
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0851   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1400000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3132
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0676  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1401000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3283
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0272  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1402000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3198
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.8     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00224  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1403000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.115    |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1404000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3231
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -664     |
| loss/alpha                         | -0.106   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1405000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3103
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0551   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 1406000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3110
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.058   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1407000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3102
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.098   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1408000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3238
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0287   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1409000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3143
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 9.26     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0306  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1410000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3181
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.11     |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1411000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.000233 |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1412000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3074
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00561  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1413000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3109
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.107    |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 1414000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3189
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0137  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1415000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3123
-----------------------------------------------------------------------------------
| alpha                              | 0.158     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 65.9      |
| eval/normalized_episode_reward_std | 25        |
| loss/actor                         | -666      |
| loss/alpha                         | -0.000346 |
| loss/critic1                       | 14.7      |
| loss/critic2                       | 14.6      |
| timestep                           | 1416000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3201
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0502   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 1417000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.9     |
| eval/normalized_episode_reward_std | 31.1     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0214  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1418000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3117
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0474   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1419000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3158
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00198 |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.9     |
| timestep                           | 1420000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0784  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 1421000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3234
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.128   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1422000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00904  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1423000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0572  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1424000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3200
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 5.36     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0385   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1425000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0106   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1426000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3317
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0647   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1427000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00431  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1428000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0453   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1429000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3144
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.00167 |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1430000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.012   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1431000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3107
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0523  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1432000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0357   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1433000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3123
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.036   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1434000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3118
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0449   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1435000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3116
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0312   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1436000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0571   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1437000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 4.99     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0153  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1438000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00564  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1439000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3089
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 9.04     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0251  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1440000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0734  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1441000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3230
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0289   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1442000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00855  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1443000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3215
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0688   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1444000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 6.13     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0951  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1445000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3187
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0178   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1446000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1447000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.000623 |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1448000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 8.89     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0122   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 1449000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3148
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0339  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.7     |
| timestep                           | 1450000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3198
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0311   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.5     |
| timestep                           | 1451000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3151
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0812  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 1452000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0955  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.5     |
| timestep                           | 1453000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3313
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 9.54     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0677  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1454000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3241
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 4.71     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.126    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 1455000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3171
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.124    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1456000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3229
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0702   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1457000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0317  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1458000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3224
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1459000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3243
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0787  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 1460000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 5.72     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.105   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1461000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3038
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 28       |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0211   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1462000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 25.5     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0006  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1463000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3326
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.129   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1464000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3250
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0126   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1465000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3296
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0384   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1466000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0385   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1467000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3355
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0793   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1468000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0306  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.9     |
| timestep                           | 1469000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54       |
| eval/normalized_episode_reward_std | 28.5     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0292   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.6     |
| timestep                           | 1470000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3107
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 19       |
| loss/critic2                       | 19.1     |
| timestep                           | 1471000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.6      |
| loss/actor                         | -665     |
| loss/alpha                         | -0.033   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.5     |
| timestep                           | 1472000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3099
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0217  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.3     |
| timestep                           | 1473000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3160
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.038    |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.5     |
| timestep                           | 1474000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3231
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0631   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1475000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2930
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0359  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 16       |
| timestep                           | 1476000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3045
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0737   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1477000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3210
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.021    |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1478000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3199
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0871  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1479000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0525  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1480000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3138
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.74     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0386  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1481000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3019
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.022    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1482000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3303
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0155  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1483000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0102   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1484000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3320
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00252  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1485000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0527   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1486000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3163
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 3.96     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.064   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1487000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3154
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 8.07     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0525   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1488000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0654   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1489000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3001
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0716   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1490000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0182  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1491000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3158
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.132    |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1492000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3156
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0626  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1493000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3222
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 7.65     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0327  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1494000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1495000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.75     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0131   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1496000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3117
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.135   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.1     |
| timestep                           | 1497000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3158
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0601  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1498000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3144
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.1      |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1499000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3114
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 7.78     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.071   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1500000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3196
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0898   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1501000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3225
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 6.97     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00838 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1502000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3101
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0281  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1503000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3143
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.71     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0528  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1504000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 1505000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0177   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1506000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3264
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0659  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1507000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3102
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00218  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1508000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3206
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.042   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1509000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1510000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0314  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 1511000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3142
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0319  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1512000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3171
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.93     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0411  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1513000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3198
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0259  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1514000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3253
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0439   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1515000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3140
-----------------------------------------------------------------------------------
| alpha                              | 0.155     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 74.3      |
| eval/normalized_episode_reward_std | 8.18      |
| loss/actor                         | -666      |
| loss/alpha                         | -0.000893 |
| loss/critic1                       | 16.1      |
| loss/critic2                       | 16        |
| timestep                           | 1516000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3320
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0175   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 1517000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3258
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0122   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1518000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3191
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 9.97     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0419  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1519000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3090
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1520000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0195  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1521000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.125    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1522000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3100
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00138  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1523000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3155
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0952  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1524000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0269  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1525000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3328
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -665     |
| loss/alpha                         | 0.038    |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 1526000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0413  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1527000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00496  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1528000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0363  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1529000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3172
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.029    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1530000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3187
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.07    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1531000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3095
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1532000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3122
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0141  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1533000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0168   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.7     |
| timestep                           | 1534000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3271
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.000804 |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 1535000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00303  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1536000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3186
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0509  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1537000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3152
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00156  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1538000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3189
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.044    |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1539000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3089
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.00659 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1540000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3196
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0482   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1541000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3064
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0356   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1542000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3283
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.79     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0619  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 1543000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3131
-----------------------------------------------------------------------------------
| alpha                              | 0.151     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 69.2      |
| eval/normalized_episode_reward_std | 23.7      |
| loss/actor                         | -665      |
| loss/alpha                         | -0.000522 |
| loss/critic1                       | 13.8      |
| loss/critic2                       | 13.6      |
| timestep                           | 1544000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3158
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0316  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1545000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3213
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0211  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1546000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3065
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.000382 |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1547000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3118
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0188  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1548000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3062
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 8.45     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0298  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1549000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3393
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1550000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3102
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 4.23     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0659   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1551000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3315
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0509  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 1552000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3144
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0901   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1553000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3174
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0448   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1554000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3094
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 8.02     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0523   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1555000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.8      |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0694   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1556000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3280
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0278  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1557000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3012
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0179  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1558000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3297
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0247  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1559000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3222
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00327 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1560000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 6.27     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0329   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1561000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3248
-----------------------------------------------------------------------------------
| alpha                              | 0.153     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 68.9      |
| eval/normalized_episode_reward_std | 21.8      |
| loss/actor                         | -666      |
| loss/alpha                         | -0.000955 |
| loss/critic1                       | 14.2      |
| loss/critic2                       | 14.2      |
| timestep                           | 1562000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0726   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1563000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3233
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0171  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1564000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 5.63     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0651  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1565000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3122
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00149  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1566000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0196   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1567000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3153
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0596  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1568000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0167   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1569000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3260
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0176  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.2     |
| timestep                           | 1570000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3186
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0293   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1571000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3160
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00246  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.3     |
| timestep                           | 1572000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3059
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00779 |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1573000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3159
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00882  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1574000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0385  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1575000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0375   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1576000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3211
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0622   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1577000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0488  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 1578000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3195
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 9.53     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0358   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1579000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00685 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1580000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3135
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0313   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1581000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3055
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.025   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1582000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.037    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1583000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3178
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00869 |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1584000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3129
-----------------------------------------------------------------------------------
| alpha                              | 0.155     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 56.4      |
| eval/normalized_episode_reward_std | 29.8      |
| loss/actor                         | -667      |
| loss/alpha                         | -0.000205 |
| loss/critic1                       | 15.1      |
| loss/critic2                       | 15        |
| timestep                           | 1585000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0229   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1586000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3087
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0127  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1587000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3132
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0865  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1588000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3242
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0731   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1589000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3194
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.019   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1590000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0224  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1591000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 6.4      |
| loss/actor                         | -666     |
| loss/alpha                         | 0.131    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1592000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3205
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0387  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1593000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00545 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1594000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0378  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1595000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3260
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.178   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1596000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3286
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.027   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 1597000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3184
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0554  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 1598000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3179
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 9.96     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0403  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1599000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3093
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.103    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1600000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0234   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1601000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3073
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.2     |
| eval/normalized_episode_reward_std | 30.5     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.021   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1602000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3086
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.085    |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1603000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2996
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0268   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1604000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0368   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1605000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3149
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0178   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1606000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3240
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.11    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1607000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3134
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0798  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1608000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3149
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.092    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1609000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3225
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0944   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1610000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0648  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1611000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3215
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0734   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1612000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3167
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0285  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1613000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2918
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0763  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1614000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3082
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0306   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1615000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3043
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0418  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1616000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.133    |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1617000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0246   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1618000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3161
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0343  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1619000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00885 |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 1620000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3362
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.062   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 1621000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3206
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0558  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1622000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0869   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1623000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3138
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0382  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1624000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3164
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0128   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1625000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00524 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1626000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3156
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00569 |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1627000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00343 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1628000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3366
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0637   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1629000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3070
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.068    |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 1630000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3134
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0647  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 1631000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3208
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0508  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1632000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3290
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0216  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1633000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0351  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1634000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0644  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1635000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -668     |
| loss/alpha                         | 0.086    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1636000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3098
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.00747  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1637000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3174
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0417   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1638000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3166
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1639000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3224
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1640000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3120
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0679  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1641000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -667     |
| loss/alpha                         | -0.133   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 1642000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3144
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0558   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1643000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3105
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.8     |
| eval/normalized_episode_reward_std | 26       |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0643   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1644000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3070
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0706   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1645000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2988
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.045    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1646000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0243   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1647000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3083
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0236  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1648000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3203
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0695  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1649000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.00318  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1650000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0499   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1651000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3170
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00783 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1652000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2979
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.036    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1653000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
-----------------------------------------------------------------------------------
| alpha                              | 0.155     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 74.4      |
| eval/normalized_episode_reward_std | 3.1       |
| loss/actor                         | -667      |
| loss/alpha                         | -0.000849 |
| loss/critic1                       | 14.4      |
| loss/critic2                       | 14.2      |
| timestep                           | 1654000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3154
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00505 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1655000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3161
-----------------------------------------------------------------------------------
| alpha                              | 0.154     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 75        |
| eval/normalized_episode_reward_std | 2.97      |
| loss/actor                         | -667      |
| loss/alpha                         | -6.71e-05 |
| loss/critic1                       | 14.2      |
| loss/critic2                       | 14.1      |
| timestep                           | 1656000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3311
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.117   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1657000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3189
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0863  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 1658000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3128
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 1659000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3248
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0375  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1660000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3156
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0515  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1661000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3088
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 27       |
| loss/actor                         | -667     |
| loss/alpha                         | -0.039   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.2     |
| timestep                           | 1662000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3196
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 15.1     |
| timestep                           | 1663000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3026
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0937   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1664000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3146
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.067   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 1665000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3231
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0247  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1666000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3118
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0608   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1667000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3233
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 9.6      |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0595   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1668000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3319
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 7.95     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1669000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3110
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.107   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1670000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3142
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 5.99     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0271  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1671000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3134
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.11    |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.6     |
| timestep                           | 1672000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3311
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 8.81     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0529   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.5     |
| timestep                           | 1673000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3334
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0227  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1674000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0661   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1675000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0405   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1676000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3233
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0165  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1677000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3143
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0517   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1678000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0499   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1679000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3344
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0173   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1680000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.6     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0347  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1681000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3200
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0947  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1682000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3304
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0205  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1683000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3280
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0822  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1684000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3194
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0331   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1685000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3118
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0385   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1686000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3149
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0778   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1687000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3089
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 1688000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3093
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00406 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1689000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3115
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.82     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00764 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1690000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3305
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1691000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3224
-----------------------------------------------------------------------------------
| alpha                              | 0.152     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 63.6      |
| eval/normalized_episode_reward_std | 26.8      |
| loss/actor                         | -666      |
| loss/alpha                         | -0.000329 |
| loss/critic1                       | 14.4      |
| loss/critic2                       | 14.2      |
| timestep                           | 1692000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3280
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0272   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1693000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3164
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0797   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1694000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3280
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0154  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1695000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3059
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0521   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1696000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3186
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.141   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1697000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0157   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1698000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00331 |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.2     |
| timestep                           | 1699000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3054
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0103   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1700000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3117
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0442   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1701000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3120
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1702000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3240
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0152  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1703000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0513   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1704000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00683 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 1705000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0966   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1706000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3121
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0498  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1707000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3230
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0188  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1708000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3179
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0616  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1709000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3067
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0276   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1710000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3164
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 6.9      |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0531   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1711000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3166
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00904  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1712000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3268
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0569  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1713000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1714000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3153
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00159 |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1715000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3106
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.024    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1716000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0392   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1717000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 25       |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0651  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1718000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3390
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00038  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1719000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 7.15     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1720000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3171
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0383   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1721000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2992
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0288   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1722000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3159
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0396   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 1723000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3314
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.055    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1724000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3155
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 4.13     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1725000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3336
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 6.92     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0485   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1726000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -666     |
| loss/alpha                         | -0.148   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1727000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3177
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.017    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1728000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3010
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0149   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1729000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3137
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0687  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1730000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3164
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0552   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1731000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3170
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 4.11     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0614   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1732000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2958
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 4.11     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0764  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1733000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3201
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -667     |
| loss/alpha                         | 0.104    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1734000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -667     |
| loss/alpha                         | 0.126    |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1735000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0483  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1736000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3108
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0578   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 1737000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3128
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1738000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3177
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0282  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1739000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3187
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0127  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1740000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3108
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0461  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 1741000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0951   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1742000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3108
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0959   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1743000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3160
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.00975  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.7     |
| timestep                           | 1744000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3083
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 7.45     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0444  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1745000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3034
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00843 |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1746000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.035   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1747000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3178
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0709  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1748000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.098   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1749000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3384
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.151    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1750000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3414
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00477 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1751000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0199  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 1752000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0354  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1753000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3137
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 4.57     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.031   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1754000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3181
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00897 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 1755000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3178
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.87     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0925  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1756000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3182
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.00295  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1757000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3174
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0472  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.2     |
| timestep                           | 1758000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0283  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1759000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3150
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.7     |
| eval/normalized_episode_reward_std | 31.1     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.145    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 1760000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3316
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0328   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1761000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1762000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0568   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1763000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1764000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3137
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0827  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 1765000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3042
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.069    |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1766000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3048
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.99     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0441   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1767000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0831   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1768000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3234
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0114   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1769000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00499 |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1770000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3200
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0313  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 1771000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3401
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0104  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 1772000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3189
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0162   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1773000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.57     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0682  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.6     |
| timestep                           | 1774000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3331
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0148  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1775000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.074    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1776000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 8        |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0279  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1777000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3158
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -669     |
| loss/alpha                         | 8.43e-05 |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1778000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3120
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00163 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1779000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3382
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1780000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.033   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1781000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3357
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 5.21     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0296  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1782000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1783000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.03    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 1784000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65       |
| eval/normalized_episode_reward_std | 25.8     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0801  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1785000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3367
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.151    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1786000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3343
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0108   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1787000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3317
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.145   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1788000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3390
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0281   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1789000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3406
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00832 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1790000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0594  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1791000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3225
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0614  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1792000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3178
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0171  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1793000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3300
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0988   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1794000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.077    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1795000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3172
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0539   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1796000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3148
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 5.35     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0766   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1797000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0964  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1798000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3222
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0393  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1799000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0607  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1800000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3234
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0929  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1801000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.00791  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1802000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3412
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 4.02     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0836   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1803000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3382
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0212   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1804000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0607   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1805000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3239
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0612  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1806000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3151
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0254   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1807000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0949   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 1808000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3184
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.113   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1809000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0161   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1810000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3240
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0035   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1811000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0369  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1812000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3125
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0351   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1813000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.165    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1814000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3166
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0719  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1815000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3069
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.056   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 1816000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0291  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1817000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0368  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1818000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3280
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0297   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1819000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0423   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1820000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.87     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0853  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1821000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3392
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0469   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1822000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.022    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1823000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3259
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0651  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1824000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3149
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00896 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1825000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1826000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3296
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 5.7      |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0544  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1827000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 9.41     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0566  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1828000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3272
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0212  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1829000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 9.95     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0267   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1830000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3372
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -669     |
| loss/alpha                         | 0.00716  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1831000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0774  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1832000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.131    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1833000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3119
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0114  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1834000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3241
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0169   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1835000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0142   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1836000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3199
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0183  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 1837000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3202
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0523  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1838000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0924  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1839000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0417   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1840000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3181
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.64     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.065    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1841000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0391   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1842000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3372
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0178  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1843000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3170
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0557  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1844000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3178
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0521   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1845000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3248
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1846000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3166
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65       |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0323  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1847000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0213   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1848000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0177  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1849000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3247
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0822  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1850000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3367
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0812   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1851000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3198
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0411  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1852000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3239
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0137  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 1853000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3385
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.00423  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1854000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3254
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0893   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1855000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0658  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1856000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3342
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0337   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1857000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 8.8      |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0307  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 1858000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.025   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1859000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0786  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 1860000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3253
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.6      |
| loss/actor                         | -669     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 1861000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3129
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 8.88     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0536   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1862000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3323
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0134  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 1863000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3035
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1864000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0244  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 1865000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0107   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1866000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3166
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0326   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1867000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3182
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0345  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1868000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3008
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.86     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0769   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 1869000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3147
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0198   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1870000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -669     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1871000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3171
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0563   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 1872000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 8.96     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0317   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1873000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3208
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0194  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 1874000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3202
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0382  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1875000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0228  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 1876000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 4.38     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0416   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1877000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0177  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1878000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3319
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 4.76     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00361 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1879000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3362
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0156  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1880000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0868  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 1881000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0096   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 1882000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0529   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1883000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0584   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1884000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0134   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1885000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3231
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0579  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1886000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0138   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1887000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3212
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 9.31     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0299   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1888000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0503  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1889000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00999 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1890000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3341
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 4.93     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0222   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 1891000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3230
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.034    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1892000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3361
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.111   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1893000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3158
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0309  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 1894000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3375
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00704 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1895000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3150
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0174   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 1896000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3205
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0317  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1897000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3313
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -669     |
| loss/alpha                         | 0.04     |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1898000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0238   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1899000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3156
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.00288  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1900000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3234
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1901000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00977 |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1902000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3170
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 9.37     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00601 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1903000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3074
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.108    |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1904000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3129
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0318  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1905000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3438
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 7.73     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.093    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1906000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3163
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0171   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1907000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3319
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0251  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1908000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 13.2     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0302   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1909000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3320
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0612  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1910000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0671  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1911000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3239
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0966   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1912000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -669     |
| loss/alpha                         | 0.095    |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1913000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0301   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1914000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3191
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0301  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1915000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3128
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0225   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1916000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1917000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3208
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0271   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 1918000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.00815  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 1919000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0675  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 1920000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3165
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.00856  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 1921000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3254
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0532  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 1922000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3390
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.096    |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 1923000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0113  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1924000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3136
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0604  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1925000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3449
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.072    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1926000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3210
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1927000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0357  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1928000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3187
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0852   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1929000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3238
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.138   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1930000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3293
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.00116  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 1931000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3246
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0685   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 1932000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3317
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0619  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 1933000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3241
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 11.2     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0035  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1934000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3382
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0562   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1935000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3238
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0749  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1936000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3211
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1937000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0724  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1938000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0532   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1939000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3191
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0523   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1940000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3327
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0475  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1941000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3379
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0119  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 1942000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3070
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.108    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 1943000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3284
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.051   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1944000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0691   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 1945000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -668     |
| loss/alpha                         | 0.05     |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1946000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0458  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1947000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.00149  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1948000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.14    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 1949000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0101   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 1950000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3156
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00783 |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 1951000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3170
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.69     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 1952000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 4.17     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0357   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1953000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3328
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.87     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00074 |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.6     |
| timestep                           | 1954000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3362
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0187  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.3     |
| timestep                           | 1955000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3425
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0892  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1956000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0659   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.3     |
| timestep                           | 1957000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3271
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0234  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1958000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0907  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1959000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1960000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0354   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 1961000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3398
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0915  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.8     |
| timestep                           | 1962000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3319
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0876   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1963000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3104
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.141    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1964000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3224
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.00589  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1965000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1966000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3376
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.041   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1967000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3343
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0457  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1968000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3118
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0425  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1969000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0142  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1970000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0379   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1971000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3296
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0983  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1972000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3328
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0957   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1973000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3432
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 9.57     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0517   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1974000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0498   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1975000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3187
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0177   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 1976000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3114
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00764 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1977000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3323
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1978000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3341
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0314  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 1979000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0384   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 1980000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3094
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0566   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13.1     |
| timestep                           | 1981000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3238
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0544  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 1982000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.076   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.2     |
| timestep                           | 1983000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3421
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0313  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1984000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0341  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 1985000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.019   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 1986000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3130
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0864   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1987000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.022    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1988000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3136
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00813  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1989000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3324
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0685   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1990000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3186
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0442  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.7     |
| timestep                           | 1991000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3242
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0521  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1992000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 8.9      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0354  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1993000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3319
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0334   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 1994000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3141
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0377  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1995000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3147
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00824  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1996000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00406  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1997000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3242
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00565 |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 1998000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0227  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 1999000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3314
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0688  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2000000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3306
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0545   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2001000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0254   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2002000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3417
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.079    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2003000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3231
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0155   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2004000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3286
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00713  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2005000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00377 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2006000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3327
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0293  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2007000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3290
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0786  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2008000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3205
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0633   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2009000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3210
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0463   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2010000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3229
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 8.09     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0243  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2011000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3124
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63       |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0182   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2012000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3225
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0295  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2013000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.014    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2014000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3096
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 8.65     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0048   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2015000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3062
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0323  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2016000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.152    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2017000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3212
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.038   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2018000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2019000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0168  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2020000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3354
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0228  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2021000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0777   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2022000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3211
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0527  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2023000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0778  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2024000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3097
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.053    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2025000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0118  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2026000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3238
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.099   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 2027000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00707  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2028000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -671     |
| loss/alpha                         | 0.109    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2029000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3172
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 7.58     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0805  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.7     |
| timestep                           | 2030000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3281
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0459  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2031000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3187
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.78     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.052    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2032000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0277   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2033000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00678 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2034000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3280
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.038    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2035000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3326
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0389   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2036000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3344
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0208  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2037000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0928  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2038000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0371  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2039000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3412
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0631  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2040000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3129
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0607   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2041000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3272
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0476   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2042000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0782   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 2043000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3359
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0228  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2044000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 8.32     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0657  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2045000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3354
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2046000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0544   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2047000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00606  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2048000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3120
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0838  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.9     |
| timestep                           | 2049000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3191
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2050000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0416  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2051000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3302
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0902   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2052000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3250
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0751   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2053000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2054000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3149
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.87     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0125  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2055000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3209
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0546   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2056000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0792  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13.1     |
| timestep                           | 2057000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3193
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0127  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2058000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0211  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2059000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0466   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2060000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3032
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0295   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2061000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3191
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0289   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 2062000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3263
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.74     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0759  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 2063000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3203
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.85     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0833  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2064000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3239
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.00836  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2065000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3140
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2066000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0804   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2067000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0296  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2068000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 11.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2069000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0278   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2070000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3203
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0612   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2071000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3127
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 7.3      |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0559   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2072000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3308
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0766  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2073000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0337  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2074000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00095 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2075000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0459   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2076000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00939 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2077000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3264
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2078000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3103
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0811  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2079000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0941   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2080000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00188  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2081000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3252
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00121  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2082000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3135
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0345  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2083000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 6.68     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0556   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2084000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3229
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0399  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2085000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3242
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0755  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2086000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3326
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0839   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 2087000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3326
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0547   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2088000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3247
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.029    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2089000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3127
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0887  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2090000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0301   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2091000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3284
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0247  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2092000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.9     |
| eval/normalized_episode_reward_std | 30.8     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.022    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2093000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0154  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2094000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3301
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0133  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2095000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3238
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0524  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2096000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3192
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0406   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2097000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0461   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2098000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3320
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.8      |
| loss/actor                         | -670     |
| loss/alpha                         | 0.032    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2099000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0385  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2100000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00149 |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2101000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3209
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0142   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2102000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3129
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0386  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2103000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3313
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00656 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2104000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3199
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.062    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2105000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3355
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0266  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 2106000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3201
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0196  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2107000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3210
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.132   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 2108000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 5.45     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0567   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2109000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0713  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 14       |
| timestep                           | 2110000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3233
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0509   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 2111000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3302
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.84     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0401   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2112000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3327
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0738  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2113000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0111  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2114000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0665   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2115000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3311
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00717 |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2116000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3264
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0182  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2117000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3283
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0294   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2118000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.047   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2119000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3362
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0552   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2120000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3406
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 7.98     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0637   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2121000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3322
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0407   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2122000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3366
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.085   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2123000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3290
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 9.2      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0476  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2124000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3351
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0947   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2125000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3474
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0189  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2126000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3338
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0636  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2127000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 9.6      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0113  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2128000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3181
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0108   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2129000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3194
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.00996  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2130000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3258
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0588  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2131000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3446
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.84     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0362   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2132000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0277   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2133000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3241
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 8.34     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0447  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2134000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3313
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 28.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00997  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2135000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3301
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0108   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2136000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0467  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2137000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0947   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2138000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3176
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.6      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0668  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2139000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.83     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0188   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2140000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3170
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0138   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2141000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3388
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0261  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2142000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3196
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0227   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2143000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0713   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2144000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3147
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2145000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0849   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2146000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3353
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0392  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2147000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0249  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2148000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00254 |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2149000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3250
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.129    |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2150000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3324
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0212  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2151000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3076
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0097   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2152000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0917  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2153000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3332
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0395  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2154000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3338
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0841  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2155000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0121   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2156000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.138    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2157000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3397
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0931   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2158000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0363   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2159000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0798  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2160000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3243
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.2     |
| timestep                           | 2161000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3342
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0768   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2162000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.017   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2163000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3369
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0214   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2164000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3196
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0472   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2165000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0149  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2166000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3335
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00262 |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2167000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3176
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0466   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2168000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0233   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2169000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3247
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0315  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2170000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3080
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2171000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2172000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3212
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2173000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3305
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0533   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2174000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3192
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0466  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2175000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3146
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0567  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2176000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3209
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2177000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3351
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2178000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3409
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00712  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2179000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3258
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00778  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2180000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3334
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0753  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2181000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3242
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0351  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2182000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3424
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0833   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2183000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3398
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0745  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2184000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 9.82     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00438  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2185000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3344
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.03    |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2186000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0458  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2187000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3319
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 5.59     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0399   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2188000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3306
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0631  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2189000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3346
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 9.22     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0527   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2190000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3258
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0463   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2191000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3390
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0273   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2192000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3332
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2193000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3357
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0949   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2194000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3377
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00637 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2195000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3317
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00204 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2196000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00373 |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2197000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3212
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.077   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2198000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0106   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2199000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0321   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2200000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3153
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 8.2      |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0699   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.4     |
| timestep                           | 2201000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0987  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2202000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0325   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2203000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.8      |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0976   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2204000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3382
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0335  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2205000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.031   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2206000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0739  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2207000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0663   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2208000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3259
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0631   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2209000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3296
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0723  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2210000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3375
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0178  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2211000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3254
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 6.49     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.00934  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2212000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3394
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.05    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2213000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3390
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0424   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2214000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3264
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0311   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2215000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 6.01     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0317  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2216000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3271
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.113   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2217000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3325
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2218000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00155 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2219000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3191
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2220000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0797   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2221000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3246
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0574  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2222000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3140
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0297  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2223000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3141
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 9.61     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0473   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2224000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2225000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3172
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.115   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2226000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.86     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0305   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2227000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.156    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2228000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3389
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2229000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0968  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2230000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.025    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2231000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.2     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0583  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2232000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3398
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.006   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2233000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3203
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 9.13     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.047    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2234000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3259
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.69     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0435   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2235000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3263
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.12    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2236000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3200
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 8.27     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0918   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2237000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3200
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.058    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2238000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3151
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 10.3     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0399  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2239000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3092
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0774  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2240000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3195
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.038    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2241000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0437   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2242000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3352
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0682  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2243000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0046   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2244000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3259
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0321   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2245000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62       |
| eval/normalized_episode_reward_std | 25.2     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0983  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2246000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0746   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2247000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3224
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 7.78     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.131    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 2248000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3234
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0554  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2249000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3272
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -669     |
| loss/alpha                         | 0.00515  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2250000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3324
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0811  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2251000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3225
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0146   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2252000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
-----------------------------------------------------------------------------------
| alpha                              | 0.148     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 72.1      |
| eval/normalized_episode_reward_std | 14.3      |
| loss/actor                         | -669      |
| loss/alpha                         | -0.000665 |
| loss/critic1                       | 14.3      |
| loss/critic2                       | 14.3      |
| timestep                           | 2253000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3239
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0663  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2254000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3329
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 4.34     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0331   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2255000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3302
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.75     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0175  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2256000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3348
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.043    |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2257000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3336
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.164   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2258000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0722  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2259000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0282   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2260000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -669     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2261000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3294
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0219   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2262000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.051    |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2263000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3308
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2264000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3286
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.044   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2265000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3243
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.048    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2266000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0129  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2267000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3348
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.82     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0386   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2268000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0816   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.7     |
| timestep                           | 2269000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3191
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0545   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2270000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3268
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 7.68     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0138   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2271000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3386
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00727 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2272000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3384
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2273000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.00743  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2274000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3370
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0325  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2275000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3344
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 5.13     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2276000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0198   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2277000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3382
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0125   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2278000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3195
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0321   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2279000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3301
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.71     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.027   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2280000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -670     |
| loss/alpha                         | -0.058   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2281000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2282000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3146
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.143   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2283000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0393  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2284000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.138    |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2285000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3353
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0451   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2286000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3243
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0271   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2287000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0704  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2288000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00408 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2289000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3365
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0121  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2290000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3222
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0449   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2291000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0642  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2292000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3332
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0109  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2293000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3410
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.032   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2294000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3329
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.97     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.019    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2295000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3198
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0594   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2296000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.087   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2297000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3348
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0686  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2298000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0516   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2299000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3195
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 26.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2300000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3314
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0892   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 2301000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3408
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0651  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 2302000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0176  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2303000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3269
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.131   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2304000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3363
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0267  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2305000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0426   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2306000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.115    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2307000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3459
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0217  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2308000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3281
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00658  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2309000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3344
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0127  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2310000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3391
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 8.35     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0492   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2311000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3439
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0359  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2312000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2313000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3301
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -673     |
| loss/alpha                         | 0.11     |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2314000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0461  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2315000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64       |
| eval/normalized_episode_reward_std | 25.9     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0131   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2316000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0735   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2317000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3301
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 24       |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0515  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2318000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3300
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00502 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2319000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3304
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00668  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2320000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3167
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 7.82     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.067   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2321000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3363
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0256   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2322000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3315
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -672     |
| loss/alpha                         | -0.152   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2323000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0341  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2324000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0461   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2325000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3134
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0408   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2326000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 5.66     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0412   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2327000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3272
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0608   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2328000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3250
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0544  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2329000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00712 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2330000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0101   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2331000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0693  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2332000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3429
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0463  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2333000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3297
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0384   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2334000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3179
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.1      |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2335000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3373
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0776  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2336000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00632  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2337000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00661 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2338000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3351
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0441   |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.7     |
| timestep                           | 2339000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0567  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2340000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3263
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0783  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2341000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3359
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0158   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2342000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0423  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2343000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3301
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0504   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2344000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3301
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0732   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2345000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 4.26     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0338   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2346000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3281
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.032   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2347000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3250
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0132  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2348000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0729   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2349000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.4     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0154  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2350000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3284
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2351000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0525  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2352000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3151
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0113  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2353000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3263
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0444  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2354000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0685  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2355000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3370
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00717  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2356000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3320
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.157    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2357000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0325  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2358000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 9.38     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0589  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2359000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0598  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2360000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3160
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0439   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2361000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3300
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0598  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2362000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3311
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 4        |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0124   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2363000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3297
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 9.11     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0189  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2364000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0216   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2365000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0277  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2366000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0484   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2367000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3381
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -674     |
| loss/alpha                         | 0.109    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2368000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3192
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 5.37     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0051  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2369000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3195
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0309   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2370000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3328
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 6.72     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0345  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2371000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3193
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0621   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2372000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3136
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0717  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2373000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3248
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0662  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2374000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3213
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0233  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2375000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0423   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2376000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3479
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 6.04     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0542   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2377000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 4.25     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0362   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2378000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0565  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2379000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3355
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2380000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0097  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2381000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3373
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0562   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2382000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00183  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2383000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3271
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 6.11     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0666   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2384000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0342  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2385000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0289  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2386000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3315
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00396  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2387000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0379   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2388000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3184
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0691  |
| loss/critic1                       | 12.5     |
| loss/critic2                       | 12.5     |
| timestep                           | 2389000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0127  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2390000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3320
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0548  |
| loss/critic1                       | 12.5     |
| loss/critic2                       | 12.6     |
| timestep                           | 2391000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3264
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.8     |
| eval/normalized_episode_reward_std | 27.5     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.000217 |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2392000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3281
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0565   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2393000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3357
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0622  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2394000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0541  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2395000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3230
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.8     |
| timestep                           | 2396000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3322
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0121   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2397000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3245
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0269   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2398000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3326
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0231  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2399000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.048    |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2400000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3290
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0516   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2401000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3296
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0018  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2402000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0925  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.3     |
| timestep                           | 2403000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3288
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -672     |
| loss/alpha                         | -0.075   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2404000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3338
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0573   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2405000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0307   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2406000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00912  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2407000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00223 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2408000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3356
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0474   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2409000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 7.41     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00586  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2410000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3306
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0438   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2411000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3354
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0864  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2412000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3201
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0579   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2413000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3260
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0261  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 2414000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0289  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.9     |
| timestep                           | 2415000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3365
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0132   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2416000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3115
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0669  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2417000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3472
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00651 |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2418000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3210
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0672   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2419000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3372
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.024   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2420000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0854   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2421000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3258
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0988  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2422000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3163
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0198   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2423000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0519   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2424000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0229  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2425000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3338
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0444  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2426000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3252
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 7        |
| loss/actor                         | -672     |
| loss/alpha                         | -0.035   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 2427000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3362
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0485   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2428000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0148  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2429000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3330
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0242   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2430000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3268
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0243  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2431000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0331   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2432000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3225
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0189  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2433000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3361
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0347  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2434000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3385
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 8.02     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0527   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2435000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3324
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00798  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2436000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3199
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.113   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2437000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3317
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0798  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2438000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3458
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0324   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2439000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3303
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 4.01     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.142    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2440000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0635  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2441000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3284
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0501   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2442000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3163
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0356   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2443000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2444000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3354
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0718   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2445000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0069  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2446000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3250
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0953  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2447000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3283
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2448000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3314
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0729   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2449000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3212
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.02     |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2450000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3202
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00406  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2451000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3169
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0104   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2452000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0462  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2453000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3184
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00864  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2454000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0485   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2455000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00684 |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.9     |
| timestep                           | 2456000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3215
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0852   |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.5     |
| timestep                           | 2457000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0245  |
| loss/critic1                       | 12.4     |
| loss/critic2                       | 12.4     |
| timestep                           | 2458000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3213
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0846  |
| loss/critic1                       | 12.5     |
| loss/critic2                       | 12.6     |
| timestep                           | 2459000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0148  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2460000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3294
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.64     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00106  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2461000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3211
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0087  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 13       |
| timestep                           | 2462000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0161  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2463000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3288
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0921   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.3     |
| timestep                           | 2464000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.045   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2465000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.201   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2466000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3271
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.9      |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0411   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2467000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3293
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0358  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2468000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0212   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2469000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3191
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0648   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.5     |
| timestep                           | 2470000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00901  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2471000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2472000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3325
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0204  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2473000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0454   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2474000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3235
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.115   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2475000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0126  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2476000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0659   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2477000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00791 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2478000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3323
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0875   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2479000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2480000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3152
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.041    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.8     |
| timestep                           | 2481000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3151
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.153   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2482000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3332
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0357   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2483000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3247
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0292   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2484000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0762  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2485000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 4.08     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.122    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2486000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0214   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2487000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3110
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.74     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0246  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2488000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3151
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63       |
| eval/normalized_episode_reward_std | 29.2     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0153   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2489000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.023    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2490000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3172
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0572  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2491000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3157
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0359  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2492000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3248
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0257   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2493000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3170
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.016    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2494000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3368
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.038   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2495000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3241
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 5.7      |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0778   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2496000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2497000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.84     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0324  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2498000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.74     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.056    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2499000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3229
-----------------------------------------------------------------------------------
| alpha                              | 0.149     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 75.2      |
| eval/normalized_episode_reward_std | 5.27      |
| loss/actor                         | -673      |
| loss/alpha                         | -0.000636 |
| loss/critic1                       | 13.5      |
| loss/critic2                       | 13.6      |
| timestep                           | 2500000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3252
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00346  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2501000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3095
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0817  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2502000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0177  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2503000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3338
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0721   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2504000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.132   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2505000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3332
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0694   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2506000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2507000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 6.34     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0485   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.6     |
| timestep                           | 2508000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3248
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0202   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2509000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0705  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2510000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3108
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 7.91     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0157  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2511000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3361
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0756  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2512000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.107    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2513000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.81     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0171   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2514000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3291
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 7.21     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0491  |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.7     |
| timestep                           | 2515000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3297
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0115  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2516000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3288
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.83     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0323   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.3     |
| timestep                           | 2517000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3297
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0503   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2518000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3335
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0736  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2519000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3247
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0478   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2520000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3300
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 26.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00039 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2521000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00712 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2522000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3369
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0175  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2523000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3246
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.04    |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2524000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3294
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0623  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2525000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3362
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0245   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2526000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0827   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2527000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 5.83     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0121   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2528000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3326
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.022   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2529000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 8.51     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.039   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2530000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3361
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 7.88     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00641  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2531000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3328
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0196  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2532000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3215
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0267  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2533000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3201
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0567   |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.6     |
| timestep                           | 2534000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3286
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0375  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2535000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3311
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0157  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2536000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3209
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.114    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2537000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3303
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.154    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2538000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0688  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2539000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3156
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.023   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2540000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3174
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0598  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2541000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0551  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2542000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3336
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0363  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2543000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0333  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2544000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3410
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.041   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2545000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0426   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 2546000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3243
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0242  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2547000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00346 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 2548000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00844 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2549000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3111
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0435  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2550000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3342
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2551000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3328
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.103    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2552000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3343
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.037    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2553000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0583   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2554000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3191
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0233   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2555000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3190
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0621  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2556000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.68     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0173   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2557000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2558000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3400
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0668  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2559000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0765  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2560000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3189
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0518   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2561000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0616   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2562000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3395
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0115  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2563000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3413
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0325  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2564000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3468
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0232   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2565000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3346
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0365  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2566000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3381
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -675     |
| loss/alpha                         | 0.166    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2567000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3241
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0678  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2568000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0335   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2569000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3242
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0428  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2570000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3250
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 6.27     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0617  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2571000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0148   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2572000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3353
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.71     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0431   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2573000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3194
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2574000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0427   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2575000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3307
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0199   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2576000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3254
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0863  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2577000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3179
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 4.79     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0487   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2578000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3151
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00518 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2579000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3215
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.4     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0279  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2580000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0663   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2581000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0889  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2582000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0017  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2583000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 9.73     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2584000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00709 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14.1     |
| timestep                           | 2585000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3153
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0508  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2586000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3291
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.192    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2587000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3302
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.116   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2588000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3378
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0268   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2589000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3339
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0686   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2590000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3433
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.068    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2591000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3303
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0158   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2592000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0728  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2593000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0543   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2594000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3245
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2595000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3314
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.199   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2596000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00243 |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2597000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.142    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2598000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3341
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00215 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2599000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3304
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00523  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2600000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3365
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.69     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0575  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2601000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3186
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0288   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2602000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3294
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0773  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2603000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3427
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0343  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2604000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0636   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2605000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3269
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0252   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2606000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3303
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0668  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2607000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3343
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.089    |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2608000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0404   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2609000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2610000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3293
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0971  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2611000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3336
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0433  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2612000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3308
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.64     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0277  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2613000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3336
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0301   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2614000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0359  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2615000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3110
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 8.88     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.163    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2616000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3307
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00364  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2617000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0565  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2618000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3185
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.71     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00551 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2619000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3412
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00507  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2620000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00336  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2621000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3271
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0412   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2622000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00179 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2623000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3311
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0223   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2624000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3349
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 7.4      |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0451  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2625000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0129  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2626000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3322
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 8.42     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2627000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3288
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00462 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2628000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3209
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.133   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2629000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.147   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2630000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.89     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0319   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2631000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3148
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00561  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2632000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3444
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0553  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2633000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3291
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.68     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0526  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2634000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3191
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00271 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2635000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3316
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0417   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2636000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3344
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0943   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2637000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3410
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.012    |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2638000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3282
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0855   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.9     |
| timestep                           | 2639000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3312
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0411  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2640000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0187  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2641000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -674     |
| loss/alpha                         | 0.103    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2642000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.76     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0477  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2643000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3332
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0444   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2644000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3209
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.012   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2645000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00851  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2646000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0484  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2647000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0138  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2648000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3224
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0722   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2649000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2650000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.06    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2651000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3239
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 4.18     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.000198 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2652000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0351  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2653000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3322
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0273   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2654000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3290
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00531 |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2655000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3315
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0706   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2656000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -675     |
| loss/alpha                         | 0.128    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2657000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3338
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0337   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2658000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3171
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.121   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2659000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3185
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0582  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2660000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3176
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0737  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2661000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3304
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.84     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0573   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2662000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3259
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0481   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2663000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0889  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2664000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0232   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2665000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0219  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2666000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3369
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.8      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0717  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2667000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3286
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0148   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2668000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0346   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.3     |
| timestep                           | 2669000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3384
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0288   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2670000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3300
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0914   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2671000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3282
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.71     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0817  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2672000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.6      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.101   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2673000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3332
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 9.47     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.043    |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2674000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3253
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 5.44     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0756   |
| loss/critic1                       | 12.5     |
| loss/critic2                       | 12.5     |
| timestep                           | 2675000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.002    |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2676000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3315
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0175  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2677000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3379
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2678000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3260
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2679000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3398
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0073  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2680000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3283
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0966   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2681000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3225
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 4.7      |
| loss/actor                         | -674     |
| loss/alpha                         | -0.181   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2682000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3315
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00446 |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2683000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3339
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0607  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2684000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3374
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0856   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2685000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 8.74     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0688  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2686000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3320
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0454  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2687000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.13    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2688000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3383
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00595  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2689000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3384
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0531   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2690000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3356
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0377   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2691000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3377
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.68     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0505   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2692000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3308
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00206  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2693000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0307  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.7     |
| timestep                           | 2694000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3187
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 6.16     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0133   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2695000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3303
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0505  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2696000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3245
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0109  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2697000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3354
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00952  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2698000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3390
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 4.71     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0509   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2699000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3462
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.071   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2700000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3354
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 7.71     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0324   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2701000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3272
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0517   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2702000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0361   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2703000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3319
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0186  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 2704000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3273
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 2705000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0281  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 2706000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3254
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0578   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2707000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3420
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0399   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2708000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3320
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0449   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2709000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3325
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0354   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2710000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3355
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0718   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2711000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3408
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.138   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2712000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3354
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0775  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2713000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3359
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 8.34     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0248   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2714000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0491  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14.1     |
| timestep                           | 2715000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3243
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2716000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0458   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2717000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3253
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0527  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2718000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3260
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.037    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2719000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3078
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0581  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2720000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3300
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0728   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2721000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3287
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.000771 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2722000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 9.45     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0396  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2723000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00178 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2724000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3323
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.64     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0476   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2725000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3384
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0162   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2726000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3364
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0422  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2727000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3348
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0123   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2728000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3324
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 11.9     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0343  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2729000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3301
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0383   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2730000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.84     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0639  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2731000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3239
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 5.74     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0424   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2732000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0511  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2733000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3212
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.2     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0825   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2734000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3258
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0194  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2735000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3254
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0323  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2736000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3304
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.106    |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2737000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0149  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2738000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3252
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.018   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2739000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 5.08     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0423   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2740000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0343  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2741000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0783  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2742000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3396
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0462   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2743000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3280
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00422  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2744000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.042   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2745000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3305
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0307   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2746000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0222   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2747000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3195
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.104   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2748000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3382
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0656  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2749000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
----------------------------------------------------------------------------------
| alpha                              | 0.139    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 7.7      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00955 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2750000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0868   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2751000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.115    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2752000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3246
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0599  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2753000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0895  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2754000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3330
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 4.71     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0763   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2755000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3199
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0366   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2756000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2757000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3329
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -676     |
| loss/alpha                         | 0.129    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2758000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.145   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2759000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3323
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0898  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2760000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3129
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.128    |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2761000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3367
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.059    |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2762000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.042   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2763000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.144    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2764000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0282  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2765000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 6.77     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0182  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2766000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0775  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2767000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3233
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00151 |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2768000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3194
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0178  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2769000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3194
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 4.48     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0248   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2770000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3202
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 5.29     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0397   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2771000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0171  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2772000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3230
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0238  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2773000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3349
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0154  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2774000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3331
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0734  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2775000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3360
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0163  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2776000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3341
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.057    |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2777000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0472   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2778000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3305
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0317  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2779000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0422   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2780000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3359
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0621  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2781000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 5.27     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0563  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2782000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3215
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00669  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2783000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3248
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.05     |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2784000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3376
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0952   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2785000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3359
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0931  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2786000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.099   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2787000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3160
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0132  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2788000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3331
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0644  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2789000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3364
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0256   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2790000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -675     |
| loss/alpha                         | 0.156    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2791000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3137
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0123  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2792000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 4.83     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0254   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2793000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0383   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2794000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3361
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0595  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2795000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3242
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0557   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2796000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3333
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 12.5     |
| loss/critic2                       | 12.5     |
| timestep                           | 2797000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.137   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2798000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00257  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2799000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3216
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.057    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2800000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0138   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2801000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3271
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0068   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2802000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0229   |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.7     |
| timestep                           | 2803000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0931   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2804000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3223
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 4.81     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0137   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2805000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3162
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0558  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2806000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3230
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2807000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3293
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.75     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0954  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2808000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3238
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0175   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2809000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0851   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2810000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3239
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -674     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2811000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3369
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0233   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2812000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3215
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.113   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2813000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3187
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0288   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2814000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3252
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.76     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0738  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2815000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3186
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0696  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2816000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00672  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2817000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 5.76     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2818000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3291
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 11.9     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0411   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2819000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3349
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0194  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2820000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3254
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0116   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2821000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2822000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3196
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 9.61     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0474   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2823000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0224   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.4     |
| timestep                           | 2824000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3420
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0219  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2825000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3331
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.07    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2826000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0419   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2827000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0652  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2828000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3334
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00723 |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2829000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3333
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00553  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2830000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0749   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2831000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3331
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.138    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2832000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0599  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2833000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.6      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.117   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2834000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0113   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2835000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3264
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 7.12     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0693   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2836000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3246
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00932 |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2837000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3300
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0723  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2838000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3180
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0146  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2839000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3335
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0215   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2840000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.032   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2841000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3338
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0142   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2842000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0959   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2843000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0733   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2844000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0199   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2845000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0258  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2846000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0976  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2847000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0567  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2848000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3204
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.082   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2849000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0512  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2850000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3293
----------------------------------------------------------------------------------
| alpha                              | 0.139    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0223   |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.4     |
| timestep                           | 2851000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.131    |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.7     |
| timestep                           | 2852000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3378
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.155    |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2853000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3302
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00318 |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2854000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.066   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2855000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.157   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2856000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3346
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0269   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2857000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0163  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 13       |
| timestep                           | 2858000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0343   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2859000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3247
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0245   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2860000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3313
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 5.1      |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0928   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2861000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00557  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2862000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3302
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.135   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2863000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3311
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.119   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2864000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3416
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2865000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2866000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0315  |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.7     |
| timestep                           | 2867000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3245
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.71     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.000163 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2868000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 5.73     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00935  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2869000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0373   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2870000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3199
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 4.76     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0044  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2871000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3312
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.197   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2872000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3336
----------------------------------------------------------------------------------
| alpha                              | 0.138    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.138   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2873000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3205
----------------------------------------------------------------------------------
| alpha                              | 0.137    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0832   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2874000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3166
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -676     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2875000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3390
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.141    |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2876000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0212   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2877000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3221
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0498  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2878000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0439  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2879000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3227
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0441   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2880000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0867   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2881000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3230
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0462   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2882000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3263
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0833  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2883000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3311
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 5.55     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0213  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2884000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0246  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2885000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0458  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2886000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3394
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0467   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2887000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3284
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00455  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2888000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3231
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0169   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2889000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00489 |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2890000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3263
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00811 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2891000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3176
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00066 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2892000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3348
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.084   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2893000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0605   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2894000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3233
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0227   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2895000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3386
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00127 |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2896000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3233
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00509 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2897000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3301
-----------------------------------------------------------------------------------
| alpha                              | 0.146     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 76.8      |
| eval/normalized_episode_reward_std | 3.03      |
| loss/actor                         | -675      |
| loss/alpha                         | -0.000426 |
| loss/critic1                       | 13        |
| loss/critic2                       | 13        |
| timestep                           | 2898000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 8.28     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0404  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2899000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0294   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2900000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0109  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2901000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3218
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0504  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2902000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0984   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2903000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3312
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00909  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2904000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3338
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00602  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2905000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3336
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0403  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2906000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3386
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0209  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2907000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3290
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 4.32     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0531  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2908000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 4.45     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0304  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2909000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3374
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0683   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2910000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3323
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0645   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2911000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0658  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2912000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3304
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.107   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 14       |
| timestep                           | 2913000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 6.73     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0551  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2914000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3303
----------------------------------------------------------------------------------
| alpha                              | 0.139    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.000658 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2915000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3290
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0369   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2916000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3282
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0367   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2917000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 6.63     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0715   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2918000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3359
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -676     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2919000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3358
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0574   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2920000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -676     |
| loss/alpha                         | 0.00751  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2921000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0798  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2922000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.1     |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2923000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3193
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0336  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2924000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0428  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2925000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3211
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00114 |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2926000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.00946  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2927000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00624 |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2928000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3185
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2929000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0994   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2930000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2931000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3161
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.022   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2932000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3226
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.064   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2933000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3359
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0729  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2934000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3251
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0252  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2935000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0341   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2936000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3294
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0398   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2937000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3176
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0737   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2938000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3192
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0595   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2939000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3200
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00267  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2940000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0285  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2941000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3381
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0124  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2942000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3197
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0147   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2943000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3242
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0255   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2944000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0365   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2945000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3304
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0191  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2946000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3320
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0279  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13.2     |
| timestep                           | 2947000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3302
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0345  |
| loss/critic1                       | 12.5     |
| loss/critic2                       | 12.6     |
| timestep                           | 2948000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.8     |
| timestep                           | 2949000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0416  |
| loss/critic1                       | 12.5     |
| loss/critic2                       | 12.5     |
| timestep                           | 2950000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3410
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0562  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2951000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0345  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2952000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3312
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0446  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2953000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3194
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13.1     |
| timestep                           | 2954000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3100
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0177   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2955000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0491   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2956000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3243
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0291   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2957000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3346
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0203   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2958000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3170
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0398   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2959000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3211
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0531   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2960000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3193
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 10.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0264  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2961000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3288
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0469  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2962000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0576  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2963000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3350
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0407  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2964000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3254
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0199  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2965000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3335
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 5.92     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.00282  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2966000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3427
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0254  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2967000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3413
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0381   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2968000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3154
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0439   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2969000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3296
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0378   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2970000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3248
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0228   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2971000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3268
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0395   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2972000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3363
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0402   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2973000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3198
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 4.26     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0387   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2974000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3199
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0157  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2975000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0135  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2976000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3294
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0058  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2977000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3304
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00147  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.4     |
| timestep                           | 2978000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 4.22     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0222  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2979000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00186 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2980000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0204  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2981000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3240
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0348  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2982000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3275
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0379  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2983000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0347  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2984000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.76     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.012   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2985000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3202
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0202   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2986000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 4.6      |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0256   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2987000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3284
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0293  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2988000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3331
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0226  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.2     |
| timestep                           | 2989000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0125  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2990000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3389
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.79     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00491 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2991000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00903 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2992000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3306
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.000619 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2993000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3346
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 7.74     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0224   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2994000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3261
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0091  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2995000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0299  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2996000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3283
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0197  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2997000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3316
-----------------------------------------------------------------------------------
| alpha                              | 0.141     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 75.2      |
| eval/normalized_episode_reward_std | 6.89      |
| loss/actor                         | -675      |
| loss/alpha                         | -0.000866 |
| loss/critic1                       | 14.2      |
| loss/critic2                       | 14        |
| timestep                           | 2998000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3279
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 8.55     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0183  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2999000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 3000000  |
----------------------------------------------------------------------------------
total time: 116554.28s
