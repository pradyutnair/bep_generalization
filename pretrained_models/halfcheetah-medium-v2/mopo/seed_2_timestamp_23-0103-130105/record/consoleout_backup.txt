Training dynamics:
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.6136621 |
| loss/dynamics_train_loss   | -8.93     |
| timestep                   | 1         |
---------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.4785367 |
| loss/dynamics_train_loss   | -27.3     |
| timestep                   | 2         |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.47126603 |
| loss/dynamics_train_loss   | -31.3      |
| timestep                   | 3          |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.45205092 |
| loss/dynamics_train_loss   | -33.2      |
| timestep                   | 4          |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.43205136 |
| loss/dynamics_train_loss   | -34.5      |
| timestep                   | 5          |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.41540438 |
| loss/dynamics_train_loss   | -35.5      |
| timestep                   | 6          |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.4008933 |
| loss/dynamics_train_loss   | -36.2     |
| timestep                   | 7         |
---------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.3876244 |
| loss/dynamics_train_loss   | -36.8     |
| timestep                   | 8         |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.38399392 |
| loss/dynamics_train_loss   | -37.3      |
| timestep                   | 9          |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.3650902 |
| loss/dynamics_train_loss   | -37.7     |
| timestep                   | 10        |
---------------------------------------------------------------------------
--------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.357003 |
| loss/dynamics_train_loss   | -38.1    |
| timestep                   | 11       |
--------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.34719467 |
| loss/dynamics_train_loss   | -38.5      |
| timestep                   | 12         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.33702865 |
| loss/dynamics_train_loss   | -38.7      |
| timestep                   | 13         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.3293918 |
| loss/dynamics_train_loss   | -39       |
| timestep                   | 14        |
---------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.3211023 |
| loss/dynamics_train_loss   | -39.3     |
| timestep                   | 15        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.31074518 |
| loss/dynamics_train_loss   | -39.5      |
| timestep                   | 16         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.3100082 |
| loss/dynamics_train_loss   | -39.7     |
| timestep                   | 17        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.29967037 |
| loss/dynamics_train_loss   | -40        |
| timestep                   | 18         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.30063918 |
| loss/dynamics_train_loss   | -40.2      |
| timestep                   | 19         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.29289007 |
| loss/dynamics_train_loss   | -40.2      |
| timestep                   | 20         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.2784122 |
| loss/dynamics_train_loss   | -40.5     |
| timestep                   | 21        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.27931175 |
| loss/dynamics_train_loss   | -40.7      |
| timestep                   | 22         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.2736166 |
| loss/dynamics_train_loss   | -40.8     |
| timestep                   | 23        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.26914203 |
| loss/dynamics_train_loss   | -41        |
| timestep                   | 24         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.25790542 |
| loss/dynamics_train_loss   | -41.1      |
| timestep                   | 25         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.24999276 |
| loss/dynamics_train_loss   | -41.2      |
| timestep                   | 26         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.24739948 |
| loss/dynamics_train_loss   | -41.3      |
| timestep                   | 27         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.24258295 |
| loss/dynamics_train_loss   | -41.4      |
| timestep                   | 28         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.24440375 |
| loss/dynamics_train_loss   | -41.5      |
| timestep                   | 29         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.24826705 |
| loss/dynamics_train_loss   | -41.6      |
| timestep                   | 30         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.23250297 |
| loss/dynamics_train_loss   | -41.7      |
| timestep                   | 31         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.23008528 |
| loss/dynamics_train_loss   | -41.9      |
| timestep                   | 32         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.22293854 |
| loss/dynamics_train_loss   | -41.9      |
| timestep                   | 33         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.21862797 |
| loss/dynamics_train_loss   | -42        |
| timestep                   | 34         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.20932356 |
| loss/dynamics_train_loss   | -42.1      |
| timestep                   | 35         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.21262023 |
| loss/dynamics_train_loss   | -42.2      |
| timestep                   | 36         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.20661369 |
| loss/dynamics_train_loss   | -42.2      |
| timestep                   | 37         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.19742966 |
| loss/dynamics_train_loss   | -42.4      |
| timestep                   | 38         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.19006953 |
| loss/dynamics_train_loss   | -42.5      |
| timestep                   | 39         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18402079 |
| loss/dynamics_train_loss   | -42.5      |
| timestep                   | 40         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18423805 |
| loss/dynamics_train_loss   | -42.6      |
| timestep                   | 41         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18038881 |
| loss/dynamics_train_loss   | -42.5      |
| timestep                   | 42         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17231436 |
| loss/dynamics_train_loss   | -42.7      |
| timestep                   | 43         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16432539 |
| loss/dynamics_train_loss   | -42.8      |
| timestep                   | 44         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1668488 |
| loss/dynamics_train_loss   | -42.7     |
| timestep                   | 45        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16889118 |
| loss/dynamics_train_loss   | -42.9      |
| timestep                   | 46         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16178873 |
| loss/dynamics_train_loss   | -42.9      |
| timestep                   | 47         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16853698 |
| loss/dynamics_train_loss   | -43        |
| timestep                   | 48         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.15829766 |
| loss/dynamics_train_loss   | -43        |
| timestep                   | 49         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.15333205 |
| loss/dynamics_train_loss   | -43.1      |
| timestep                   | 50         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1565974 |
| loss/dynamics_train_loss   | -43.2     |
| timestep                   | 51        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.15553568 |
| loss/dynamics_train_loss   | -43.2      |
| timestep                   | 52         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.15437731 |
| loss/dynamics_train_loss   | -43.2      |
| timestep                   | 53         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.15342128 |
| loss/dynamics_train_loss   | -43.3      |
| timestep                   | 54         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.15043311 |
| loss/dynamics_train_loss   | -43.3      |
| timestep                   | 55         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.15191467 |
| loss/dynamics_train_loss   | -43.4      |
| timestep                   | 56         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.15152003 |
| loss/dynamics_train_loss   | -43.5      |
| timestep                   | 57         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.15507254 |
| loss/dynamics_train_loss   | -43.5      |
| timestep                   | 58         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.14203674 |
| loss/dynamics_train_loss   | -43.6      |
| timestep                   | 59         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1427458 |
| loss/dynamics_train_loss   | -43.6     |
| timestep                   | 60        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.14615336 |
| loss/dynamics_train_loss   | -43.7      |
| timestep                   | 61         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1477154 |
| loss/dynamics_train_loss   | -43.7     |
| timestep                   | 62        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.14185278 |
| loss/dynamics_train_loss   | -43.7      |
| timestep                   | 63         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.14359604 |
| loss/dynamics_train_loss   | -43.7      |
| timestep                   | 64         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.13640212 |
| loss/dynamics_train_loss   | -43.9      |
| timestep                   | 65         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.13603303 |
| loss/dynamics_train_loss   | -43.9      |
| timestep                   | 66         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.13632907 |
| loss/dynamics_train_loss   | -43.9      |
| timestep                   | 67         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.13726619 |
| loss/dynamics_train_loss   | -44        |
| timestep                   | 68         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.14173293 |
| loss/dynamics_train_loss   | -43.9      |
| timestep                   | 69         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.14115308 |
| loss/dynamics_train_loss   | -44        |
| timestep                   | 70         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1349262 |
| loss/dynamics_train_loss   | -44.1     |
| timestep                   | 71        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.13180585 |
| loss/dynamics_train_loss   | -44.1      |
| timestep                   | 72         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1321955 |
| loss/dynamics_train_loss   | -44.2     |
| timestep                   | 73        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.14000382 |
| loss/dynamics_train_loss   | -44.2      |
| timestep                   | 74         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.13134125 |
| loss/dynamics_train_loss   | -44.3      |
| timestep                   | 75         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12968886 |
| loss/dynamics_train_loss   | -44.3      |
| timestep                   | 76         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12461966 |
| loss/dynamics_train_loss   | -44.4      |
| timestep                   | 77         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12596127 |
| loss/dynamics_train_loss   | -44.4      |
| timestep                   | 78         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12848233 |
| loss/dynamics_train_loss   | -44.4      |
| timestep                   | 79         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.13062464 |
| loss/dynamics_train_loss   | -44.4      |
| timestep                   | 80         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12562084 |
| loss/dynamics_train_loss   | -44.5      |
| timestep                   | 81         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12859127 |
| loss/dynamics_train_loss   | -44.5      |
| timestep                   | 82         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12718709 |
| loss/dynamics_train_loss   | -44.6      |
| timestep                   | 83         |
----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.122085616 |
| loss/dynamics_train_loss   | -44.6       |
| timestep                   | 84          |
-----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11818323 |
| loss/dynamics_train_loss   | -44.6      |
| timestep                   | 85         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12205348 |
| loss/dynamics_train_loss   | -44.7      |
| timestep                   | 86         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1321182 |
| loss/dynamics_train_loss   | -44.6     |
| timestep                   | 87        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12571177 |
| loss/dynamics_train_loss   | -44.7      |
| timestep                   | 88         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12224492 |
| loss/dynamics_train_loss   | -44.8      |
| timestep                   | 89         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11866327 |
| loss/dynamics_train_loss   | -44.8      |
| timestep                   | 90         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12645732 |
| loss/dynamics_train_loss   | -44.8      |
| timestep                   | 91         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12231307 |
| loss/dynamics_train_loss   | -44.8      |
| timestep                   | 92         |
----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.118971586 |
| loss/dynamics_train_loss   | -44.8       |
| timestep                   | 93          |
-----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11832017 |
| loss/dynamics_train_loss   | -44.9      |
| timestep                   | 94         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12108803 |
| loss/dynamics_train_loss   | -44.8      |
| timestep                   | 95         |
----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.113923356 |
| loss/dynamics_train_loss   | -45         |
| timestep                   | 96          |
-----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11481533 |
| loss/dynamics_train_loss   | -45        |
| timestep                   | 97         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.12001018 |
| loss/dynamics_train_loss   | -45.1      |
| timestep                   | 98         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11291289 |
| loss/dynamics_train_loss   | -45.1      |
| timestep                   | 99         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11511324 |
| loss/dynamics_train_loss   | -45.2      |
| timestep                   | 100        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11612998 |
| loss/dynamics_train_loss   | -45.1      |
| timestep                   | 101        |
----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.115360044 |
| loss/dynamics_train_loss   | -45.3       |
| timestep                   | 102         |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.121523306 |
| loss/dynamics_train_loss   | -45.1       |
| timestep                   | 103         |
-----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11161622 |
| loss/dynamics_train_loss   | -45.2      |
| timestep                   | 104        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11252447 |
| loss/dynamics_train_loss   | -45.3      |
| timestep                   | 105        |
----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.115755394 |
| loss/dynamics_train_loss   | -45.3       |
| timestep                   | 106         |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.111613214 |
| loss/dynamics_train_loss   | -45.3       |
| timestep                   | 107         |
-----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11180983 |
| loss/dynamics_train_loss   | -45.4      |
| timestep                   | 108        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11420117 |
| loss/dynamics_train_loss   | -45.4      |
| timestep                   | 109        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11328991 |
| loss/dynamics_train_loss   | -45.4      |
| timestep                   | 110        |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1158033 |
| loss/dynamics_train_loss   | -45.4     |
| timestep                   | 111       |
---------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1188183 |
| loss/dynamics_train_loss   | -45.5     |
| timestep                   | 112       |
---------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.111173764 |
| loss/dynamics_train_loss   | -45.5       |
| timestep                   | 113         |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.116252325 |
| loss/dynamics_train_loss   | -45.5       |
| timestep                   | 114         |
-----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11312573 |
| loss/dynamics_train_loss   | -45.6      |
| timestep                   | 115        |
----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.112328544 |
| loss/dynamics_train_loss   | -45.5       |
| timestep                   | 116         |
-----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11292032 |
| loss/dynamics_train_loss   | -45.6      |
| timestep                   | 117        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10817649 |
| loss/dynamics_train_loss   | -45.7      |
| timestep                   | 118        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11140726 |
| loss/dynamics_train_loss   | -45.5      |
| timestep                   | 119        |
----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.110634364 |
| loss/dynamics_train_loss   | -45.6       |
| timestep                   | 120         |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.112698235 |
| loss/dynamics_train_loss   | -45.7       |
| timestep                   | 121         |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.116577506 |
| loss/dynamics_train_loss   | -45.7       |
| timestep                   | 122         |
-----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10896536 |
| loss/dynamics_train_loss   | -45.8      |
| timestep                   | 123        |
----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.109123275 |
| loss/dynamics_train_loss   | -45.8       |
| timestep                   | 124         |
-----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11001124 |
| loss/dynamics_train_loss   | -45.9      |
| timestep                   | 125        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11454364 |
| loss/dynamics_train_loss   | -45.8      |
| timestep                   | 126        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11405907 |
| loss/dynamics_train_loss   | -45.7      |
| timestep                   | 127        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11187998 |
| loss/dynamics_train_loss   | -45.7      |
| timestep                   | 128        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10717889 |
| loss/dynamics_train_loss   | -45.9      |
| timestep                   | 129        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10653217 |
| loss/dynamics_train_loss   | -45.9      |
| timestep                   | 130        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10709815 |
| loss/dynamics_train_loss   | -46        |
| timestep                   | 131        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11051879 |
| loss/dynamics_train_loss   | -45.9      |
| timestep                   | 132        |
----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.114112996 |
| loss/dynamics_train_loss   | -46         |
| timestep                   | 133         |
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.112898566 |
| loss/dynamics_train_loss   | -46         |
| timestep                   | 134         |
-----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10605929 |
| loss/dynamics_train_loss   | -46.1      |
| timestep                   | 135        |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1076756 |
| loss/dynamics_train_loss   | -46.1     |
| timestep                   | 136       |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11244972 |
| loss/dynamics_train_loss   | -46        |
| timestep                   | 137        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10899402 |
| loss/dynamics_train_loss   | -46.1      |
| timestep                   | 138        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10704877 |
| loss/dynamics_train_loss   | -46        |
| timestep                   | 139        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11269166 |
| loss/dynamics_train_loss   | -46.2      |
| timestep                   | 140        |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1105126 |
| loss/dynamics_train_loss   | -46.1     |
| timestep                   | 141       |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10840897 |
| loss/dynamics_train_loss   | -46.1      |
| timestep                   | 142        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11107097 |
| loss/dynamics_train_loss   | -46.2      |
| timestep                   | 143        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10433297 |
| loss/dynamics_train_loss   | -46.2      |
| timestep                   | 144        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10877194 |
| loss/dynamics_train_loss   | -46.3      |
| timestep                   | 145        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11025212 |
| loss/dynamics_train_loss   | -46.2      |
| timestep                   | 146        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.10744194 |
| loss/dynamics_train_loss   | -46.3      |
| timestep                   | 147        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.11077146 |
| loss/dynamics_train_loss   | -46.3      |
| timestep                   | 148        |
----------------------------------------------------------------------------
-----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.109210595 |
| loss/dynamics_train_loss   | -46.3       |
| timestep                   | 149         |
-----------------------------------------------------------------------------
elites:[4, 2, 1, 3, 5] , holdout loss: 0.09765802323818207
num rollout transitions: 250000, reward mean: 3.5950
----------------------------------------------------------------------------------
| alpha                              | 0.951    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.25     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -24.6    |
| loss/alpha                         | -0.505   |
| loss/critic1                       | 3.17     |
| loss/critic2                       | 3.2      |
| timestep                           | 1000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.8350
----------------------------------------------------------------------------------
| alpha                              | 0.86     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.25     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -50.6    |
| loss/alpha                         | -1.5     |
| loss/critic1                       | 4.57     |
| loss/critic2                       | 4.57     |
| timestep                           | 2000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.8514
----------------------------------------------------------------------------------
| alpha                              | 0.779    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.24     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -72.2    |
| loss/alpha                         | -2.47    |
| loss/critic1                       | 8.03     |
| loss/critic2                       | 8.04     |
| timestep                           | 3000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9186
----------------------------------------------------------------------------------
| alpha                              | 0.706    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.23     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -89.5    |
| loss/alpha                         | -3.34    |
| loss/critic1                       | 11.2     |
| loss/critic2                       | 11.2     |
| timestep                           | 4000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9615
----------------------------------------------------------------------------------
| alpha                              | 0.64     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.22     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -104     |
| loss/alpha                         | -4.05    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 5000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0001
----------------------------------------------------------------------------------
| alpha                              | 0.583    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.19     |
| eval/normalized_episode_reward_std | 2.27     |
| loss/actor                         | -116     |
| loss/alpha                         | -4.52    |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.4     |
| timestep                           | 6000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9760
----------------------------------------------------------------------------------
| alpha                              | 0.531    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 1.68     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -126     |
| loss/alpha                         | -4.81    |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.4     |
| timestep                           | 7000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0056
----------------------------------------------------------------------------------
| alpha                              | 0.485    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 0.763    |
| eval/normalized_episode_reward_std | 4.18     |
| loss/actor                         | -136     |
| loss/alpha                         | -4.93    |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 21.3     |
| timestep                           | 8000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0132
----------------------------------------------------------------------------------
| alpha                              | 0.444    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 0.618    |
| eval/normalized_episode_reward_std | 4.97     |
| loss/actor                         | -145     |
| loss/alpha                         | -5.03    |
| loss/critic1                       | 26.2     |
| loss/critic2                       | 25.1     |
| timestep                           | 9000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0204
----------------------------------------------------------------------------------
| alpha                              | 0.405    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -0.316   |
| eval/normalized_episode_reward_std | 5.24     |
| loss/actor                         | -152     |
| loss/alpha                         | -5.08    |
| loss/critic1                       | 30.5     |
| loss/critic2                       | 29.1     |
| timestep                           | 10000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0178
----------------------------------------------------------------------------------
| alpha                              | 0.371    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -1.82    |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -159     |
| loss/alpha                         | -5.01    |
| loss/critic1                       | 35.6     |
| loss/critic2                       | 34.1     |
| timestep                           | 11000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0290
----------------------------------------------------------------------------------
| alpha                              | 0.339    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -0.951   |
| eval/normalized_episode_reward_std | 6.18     |
| loss/actor                         | -164     |
| loss/alpha                         | -4.89    |
| loss/critic1                       | 40       |
| loss/critic2                       | 38.5     |
| timestep                           | 12000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0388
----------------------------------------------------------------------------------
| alpha                              | 0.31     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 0.477    |
| eval/normalized_episode_reward_std | 5.75     |
| loss/actor                         | -168     |
| loss/alpha                         | -4.78    |
| loss/critic1                       | 41.5     |
| loss/critic2                       | 40.2     |
| timestep                           | 13000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0540
----------------------------------------------------------------------------------
| alpha                              | 0.284    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 1.17     |
| eval/normalized_episode_reward_std | 4.89     |
| loss/actor                         | -171     |
| loss/alpha                         | -4.61    |
| loss/critic1                       | 42.9     |
| loss/critic2                       | 41.9     |
| timestep                           | 14000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0915
----------------------------------------------------------------------------------
| alpha                              | 0.26     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -0.355   |
| eval/normalized_episode_reward_std | 3.86     |
| loss/actor                         | -174     |
| loss/alpha                         | -4.2     |
| loss/critic1                       | 46.4     |
| loss/critic2                       | 45.8     |
| timestep                           | 15000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1083
----------------------------------------------------------------------------------
| alpha                              | 0.24     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.48     |
| eval/normalized_episode_reward_std | 7.41     |
| loss/actor                         | -176     |
| loss/alpha                         | -3.36    |
| loss/critic1                       | 51.1     |
| loss/critic2                       | 50.4     |
| timestep                           | 16000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0858
----------------------------------------------------------------------------------
| alpha                              | 0.223    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 1.62     |
| eval/normalized_episode_reward_std | 5.73     |
| loss/actor                         | -179     |
| loss/alpha                         | -2.58    |
| loss/critic1                       | 53       |
| loss/critic2                       | 52.3     |
| timestep                           | 17000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0890
----------------------------------------------------------------------------------
| alpha                              | 0.209    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.68     |
| eval/normalized_episode_reward_std | 5.04     |
| loss/actor                         | -182     |
| loss/alpha                         | -1.71    |
| loss/critic1                       | 55.4     |
| loss/critic2                       | 55.2     |
| timestep                           | 18000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1101
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 8.51     |
| eval/normalized_episode_reward_std | 8.95     |
| loss/actor                         | -185     |
| loss/alpha                         | -0.991   |
| loss/critic1                       | 58.1     |
| loss/critic2                       | 57.7     |
| timestep                           | 19000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1205
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 4.75     |
| eval/normalized_episode_reward_std | 5.17     |
| loss/actor                         | -189     |
| loss/alpha                         | -0.379   |
| loss/critic1                       | 59.1     |
| loss/critic2                       | 58.8     |
| timestep                           | 20000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1193
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 7.08     |
| eval/normalized_episode_reward_std | 8.15     |
| loss/actor                         | -193     |
| loss/alpha                         | -0.222   |
| loss/critic1                       | 56       |
| loss/critic2                       | 55.7     |
| timestep                           | 21000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1209
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.82     |
| eval/normalized_episode_reward_std | 7.09     |
| loss/actor                         | -196     |
| loss/alpha                         | 0.062    |
| loss/critic1                       | 64.7     |
| loss/critic2                       | 64.4     |
| timestep                           | 22000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1570
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 4.43     |
| eval/normalized_episode_reward_std | 6.01     |
| loss/actor                         | -200     |
| loss/alpha                         | 0.218    |
| loss/critic1                       | 67.3     |
| loss/critic2                       | 66.9     |
| timestep                           | 23000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1570
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 9.15     |
| eval/normalized_episode_reward_std | 8.55     |
| loss/actor                         | -204     |
| loss/alpha                         | 0.208    |
| loss/critic1                       | 77.9     |
| loss/critic2                       | 77.4     |
| timestep                           | 24000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1663
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 14.6     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -207     |
| loss/alpha                         | 0.231    |
| loss/critic1                       | 78.6     |
| loss/critic2                       | 78.1     |
| timestep                           | 25000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1859
----------------------------------------------------------------------------------
| alpha                              | 0.214    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 14.7     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -211     |
| loss/alpha                         | 0.228    |
| loss/critic1                       | 82.6     |
| loss/critic2                       | 82       |
| timestep                           | 26000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1546
----------------------------------------------------------------------------------
| alpha                              | 0.219    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 18       |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -214     |
| loss/alpha                         | 0.00209  |
| loss/critic1                       | 79.4     |
| loss/critic2                       | 78.7     |
| timestep                           | 27000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2142
----------------------------------------------------------------------------------
| alpha                              | 0.221    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 13.3     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -218     |
| loss/alpha                         | 0.108    |
| loss/critic1                       | 76       |
| loss/critic2                       | 75.7     |
| timestep                           | 28000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2034
----------------------------------------------------------------------------------
| alpha                              | 0.229    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 29.1     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -221     |
| loss/alpha                         | 0.18     |
| loss/critic1                       | 85.5     |
| loss/critic2                       | 85.4     |
| timestep                           | 29000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1913
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 36.7     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -224     |
| loss/alpha                         | 0.121    |
| loss/critic1                       | 83       |
| loss/critic2                       | 83.1     |
| timestep                           | 30000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1640
----------------------------------------------------------------------------------
| alpha                              | 0.24     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 27.1     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -228     |
| loss/alpha                         | 0.0158   |
| loss/critic1                       | 80.6     |
| loss/critic2                       | 81.3     |
| timestep                           | 31000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2054
----------------------------------------------------------------------------------
| alpha                              | 0.241    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 40.3     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -231     |
| loss/alpha                         | 0.0657   |
| loss/critic1                       | 78.1     |
| loss/critic2                       | 78.5     |
| timestep                           | 32000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1955
----------------------------------------------------------------------------------
| alpha                              | 0.247    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 34.7     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -234     |
| loss/alpha                         | 0.0864   |
| loss/critic1                       | 80.4     |
| loss/critic2                       | 80.7     |
| timestep                           | 33000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2287
----------------------------------------------------------------------------------
| alpha                              | 0.25     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 23       |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -239     |
| loss/alpha                         | 0.0574   |
| loss/critic1                       | 66.8     |
| loss/critic2                       | 66.5     |
| timestep                           | 34000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2441
----------------------------------------------------------------------------------
| alpha                              | 0.257    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47.7     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -242     |
| loss/alpha                         | 0.142    |
| loss/critic1                       | 71.7     |
| loss/critic2                       | 71.8     |
| timestep                           | 35000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2452
----------------------------------------------------------------------------------
| alpha                              | 0.264    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 36.7     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -246     |
| loss/alpha                         | 0.106    |
| loss/critic1                       | 74.2     |
| loss/critic2                       | 74.4     |
| timestep                           | 36000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2347
----------------------------------------------------------------------------------
| alpha                              | 0.27     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 26.3     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -249     |
| loss/alpha                         | 0.0628   |
| loss/critic1                       | 73.9     |
| loss/critic2                       | 74.1     |
| timestep                           | 37000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2369
----------------------------------------------------------------------------------
| alpha                              | 0.275    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 35.1     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -253     |
| loss/alpha                         | 0.0922   |
| loss/critic1                       | 78.6     |
| loss/critic2                       | 78.6     |
| timestep                           | 38000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2425
----------------------------------------------------------------------------------
| alpha                              | 0.279    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 30.7     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -256     |
| loss/alpha                         | 0.0503   |
| loss/critic1                       | 81.4     |
| loss/critic2                       | 81.5     |
| timestep                           | 39000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2308
----------------------------------------------------------------------------------
| alpha                              | 0.281    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 41       |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -260     |
| loss/alpha                         | 0.0202   |
| loss/critic1                       | 74.3     |
| loss/critic2                       | 74.4     |
| timestep                           | 40000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2248
----------------------------------------------------------------------------------
| alpha                              | 0.282    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 23.9     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -264     |
| loss/alpha                         | 0.0238   |
| loss/critic1                       | 69.4     |
| loss/critic2                       | 69.3     |
| timestep                           | 41000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2467
----------------------------------------------------------------------------------
| alpha                              | 0.288    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 25.6     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -267     |
| loss/alpha                         | 0.07     |
| loss/critic1                       | 79.3     |
| loss/critic2                       | 79       |
| timestep                           | 42000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2457
----------------------------------------------------------------------------------
| alpha                              | 0.292    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 45.6     |
| eval/normalized_episode_reward_std | 13.2     |
| loss/actor                         | -270     |
| loss/alpha                         | 0.0629   |
| loss/critic1                       | 74.9     |
| loss/critic2                       | 74.2     |
| timestep                           | 43000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2418
----------------------------------------------------------------------------------
| alpha                              | 0.295    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 18.7     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -273     |
| loss/alpha                         | 0.0118   |
| loss/critic1                       | 73.5     |
| loss/critic2                       | 73.1     |
| timestep                           | 44000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2698
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.3     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -276     |
| loss/alpha                         | 0.0474   |
| loss/critic1                       | 74       |
| loss/critic2                       | 73.6     |
| timestep                           | 45000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2452
----------------------------------------------------------------------------------
| alpha                              | 0.297    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 28.5     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -279     |
| loss/alpha                         | -0.0518  |
| loss/critic1                       | 72.8     |
| loss/critic2                       | 72.2     |
| timestep                           | 46000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2595
----------------------------------------------------------------------------------
| alpha                              | 0.295    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 28.1     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -283     |
| loss/alpha                         | 0.00324  |
| loss/critic1                       | 64.8     |
| loss/critic2                       | 64.1     |
| timestep                           | 47000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2659
----------------------------------------------------------------------------------
| alpha                              | 0.293    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 23.3     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -286     |
| loss/alpha                         | -0.0584  |
| loss/critic1                       | 60.8     |
| loss/critic2                       | 60.1     |
| timestep                           | 48000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2687
----------------------------------------------------------------------------------
| alpha                              | 0.291    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 31.3     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -290     |
| loss/alpha                         | 0.0109   |
| loss/critic1                       | 65.3     |
| loss/critic2                       | 65       |
| timestep                           | 49000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2667
----------------------------------------------------------------------------------
| alpha                              | 0.293    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.2     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -294     |
| loss/alpha                         | 0.0243   |
| loss/critic1                       | 63.4     |
| loss/critic2                       | 62.8     |
| timestep                           | 50000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2549
----------------------------------------------------------------------------------
| alpha                              | 0.296    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.3     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -298     |
| loss/alpha                         | 0.0493   |
| loss/critic1                       | 60.2     |
| loss/critic2                       | 59.4     |
| timestep                           | 51000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2374
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 33.5     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -302     |
| loss/alpha                         | -0.00149 |
| loss/critic1                       | 61.9     |
| loss/critic2                       | 61.3     |
| timestep                           | 52000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2590
----------------------------------------------------------------------------------
| alpha                              | 0.3      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 23.7     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -305     |
| loss/alpha                         | 0.049    |
| loss/critic1                       | 60.5     |
| loss/critic2                       | 59.6     |
| timestep                           | 53000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2558
----------------------------------------------------------------------------------
| alpha                              | 0.302    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 18.2     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -309     |
| loss/alpha                         | 0.0463   |
| loss/critic1                       | 56       |
| loss/critic2                       | 55.4     |
| timestep                           | 54000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2697
----------------------------------------------------------------------------------
| alpha                              | 0.306    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.5     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -312     |
| loss/alpha                         | -0.0296  |
| loss/critic1                       | 59.5     |
| loss/critic2                       | 58.2     |
| timestep                           | 55000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2518
----------------------------------------------------------------------------------
| alpha                              | 0.304    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.8     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -315     |
| loss/alpha                         | 0.0135   |
| loss/critic1                       | 59.6     |
| loss/critic2                       | 58.8     |
| timestep                           | 56000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2706
----------------------------------------------------------------------------------
| alpha                              | 0.305    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 42.9     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -318     |
| loss/alpha                         | 0.0271   |
| loss/critic1                       | 58.8     |
| loss/critic2                       | 58.1     |
| timestep                           | 57000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2746
----------------------------------------------------------------------------------
| alpha                              | 0.303    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.2     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -321     |
| loss/alpha                         | -0.0642  |
| loss/critic1                       | 59.5     |
| loss/critic2                       | 58.6     |
| timestep                           | 58000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.301    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 41.7     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -325     |
| loss/alpha                         | 0.00873  |
| loss/critic1                       | 55       |
| loss/critic2                       | 54.4     |
| timestep                           | 59000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2624
----------------------------------------------------------------------------------
| alpha                              | 0.302    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 6.65     |
| eval/normalized_episode_reward_std | 7.16     |
| loss/actor                         | -328     |
| loss/alpha                         | -0.015   |
| loss/critic1                       | 51       |
| loss/critic2                       | 50.2     |
| timestep                           | 60000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2537
----------------------------------------------------------------------------------
| alpha                              | 0.303    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 45.1     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -331     |
| loss/alpha                         | 0.0385   |
| loss/critic1                       | 56.4     |
| loss/critic2                       | 55.3     |
| timestep                           | 61000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.304    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.3     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -334     |
| loss/alpha                         | -0.00544 |
| loss/critic1                       | 55.5     |
| loss/critic2                       | 54.3     |
| timestep                           | 62000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2776
-----------------------------------------------------------------------------------
| alpha                              | 0.304     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 38.6      |
| eval/normalized_episode_reward_std | 20.7      |
| loss/actor                         | -337      |
| loss/alpha                         | -6.95e-05 |
| loss/critic1                       | 54.3      |
| loss/critic2                       | 53.4      |
| timestep                           | 63000     |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2721
----------------------------------------------------------------------------------
| alpha                              | 0.304    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 31.2     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -340     |
| loss/alpha                         | 0.026    |
| loss/critic1                       | 55.3     |
| loss/critic2                       | 54.3     |
| timestep                           | 64000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2771
----------------------------------------------------------------------------------
| alpha                              | 0.305    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 46.7     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -342     |
| loss/alpha                         | -0.00528 |
| loss/critic1                       | 57.2     |
| loss/critic2                       | 56.3     |
| timestep                           | 65000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2615
----------------------------------------------------------------------------------
| alpha                              | 0.304    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47.8     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -345     |
| loss/alpha                         | -0.0436  |
| loss/critic1                       | 46.5     |
| loss/critic2                       | 45.9     |
| timestep                           | 66000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2761
----------------------------------------------------------------------------------
| alpha                              | 0.3      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 38.3     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -348     |
| loss/alpha                         | -0.00928 |
| loss/critic1                       | 45.5     |
| loss/critic2                       | 45.2     |
| timestep                           | 67000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2756
----------------------------------------------------------------------------------
| alpha                              | 0.299    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.2     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -350     |
| loss/alpha                         | -0.0182  |
| loss/critic1                       | 48.5     |
| loss/critic2                       | 47.8     |
| timestep                           | 68000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2773
----------------------------------------------------------------------------------
| alpha                              | 0.299    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 36.2     |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -353     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 47.2     |
| loss/critic2                       | 46.8     |
| timestep                           | 69000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2677
----------------------------------------------------------------------------------
| alpha                              | 0.296    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.4     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -356     |
| loss/alpha                         | -0.00283 |
| loss/critic1                       | 47.2     |
| loss/critic2                       | 46.7     |
| timestep                           | 70000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2850
----------------------------------------------------------------------------------
| alpha                              | 0.3      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.8     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -359     |
| loss/alpha                         | 0.0431   |
| loss/critic1                       | 48.8     |
| loss/critic2                       | 48.2     |
| timestep                           | 71000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2711
----------------------------------------------------------------------------------
| alpha                              | 0.302    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 45.3     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -362     |
| loss/alpha                         | 0.048    |
| loss/critic1                       | 46.9     |
| loss/critic2                       | 46       |
| timestep                           | 72000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2718
----------------------------------------------------------------------------------
| alpha                              | 0.303    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 42.6     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -365     |
| loss/alpha                         | -0.0408  |
| loss/critic1                       | 46.1     |
| loss/critic2                       | 45.7     |
| timestep                           | 73000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2837
----------------------------------------------------------------------------------
| alpha                              | 0.299    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.9     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -367     |
| loss/alpha                         | -0.0371  |
| loss/critic1                       | 44.8     |
| loss/critic2                       | 44.1     |
| timestep                           | 74000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2752
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 34.8     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -370     |
| loss/alpha                         | -0.00525 |
| loss/critic1                       | 42.8     |
| loss/critic2                       | 42.3     |
| timestep                           | 75000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2804
----------------------------------------------------------------------------------
| alpha                              | 0.3      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.7     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -373     |
| loss/alpha                         | 0.0254   |
| loss/critic1                       | 42.8     |
| loss/critic2                       | 42.4     |
| timestep                           | 76000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2715
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.9     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -375     |
| loss/alpha                         | -0.0417  |
| loss/critic1                       | 44.4     |
| loss/critic2                       | 43.6     |
| timestep                           | 77000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2767
----------------------------------------------------------------------------------
| alpha                              | 0.293    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 35.7     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -378     |
| loss/alpha                         | -0.0511  |
| loss/critic1                       | 43.8     |
| loss/critic2                       | 42.8     |
| timestep                           | 78000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2989
----------------------------------------------------------------------------------
| alpha                              | 0.291    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48       |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -381     |
| loss/alpha                         | -0.0224  |
| loss/critic1                       | 46.1     |
| loss/critic2                       | 45.8     |
| timestep                           | 79000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.292    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.7     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -383     |
| loss/alpha                         | 0.0258   |
| loss/critic1                       | 43.7     |
| loss/critic2                       | 43       |
| timestep                           | 80000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2680
----------------------------------------------------------------------------------
| alpha                              | 0.292    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.1     |
| eval/normalized_episode_reward_std | 8.44     |
| loss/actor                         | -386     |
| loss/alpha                         | -0.02    |
| loss/critic1                       | 44.1     |
| loss/critic2                       | 43.2     |
| timestep                           | 81000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2685
----------------------------------------------------------------------------------
| alpha                              | 0.289    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -388     |
| loss/alpha                         | -0.0536  |
| loss/critic1                       | 42.1     |
| loss/critic2                       | 41.7     |
| timestep                           | 82000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.288    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.3     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -390     |
| loss/alpha                         | 0.0172   |
| loss/critic1                       | 42.7     |
| loss/critic2                       | 42       |
| timestep                           | 83000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.289    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.1     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -392     |
| loss/alpha                         | -0.00623 |
| loss/critic1                       | 42.3     |
| loss/critic2                       | 42       |
| timestep                           | 84000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2964
----------------------------------------------------------------------------------
| alpha                              | 0.287    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 20       |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -394     |
| loss/alpha                         | -0.0297  |
| loss/critic1                       | 39.7     |
| loss/critic2                       | 39.3     |
| timestep                           | 85000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2814
----------------------------------------------------------------------------------
| alpha                              | 0.283    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.8     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -396     |
| loss/alpha                         | -0.054   |
| loss/critic1                       | 41.4     |
| loss/critic2                       | 40.6     |
| timestep                           | 86000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.281    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.3     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -398     |
| loss/alpha                         | -0.0324  |
| loss/critic1                       | 44.4     |
| loss/critic2                       | 44       |
| timestep                           | 87000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3000
----------------------------------------------------------------------------------
| alpha                              | 0.278    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47       |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -400     |
| loss/alpha                         | -0.0386  |
| loss/critic1                       | 40.2     |
| loss/critic2                       | 40       |
| timestep                           | 88000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2781
----------------------------------------------------------------------------------
| alpha                              | 0.275    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47.5     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -402     |
| loss/alpha                         | -0.0327  |
| loss/critic1                       | 39.6     |
| loss/critic2                       | 39       |
| timestep                           | 89000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2589
----------------------------------------------------------------------------------
| alpha                              | 0.273    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.9     |
| eval/normalized_episode_reward_std | 25.6     |
| loss/actor                         | -404     |
| loss/alpha                         | -0.0313  |
| loss/critic1                       | 38.3     |
| loss/critic2                       | 38       |
| timestep                           | 90000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2980
----------------------------------------------------------------------------------
| alpha                              | 0.272    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.4     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -406     |
| loss/alpha                         | 0.0192   |
| loss/critic1                       | 36.4     |
| loss/critic2                       | 36       |
| timestep                           | 91000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2816
----------------------------------------------------------------------------------
| alpha                              | 0.272    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.4     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -408     |
| loss/alpha                         | -0.0393  |
| loss/critic1                       | 36.4     |
| loss/critic2                       | 35.8     |
| timestep                           | 92000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.27     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.6     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -410     |
| loss/alpha                         | -0.0181  |
| loss/critic1                       | 36.9     |
| loss/critic2                       | 36.3     |
| timestep                           | 93000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3103
----------------------------------------------------------------------------------
| alpha                              | 0.268    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.7     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -412     |
| loss/alpha                         | -0.0438  |
| loss/critic1                       | 35.6     |
| loss/critic2                       | 34.7     |
| timestep                           | 94000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2956
----------------------------------------------------------------------------------
| alpha                              | 0.266    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.8     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -414     |
| loss/alpha                         | -0.00976 |
| loss/critic1                       | 36.6     |
| loss/critic2                       | 35.7     |
| timestep                           | 95000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.265    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53       |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -416     |
| loss/alpha                         | -0.0537  |
| loss/critic1                       | 36.9     |
| loss/critic2                       | 36.1     |
| timestep                           | 96000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2903
----------------------------------------------------------------------------------
| alpha                              | 0.265    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -418     |
| loss/alpha                         | 0.0768   |
| loss/critic1                       | 39       |
| loss/critic2                       | 38.3     |
| timestep                           | 97000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2760
----------------------------------------------------------------------------------
| alpha                              | 0.267    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.2     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -421     |
| loss/alpha                         | -0.0259  |
| loss/critic1                       | 36.9     |
| loss/critic2                       | 36.3     |
| timestep                           | 98000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2838
----------------------------------------------------------------------------------
| alpha                              | 0.264    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.2     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -422     |
| loss/alpha                         | -0.0576  |
| loss/critic1                       | 36.7     |
| loss/critic2                       | 36       |
| timestep                           | 99000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2986
----------------------------------------------------------------------------------
| alpha                              | 0.262    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58       |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -424     |
| loss/alpha                         | 0.0157   |
| loss/critic1                       | 37.9     |
| loss/critic2                       | 37.4     |
| timestep                           | 100000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2996
----------------------------------------------------------------------------------
| alpha                              | 0.265    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 4.51     |
| loss/actor                         | -426     |
| loss/alpha                         | 0.0349   |
| loss/critic1                       | 39.3     |
| loss/critic2                       | 38.7     |
| timestep                           | 101000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.264    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 40.3     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -427     |
| loss/alpha                         | -0.0494  |
| loss/critic1                       | 36       |
| loss/critic2                       | 35.2     |
| timestep                           | 102000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3047
----------------------------------------------------------------------------------
| alpha                              | 0.265    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.4     |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -429     |
| loss/alpha                         | 0.0866   |
| loss/critic1                       | 37       |
| loss/critic2                       | 36.6     |
| timestep                           | 103000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2977
----------------------------------------------------------------------------------
| alpha                              | 0.268    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.3     |
| eval/normalized_episode_reward_std | 9.61     |
| loss/actor                         | -431     |
| loss/alpha                         | -0.00258 |
| loss/critic1                       | 36       |
| loss/critic2                       | 35.8     |
| timestep                           | 104000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2965
----------------------------------------------------------------------------------
| alpha                              | 0.267    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -433     |
| loss/alpha                         | -0.00441 |
| loss/critic1                       | 33.6     |
| loss/critic2                       | 33       |
| timestep                           | 105000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2847
----------------------------------------------------------------------------------
| alpha                              | 0.264    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.2     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -434     |
| loss/alpha                         | -0.113   |
| loss/critic1                       | 32.5     |
| loss/critic2                       | 32.1     |
| timestep                           | 106000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3088
----------------------------------------------------------------------------------
| alpha                              | 0.258    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -436     |
| loss/alpha                         | -0.0386  |
| loss/critic1                       | 33.7     |
| loss/critic2                       | 33       |
| timestep                           | 107000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3086
----------------------------------------------------------------------------------
| alpha                              | 0.255    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.1     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -437     |
| loss/alpha                         | -0.0611  |
| loss/critic1                       | 31.4     |
| loss/critic2                       | 31       |
| timestep                           | 108000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3144
----------------------------------------------------------------------------------
| alpha                              | 0.253    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.2     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -439     |
| loss/alpha                         | -0.0214  |
| loss/critic1                       | 33.4     |
| loss/critic2                       | 32.9     |
| timestep                           | 109000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.251    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -441     |
| loss/alpha                         | -0.0243  |
| loss/critic1                       | 37.3     |
| loss/critic2                       | 35.7     |
| timestep                           | 110000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3138
----------------------------------------------------------------------------------
| alpha                              | 0.251    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.1     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -443     |
| loss/alpha                         | 0.021    |
| loss/critic1                       | 33.1     |
| loss/critic2                       | 32.6     |
| timestep                           | 111000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3096
----------------------------------------------------------------------------------
| alpha                              | 0.25     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.5     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -444     |
| loss/alpha                         | -0.0286  |
| loss/critic1                       | 33.8     |
| loss/critic2                       | 33.3     |
| timestep                           | 112000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3061
----------------------------------------------------------------------------------
| alpha                              | 0.25     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57       |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -445     |
| loss/alpha                         | -0.00176 |
| loss/critic1                       | 34.3     |
| loss/critic2                       | 33.7     |
| timestep                           | 113000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3287
----------------------------------------------------------------------------------
| alpha                              | 0.25     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.3     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -447     |
| loss/alpha                         | -0.00594 |
| loss/critic1                       | 31.8     |
| loss/critic2                       | 31.7     |
| timestep                           | 114000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3159
----------------------------------------------------------------------------------
| alpha                              | 0.249    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.5     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -448     |
| loss/alpha                         | -0.0362  |
| loss/critic1                       | 31.7     |
| loss/critic2                       | 31.3     |
| timestep                           | 115000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.246    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.7     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -449     |
| loss/alpha                         | -0.0509  |
| loss/critic1                       | 31.1     |
| loss/critic2                       | 31       |
| timestep                           | 116000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.246    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 3.6      |
| loss/actor                         | -451     |
| loss/alpha                         | 0.0325   |
| loss/critic1                       | 29.3     |
| loss/critic2                       | 29.1     |
| timestep                           | 117000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3280
----------------------------------------------------------------------------------
| alpha                              | 0.246    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.7     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -452     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 30.5     |
| loss/critic2                       | 30       |
| timestep                           | 118000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3318
----------------------------------------------------------------------------------
| alpha                              | 0.246    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.1     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -453     |
| loss/alpha                         | 0.0233   |
| loss/critic1                       | 30.4     |
| loss/critic2                       | 30       |
| timestep                           | 119000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3389
----------------------------------------------------------------------------------
| alpha                              | 0.246    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.4     |
| eval/normalized_episode_reward_std | 9.42     |
| loss/actor                         | -454     |
| loss/alpha                         | -0.0649  |
| loss/critic1                       | 31.7     |
| loss/critic2                       | 31.1     |
| timestep                           | 120000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3193
----------------------------------------------------------------------------------
| alpha                              | 0.244    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.2     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -456     |
| loss/alpha                         | 0.0227   |
| loss/critic1                       | 29.7     |
| loss/critic2                       | 29.3     |
| timestep                           | 121000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3042
----------------------------------------------------------------------------------
| alpha                              | 0.243    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.2     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -457     |
| loss/alpha                         | -0.0684  |
| loss/critic1                       | 29.4     |
| loss/critic2                       | 28.9     |
| timestep                           | 122000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3256
----------------------------------------------------------------------------------
| alpha                              | 0.24     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.4     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -458     |
| loss/alpha                         | -0.033   |
| loss/critic1                       | 29.1     |
| loss/critic2                       | 28.5     |
| timestep                           | 123000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3300
----------------------------------------------------------------------------------
| alpha                              | 0.24     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.2     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -460     |
| loss/alpha                         | 0.0331   |
| loss/critic1                       | 28.5     |
| loss/critic2                       | 28.1     |
| timestep                           | 124000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3016
----------------------------------------------------------------------------------
| alpha                              | 0.24     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -461     |
| loss/alpha                         | -0.0297  |
| loss/critic1                       | 28.3     |
| loss/critic2                       | 28.1     |
| timestep                           | 125000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.238    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -462     |
| loss/alpha                         | -0.0195  |
| loss/critic1                       | 28.2     |
| loss/critic2                       | 27.7     |
| timestep                           | 126000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.238    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 8.86     |
| loss/actor                         | -463     |
| loss/alpha                         | -0.0225  |
| loss/critic1                       | 26.9     |
| loss/critic2                       | 26.6     |
| timestep                           | 127000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3556
----------------------------------------------------------------------------------
| alpha                              | 0.237    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 10.3     |
| loss/actor                         | -464     |
| loss/alpha                         | 0.0344   |
| loss/critic1                       | 27.3     |
| loss/critic2                       | 26.9     |
| timestep                           | 128000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3328
----------------------------------------------------------------------------------
| alpha                              | 0.238    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -466     |
| loss/alpha                         | -0.0364  |
| loss/critic1                       | 26.8     |
| loss/critic2                       | 26.1     |
| timestep                           | 129000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3074
----------------------------------------------------------------------------------
| alpha                              | 0.237    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -467     |
| loss/alpha                         | 0.00807  |
| loss/critic1                       | 27.7     |
| loss/critic2                       | 27.1     |
| timestep                           | 130000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3144
----------------------------------------------------------------------------------
| alpha                              | 0.239    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -469     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 27.7     |
| loss/critic2                       | 27.3     |
| timestep                           | 131000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.238    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -470     |
| loss/alpha                         | -0.0307  |
| loss/critic1                       | 27.1     |
| loss/critic2                       | 26.5     |
| timestep                           | 132000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3313
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.8     |
| eval/normalized_episode_reward_std | 7.41     |
| loss/actor                         | -471     |
| loss/alpha                         | -0.0723  |
| loss/critic1                       | 27       |
| loss/critic2                       | 26.5     |
| timestep                           | 133000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3263
----------------------------------------------------------------------------------
| alpha                              | 0.231    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.4     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -473     |
| loss/alpha                         | -0.072   |
| loss/critic1                       | 26.7     |
| loss/critic2                       | 26.4     |
| timestep                           | 134000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3306
----------------------------------------------------------------------------------
| alpha                              | 0.228    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -474     |
| loss/alpha                         | -0.0382  |
| loss/critic1                       | 26.9     |
| loss/critic2                       | 26.4     |
| timestep                           | 135000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3317
----------------------------------------------------------------------------------
| alpha                              | 0.229    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.4     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -475     |
| loss/alpha                         | 0.0664   |
| loss/critic1                       | 26.5     |
| loss/critic2                       | 26.1     |
| timestep                           | 136000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3374
----------------------------------------------------------------------------------
| alpha                              | 0.231    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -477     |
| loss/alpha                         | 0.0028   |
| loss/critic1                       | 28.1     |
| loss/critic2                       | 27.5     |
| timestep                           | 137000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3341
----------------------------------------------------------------------------------
| alpha                              | 0.232    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -478     |
| loss/alpha                         | 0.00113  |
| loss/critic1                       | 26.7     |
| loss/critic2                       | 26.5     |
| timestep                           | 138000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3183
----------------------------------------------------------------------------------
| alpha                              | 0.23     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -479     |
| loss/alpha                         | -0.0446  |
| loss/critic1                       | 26.6     |
| loss/critic2                       | 26.3     |
| timestep                           | 139000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3138
----------------------------------------------------------------------------------
| alpha                              | 0.229    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 37.7     |
| eval/normalized_episode_reward_std | 26.2     |
| loss/actor                         | -480     |
| loss/alpha                         | 0.0143   |
| loss/critic1                       | 25.5     |
| loss/critic2                       | 24.9     |
| timestep                           | 140000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3313
----------------------------------------------------------------------------------
| alpha                              | 0.232    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.2     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -481     |
| loss/alpha                         | 0.0838   |
| loss/critic1                       | 26.3     |
| loss/critic2                       | 26.1     |
| timestep                           | 141000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3277
----------------------------------------------------------------------------------
| alpha                              | 0.233    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.2     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -483     |
| loss/alpha                         | -0.0342  |
| loss/critic1                       | 26.1     |
| loss/critic2                       | 25.8     |
| timestep                           | 142000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3254
----------------------------------------------------------------------------------
| alpha                              | 0.231    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.3     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -483     |
| loss/alpha                         | -0.0155  |
| loss/critic1                       | 30       |
| loss/critic2                       | 29.7     |
| timestep                           | 143000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3175
----------------------------------------------------------------------------------
| alpha                              | 0.229    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.2     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -484     |
| loss/alpha                         | -0.0795  |
| loss/critic1                       | 27.6     |
| loss/critic2                       | 27.4     |
| timestep                           | 144000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.228    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -485     |
| loss/alpha                         | 0.0587   |
| loss/critic1                       | 28.5     |
| loss/critic2                       | 28.1     |
| timestep                           | 145000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3202
----------------------------------------------------------------------------------
| alpha                              | 0.23     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 6.97     |
| loss/actor                         | -486     |
| loss/alpha                         | -0.0553  |
| loss/critic1                       | 27.5     |
| loss/critic2                       | 27.1     |
| timestep                           | 146000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3336
----------------------------------------------------------------------------------
| alpha                              | 0.226    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -486     |
| loss/alpha                         | -0.0492  |
| loss/critic1                       | 27.3     |
| loss/critic2                       | 26.8     |
| timestep                           | 147000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3274
----------------------------------------------------------------------------------
| alpha                              | 0.224    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.1     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -487     |
| loss/alpha                         | -0.0204  |
| loss/critic1                       | 23.8     |
| loss/critic2                       | 23.3     |
| timestep                           | 148000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3178
----------------------------------------------------------------------------------
| alpha                              | 0.223    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -488     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 24.8     |
| timestep                           | 149000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3501
----------------------------------------------------------------------------------
| alpha                              | 0.224    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -490     |
| loss/alpha                         | 0.0677   |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 24.9     |
| timestep                           | 150000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3383
----------------------------------------------------------------------------------
| alpha                              | 0.227    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.3     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -491     |
| loss/alpha                         | 0.0216   |
| loss/critic1                       | 25.4     |
| loss/critic2                       | 25.1     |
| timestep                           | 151000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3173
----------------------------------------------------------------------------------
| alpha                              | 0.225    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -492     |
| loss/alpha                         | -0.0906  |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 24.8     |
| timestep                           | 152000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3253
----------------------------------------------------------------------------------
| alpha                              | 0.224    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -493     |
| loss/alpha                         | 0.0646   |
| loss/critic1                       | 25       |
| loss/critic2                       | 24.6     |
| timestep                           | 153000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3165
----------------------------------------------------------------------------------
| alpha                              | 0.225    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -494     |
| loss/alpha                         | -0.037   |
| loss/critic1                       | 23.8     |
| loss/critic2                       | 23.3     |
| timestep                           | 154000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3389
----------------------------------------------------------------------------------
| alpha                              | 0.223    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.8     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -495     |
| loss/alpha                         | -0.0368  |
| loss/critic1                       | 23.1     |
| loss/critic2                       | 22.8     |
| timestep                           | 155000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3145
----------------------------------------------------------------------------------
| alpha                              | 0.222    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 31.6     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -496     |
| loss/alpha                         | -0.0529  |
| loss/critic1                       | 23       |
| loss/critic2                       | 22.5     |
| timestep                           | 156000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.219    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.2     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -497     |
| loss/alpha                         | -0.0169  |
| loss/critic1                       | 23.6     |
| loss/critic2                       | 23.1     |
| timestep                           | 157000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3166
----------------------------------------------------------------------------------
| alpha                              | 0.22     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.1     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -498     |
| loss/alpha                         | 0.00705  |
| loss/critic1                       | 24.2     |
| loss/critic2                       | 23.9     |
| timestep                           | 158000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3178
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48       |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -499     |
| loss/alpha                         | -0.0806  |
| loss/critic1                       | 24       |
| loss/critic2                       | 23.5     |
| timestep                           | 159000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3241
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 3.81     |
| loss/actor                         | -500     |
| loss/alpha                         | 0.0247   |
| loss/critic1                       | 24.5     |
| loss/critic2                       | 24       |
| timestep                           | 160000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3285
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59       |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -501     |
| loss/alpha                         | -0.0179  |
| loss/critic1                       | 24.5     |
| loss/critic2                       | 23.9     |
| timestep                           | 161000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3240
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -502     |
| loss/alpha                         | 0.039    |
| loss/critic1                       | 24.5     |
| loss/critic2                       | 24.1     |
| timestep                           | 162000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3211
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -503     |
| loss/alpha                         | 0.00162  |
| loss/critic1                       | 24.7     |
| loss/critic2                       | 24.7     |
| timestep                           | 163000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3441
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 11       |
| loss/actor                         | -504     |
| loss/alpha                         | -0.069   |
| loss/critic1                       | 23.9     |
| loss/critic2                       | 23.4     |
| timestep                           | 164000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3276
----------------------------------------------------------------------------------
| alpha                              | 0.214    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -504     |
| loss/alpha                         | -0.0402  |
| loss/critic1                       | 23.7     |
| loss/critic2                       | 23.4     |
| timestep                           | 165000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3212
----------------------------------------------------------------------------------
| alpha                              | 0.212    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -505     |
| loss/alpha                         | -0.082   |
| loss/critic1                       | 25.1     |
| loss/critic2                       | 24.9     |
| timestep                           | 166000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3459
----------------------------------------------------------------------------------
| alpha                              | 0.209    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47.5     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -506     |
| loss/alpha                         | -0.0343  |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.3     |
| timestep                           | 167000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3253
----------------------------------------------------------------------------------
| alpha                              | 0.209    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 8.69     |
| loss/actor                         | -507     |
| loss/alpha                         | 0.0584   |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.6     |
| timestep                           | 168000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3262
----------------------------------------------------------------------------------
| alpha                              | 0.21     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 28       |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -508     |
| loss/alpha                         | -0.0267  |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.2     |
| timestep                           | 169000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3257
----------------------------------------------------------------------------------
| alpha                              | 0.21     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -509     |
| loss/alpha                         | 0.0131   |
| loss/critic1                       | 24       |
| loss/critic2                       | 23.8     |
| timestep                           | 170000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3352
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -510     |
| loss/alpha                         | -0.0627  |
| loss/critic1                       | 24.2     |
| loss/critic2                       | 23.8     |
| timestep                           | 171000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3487
----------------------------------------------------------------------------------
| alpha                              | 0.207    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -511     |
| loss/alpha                         | -0.0115  |
| loss/critic1                       | 24.7     |
| loss/critic2                       | 24.3     |
| timestep                           | 172000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -512     |
| loss/alpha                         | -0.0432  |
| loss/critic1                       | 23.9     |
| loss/critic2                       | 23.7     |
| timestep                           | 173000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3356
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -512     |
| loss/alpha                         | 0.00617  |
| loss/critic1                       | 24.2     |
| loss/critic2                       | 23.7     |
| timestep                           | 174000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3176
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -513     |
| loss/alpha                         | -0.036   |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.1     |
| timestep                           | 175000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3156
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -514     |
| loss/alpha                         | 0.0263   |
| loss/critic1                       | 23.4     |
| loss/critic2                       | 23.1     |
| timestep                           | 176000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.5     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -515     |
| loss/alpha                         | 0.0124   |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.3     |
| timestep                           | 177000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3578
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61       |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -516     |
| loss/alpha                         | 0.0158   |
| loss/critic1                       | 22.2     |
| loss/critic2                       | 21.7     |
| timestep                           | 178000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3368
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.8     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -516     |
| loss/alpha                         | -0.00907 |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.2     |
| timestep                           | 179000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3432
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -517     |
| loss/alpha                         | -0.00153 |
| loss/critic1                       | 23       |
| loss/critic2                       | 22.9     |
| timestep                           | 180000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3379
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 8.56     |
| loss/actor                         | -518     |
| loss/alpha                         | -0.0291  |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22       |
| timestep                           | 181000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -518     |
| loss/alpha                         | 0.0207   |
| loss/critic1                       | 22.7     |
| loss/critic2                       | 22.4     |
| timestep                           | 182000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3422
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -519     |
| loss/alpha                         | 0.0208   |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.4     |
| timestep                           | 183000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3143
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -520     |
| loss/alpha                         | -0.0403  |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.3     |
| timestep                           | 184000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3429
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.5     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -520     |
| loss/alpha                         | -0.0473  |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 20.9     |
| timestep                           | 185000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55       |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -521     |
| loss/alpha                         | -0.0337  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.7     |
| timestep                           | 186000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3308
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -522     |
| loss/alpha                         | -0.00711 |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.9     |
| timestep                           | 187000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3255
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.3     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -523     |
| loss/alpha                         | -0.0289  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.6     |
| timestep                           | 188000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3298
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -523     |
| loss/alpha                         | -0.03    |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.6     |
| timestep                           | 189000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 5.01     |
| loss/actor                         | -524     |
| loss/alpha                         | 0.0229   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.3     |
| timestep                           | 190000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3269
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47.9     |
| eval/normalized_episode_reward_std | 25.5     |
| loss/actor                         | -525     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.3     |
| timestep                           | 191000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -525     |
| loss/alpha                         | 0.00607  |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.8     |
| timestep                           | 192000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3440
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -526     |
| loss/alpha                         | 0.0469   |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.3     |
| timestep                           | 193000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3505
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -526     |
| loss/alpha                         | -0.0692  |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.8     |
| timestep                           | 194000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3299
-----------------------------------------------------------------------------------
| alpha                              | 0.198     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 70.5      |
| eval/normalized_episode_reward_std | 2.92      |
| loss/actor                         | -527      |
| loss/alpha                         | -0.000169 |
| loss/critic1                       | 21.2      |
| loss/critic2                       | 20.8      |
| timestep                           | 195000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3168
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -528     |
| loss/alpha                         | 0.0386   |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.2     |
| timestep                           | 196000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -529     |
| loss/alpha                         | -0.0794  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 21.7     |
| timestep                           | 197000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3375
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 2.6      |
| loss/actor                         | -529     |
| loss/alpha                         | -0.00402 |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 20.9     |
| timestep                           | 198000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3272
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 7.34     |
| loss/actor                         | -530     |
| loss/alpha                         | 0.0856   |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 20.6     |
| timestep                           | 199000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3384
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -531     |
| loss/alpha                         | -0.0167  |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.3     |
| timestep                           | 200000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3217
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -532     |
| loss/alpha                         | -0.047   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.2     |
| timestep                           | 201000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -533     |
| loss/alpha                         | -0.0117  |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.6     |
| timestep                           | 202000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3207
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -533     |
| loss/alpha                         | -0.029   |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.1     |
| timestep                           | 203000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3331
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.91     |
| loss/actor                         | -534     |
| loss/alpha                         | -0.0417  |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.1     |
| timestep                           | 204000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3322
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 4.1      |
| loss/actor                         | -534     |
| loss/alpha                         | 0.0138   |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 20.6     |
| timestep                           | 205000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3362
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 7.41     |
| loss/actor                         | -535     |
| loss/alpha                         | -0.0198  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.2     |
| timestep                           | 206000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3349
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -536     |
| loss/alpha                         | -0.0757  |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 19.9     |
| timestep                           | 207000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3397
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.7     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -537     |
| loss/alpha                         | 0.0216   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.3     |
| timestep                           | 208000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3301
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 4.63     |
| loss/actor                         | -538     |
| loss/alpha                         | 0.093    |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 19.9     |
| timestep                           | 209000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3371
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -538     |
| loss/alpha                         | -0.0773  |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.4     |
| timestep                           | 210000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3306
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -539     |
| loss/alpha                         | 0.0323   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 19.9     |
| timestep                           | 211000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3360
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -540     |
| loss/alpha                         | -0.0346  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.5     |
| timestep                           | 212000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3431
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -541     |
| loss/alpha                         | 0.0049   |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.8     |
| timestep                           | 213000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3252
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 4.12     |
| loss/actor                         | -542     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.3     |
| timestep                           | 214000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -543     |
| loss/alpha                         | 0.00832  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.3     |
| timestep                           | 215000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3324
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -544     |
| loss/alpha                         | 0.0308   |
| loss/critic1                       | 26.9     |
| loss/critic2                       | 26.4     |
| timestep                           | 216000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3208
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -545     |
| loss/alpha                         | -0.0175  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.2     |
| timestep                           | 217000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 2.57     |
| loss/actor                         | -546     |
| loss/alpha                         | -0.0439  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 18.9     |
| timestep                           | 218000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3337
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -547     |
| loss/alpha                         | 0.0517   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.1     |
| timestep                           | 219000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3185
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 2.53     |
| loss/actor                         | -547     |
| loss/alpha                         | -0.0148  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.5     |
| timestep                           | 220000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3139
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -547     |
| loss/alpha                         | -0.0353  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 18.9     |
| timestep                           | 221000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -548     |
| loss/alpha                         | 0.0335   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.5     |
| timestep                           | 222000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3366
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.5      |
| loss/actor                         | -548     |
| loss/alpha                         | -0.00479 |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 18.9     |
| timestep                           | 223000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3267
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -549     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.5     |
| timestep                           | 224000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3181
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -550     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 19.9     |
| timestep                           | 225000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3500
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -550     |
| loss/alpha                         | 0.0267   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.4     |
| timestep                           | 226000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3278
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -551     |
| loss/alpha                         | 0.0313   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 19.8     |
| timestep                           | 227000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3290
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -552     |
| loss/alpha                         | -0.0786  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.8     |
| timestep                           | 228000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3392
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -552     |
| loss/alpha                         | -0.0694  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18       |
| timestep                           | 229000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3392
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.3     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -553     |
| loss/alpha                         | -0.0524  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 18.9     |
| timestep                           | 230000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3345
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 2.63     |
| loss/actor                         | -554     |
| loss/alpha                         | 0.0872   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.2     |
| timestep                           | 231000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3335
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -554     |
| loss/alpha                         | -0.0173  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.1     |
| timestep                           | 232000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3351
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -554     |
| loss/alpha                         | -0.0273  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.5     |
| timestep                           | 233000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3294
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 2.56     |
| loss/actor                         | -555     |
| loss/alpha                         | -0.0358  |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.3     |
| timestep                           | 234000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3398
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -556     |
| loss/alpha                         | 0.03     |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.5     |
| timestep                           | 235000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3329
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -556     |
| loss/alpha                         | 0.063    |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.3     |
| timestep                           | 236000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3384
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -557     |
| loss/alpha                         | 0.0181   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.1     |
| timestep                           | 237000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3219
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -558     |
| loss/alpha                         | 0.0797   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.3     |
| timestep                           | 238000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -558     |
| loss/alpha                         | -0.00567 |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 19.9     |
| timestep                           | 239000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3397
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 4.31     |
| loss/actor                         | -559     |
| loss/alpha                         | -0.0251  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.7     |
| timestep                           | 240000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -560     |
| loss/alpha                         | -0.0142  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.2     |
| timestep                           | 241000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3469
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -561     |
| loss/alpha                         | 0.0221   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 19.6     |
| timestep                           | 242000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3116
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -561     |
| loss/alpha                         | -0.0311  |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20       |
| timestep                           | 243000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3239
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -562     |
| loss/alpha                         | -0.0452  |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.4     |
| timestep                           | 244000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -562     |
| loss/alpha                         | 0.0397   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.1     |
| timestep                           | 245000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3487
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -563     |
| loss/alpha                         | 0.0318   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.2     |
| timestep                           | 246000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3163
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 5.77     |
| loss/actor                         | -563     |
| loss/alpha                         | -0.0168  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.2     |
| timestep                           | 247000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -564     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 18.9     |
| timestep                           | 248000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3380
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -564     |
| loss/alpha                         | -0.0885  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 18.6     |
| timestep                           | 249000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3288
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -565     |
| loss/alpha                         | 0.0497   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 19.6     |
| timestep                           | 250000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3244
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -565     |
| loss/alpha                         | -0.0114  |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 21.9     |
| timestep                           | 251000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3370
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -566     |
| loss/alpha                         | -0.0157  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 19.9     |
| timestep                           | 252000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3040
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -567     |
| loss/alpha                         | -0.00573 |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.4     |
| timestep                           | 253000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3230
-----------------------------------------------------------------------------------
| alpha                              | 0.189     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 75.7      |
| eval/normalized_episode_reward_std | 3.29      |
| loss/actor                         | -567      |
| loss/alpha                         | -4.88e-06 |
| loss/critic1                       | 20.6      |
| loss/critic2                       | 20.1      |
| timestep                           | 254000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3363
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -567     |
| loss/alpha                         | 0.094    |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.1     |
| timestep                           | 255000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3253
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -567     |
| loss/alpha                         | -0.0198  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.5     |
| timestep                           | 256000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3342
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -568     |
| loss/alpha                         | -0.0701  |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 20.9     |
| timestep                           | 257000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3138
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -568     |
| loss/alpha                         | 0.0219   |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.8     |
| timestep                           | 258000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3210
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -568     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 20.9     |
| timestep                           | 259000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3249
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -569     |
| loss/alpha                         | -0.0165  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.5     |
| timestep                           | 260000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3069
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -569     |
| loss/alpha                         | -0.0413  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 19.9     |
| timestep                           | 261000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3194
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -570     |
| loss/alpha                         | 0.0223   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 19.8     |
| timestep                           | 262000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3245
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -570     |
| loss/alpha                         | 0.022    |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20       |
| timestep                           | 263000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3309
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -570     |
| loss/alpha                         | -0.00565 |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.2     |
| timestep                           | 264000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3253
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -570     |
| loss/alpha                         | 0.0137   |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.5     |
| timestep                           | 265000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3306
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -570     |
| loss/alpha                         | -0.136   |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.1     |
| timestep                           | 266000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3334
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 4.09     |
| loss/actor                         | -570     |
| loss/alpha                         | 0.0472   |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 20.8     |
| timestep                           | 267000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3360
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -570     |
| loss/alpha                         | 0.000175 |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.2     |
| timestep                           | 268000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3229
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.3     |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -570     |
| loss/alpha                         | -0.00593 |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.2     |
| timestep                           | 269000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3213
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -570     |
| loss/alpha                         | 0.0366   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.6     |
| timestep                           | 270000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3315
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 2.62     |
| loss/actor                         | -571     |
| loss/alpha                         | 0.0217   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20       |
| timestep                           | 271000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3368
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -571     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.7     |
| timestep                           | 272000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3323
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -571     |
| loss/alpha                         | -0.129   |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.1     |
| timestep                           | 273000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3416
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -571     |
| loss/alpha                         | -0.03    |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.4     |
| timestep                           | 274000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3388
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -572     |
| loss/alpha                         | -0.0381  |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.2     |
| timestep                           | 275000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3375
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -572     |
| loss/alpha                         | 0.0566   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.4     |
| timestep                           | 276000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3109
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -572     |
| loss/alpha                         | 0.0669   |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.8     |
| timestep                           | 277000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -572     |
| loss/alpha                         | 0.00248  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.7     |
| timestep                           | 278000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3188
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -572     |
| loss/alpha                         | 0.0382   |
| loss/critic1                       | 22.7     |
| loss/critic2                       | 22.5     |
| timestep                           | 279000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3155
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -572     |
| loss/alpha                         | -0.0238  |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.5     |
| timestep                           | 280000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3265
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -572     |
| loss/alpha                         | -0.0646  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 19.9     |
| timestep                           | 281000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3090
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -572     |
| loss/alpha                         | 0.0574   |
| loss/critic1                       | 22.9     |
| loss/critic2                       | 22.6     |
| timestep                           | 282000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3237
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 4.17     |
| loss/actor                         | -573     |
| loss/alpha                         | 0.05     |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.6     |
| timestep                           | 283000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3401
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -573     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 18.9     |
| timestep                           | 284000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3349
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 5.72     |
| loss/actor                         | -574     |
| loss/alpha                         | -0.0129  |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.7     |
| timestep                           | 285000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3358
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -574     |
| loss/alpha                         | 0.00619  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.1     |
| timestep                           | 286000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3392
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -575     |
| loss/alpha                         | 0.0458   |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.3     |
| timestep                           | 287000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3236
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -575     |
| loss/alpha                         | -0.00489 |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.5     |
| timestep                           | 288000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3371
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -576     |
| loss/alpha                         | -0.0782  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.3     |
| timestep                           | 289000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3392
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -576     |
| loss/alpha                         | 0.0324   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.3     |
| timestep                           | 290000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3340
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -577     |
| loss/alpha                         | -0.052   |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.3     |
| timestep                           | 291000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3307
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -577     |
| loss/alpha                         | 0.0346   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.6     |
| timestep                           | 292000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3243
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -578     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.4     |
| timestep                           | 293000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3147
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -578     |
| loss/alpha                         | -0.0135  |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.3     |
| timestep                           | 294000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3373
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -578     |
| loss/alpha                         | 0.0333   |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.5     |
| timestep                           | 295000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3195
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -579     |
| loss/alpha                         | 0.0378   |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.1     |
| timestep                           | 296000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3361
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -579     |
| loss/alpha                         | -0.024   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20       |
| timestep                           | 297000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3306
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -580     |
| loss/alpha                         | 0.0419   |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 21       |
| timestep                           | 298000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3383
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -580     |
| loss/alpha                         | -0.00707 |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.3     |
| timestep                           | 299000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3486
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -581     |
| loss/alpha                         | -0.142   |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.8     |
| timestep                           | 300000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3228
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 5.45     |
| loss/actor                         | -581     |
| loss/alpha                         | -0.0891  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.1     |
| timestep                           | 301000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3297
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -582     |
| loss/alpha                         | 0.0136   |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.8     |
| timestep                           | 302000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3373
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 6.08     |
| loss/actor                         | -582     |
| loss/alpha                         | 0.0795   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.5     |
| timestep                           | 303000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3467
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.5     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -583     |
| loss/alpha                         | 0.00775  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.1     |
| timestep                           | 304000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3322
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -583     |
| loss/alpha                         | 0.0186   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.1     |
| timestep                           | 305000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3266
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -583     |
| loss/alpha                         | -0.045   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.2     |
| timestep                           | 306000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3376
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -584     |
| loss/alpha                         | 0.0239   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.1     |
| timestep                           | 307000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3396
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -584     |
| loss/alpha                         | 0.0491   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.3     |
| timestep                           | 308000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3357
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -584     |
| loss/alpha                         | -0.0667  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.9     |
| timestep                           | 309000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3442
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -584     |
| loss/alpha                         | -0.00615 |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 17.9     |
| timestep                           | 310000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3304
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -584     |
| loss/alpha                         | 0.0531   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.4     |
| timestep                           | 311000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
-----------------------------------------------------------------------------------
| alpha                              | 0.184     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 70.4      |
| eval/normalized_episode_reward_std | 2.99      |
| loss/actor                         | -584      |
| loss/alpha                         | -0.000722 |
| loss/critic1                       | 18.1      |
| loss/critic2                       | 17.6      |
| timestep                           | 312000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3292
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -584     |
| loss/alpha                         | -0.0895  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.5     |
| timestep                           | 313000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3432
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -584     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.2     |
| timestep                           | 314000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3214
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -584     |
| loss/alpha                         | 0.0725   |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.7     |
| timestep                           | 315000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3212
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -585     |
| loss/alpha                         | 0.0109   |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 20.6     |
| timestep                           | 316000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3371
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 6.96     |
| loss/actor                         | -585     |
| loss/alpha                         | 0.00633  |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.2     |
| timestep                           | 317000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3495
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -585     |
| loss/alpha                         | 0.0555   |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 21.6     |
| timestep                           | 318000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3421
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -585     |
| loss/alpha                         | -0.00557 |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 19.8     |
| timestep                           | 319000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3368
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 2.64     |
| loss/actor                         | -586     |
| loss/alpha                         | -0.053   |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.2     |
| timestep                           | 320000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3368
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -586     |
| loss/alpha                         | -0.0804  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.1     |
| timestep                           | 321000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3521
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 8.72     |
| loss/actor                         | -587     |
| loss/alpha                         | 0.0281   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.2     |
| timestep                           | 322000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3271
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -587     |
| loss/alpha                         | -0.035   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.1     |
| timestep                           | 323000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3334
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 4.05     |
| loss/actor                         | -588     |
| loss/alpha                         | 0.0683   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.3     |
| timestep                           | 324000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3220
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -588     |
| loss/alpha                         | 0.0676   |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.8     |
| timestep                           | 325000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3360
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -588     |
| loss/alpha                         | 0.0307   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.2     |
| timestep                           | 326000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3222
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -588     |
| loss/alpha                         | 0.0936   |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 21.8     |
| timestep                           | 327000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3347
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -588     |
| loss/alpha                         | -0.0532  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.5     |
| timestep                           | 328000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3454
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -588     |
| loss/alpha                         | -0.109   |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 20.8     |
| timestep                           | 329000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3434
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.0334  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 19.9     |
| timestep                           | 330000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3172
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.1     |
| eval/normalized_episode_reward_std | 25.2     |
| loss/actor                         | -589     |
| loss/alpha                         | 0.0427   |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 20.9     |
| timestep                           | 331000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.0119  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 21.7     |
| timestep                           | 332000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3364
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -590     |
| loss/alpha                         | 0.00939  |
| loss/critic1                       | 23.7     |
| loss/critic2                       | 23.2     |
| timestep                           | 333000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3441
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -590     |
| loss/alpha                         | -0.0163  |
| loss/critic1                       | 23.1     |
| loss/critic2                       | 22.7     |
| timestep                           | 334000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3344
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -590     |
| loss/alpha                         | -0.0906  |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.2     |
| timestep                           | 335000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3322
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -590     |
| loss/alpha                         | 0.0143   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 19.9     |
| timestep                           | 336000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3281
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -590     |
| loss/alpha                         | 0.0344   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.2     |
| timestep                           | 337000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3437
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -590     |
| loss/alpha                         | -0.106   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18       |
| timestep                           | 338000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3352
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 4.39     |
| loss/actor                         | -590     |
| loss/alpha                         | -0.0393  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.7     |
| timestep                           | 339000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3343
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.62     |
| loss/actor                         | -591     |
| loss/alpha                         | 0.0948   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19       |
| timestep                           | 340000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3520
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -591     |
| loss/alpha                         | 0.07     |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.6     |
| timestep                           | 341000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3402
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -592     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.5     |
| timestep                           | 342000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3507
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -592     |
| loss/alpha                         | 0.0359   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.2     |
| timestep                           | 343000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3511
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -592     |
| loss/alpha                         | 0.025    |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 18.7     |
| timestep                           | 344000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3295
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -593     |
| loss/alpha                         | -0.0589  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.8     |
| timestep                           | 345000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3234
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -593     |
| loss/alpha                         | -0.00195 |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.2     |
| timestep                           | 346000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3480
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -594     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 17.8     |
| timestep                           | 347000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3367
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -594     |
| loss/alpha                         | 0.0155   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.3     |
| timestep                           | 348000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3400
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -594     |
| loss/alpha                         | -0.0246  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.3     |
| timestep                           | 349000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3399
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -595     |
| loss/alpha                         | -0.00264 |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19       |
| timestep                           | 350000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3587
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -595     |
| loss/alpha                         | 0.018    |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19       |
| timestep                           | 351000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3697
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -595     |
| loss/alpha                         | 0.071    |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.3     |
| timestep                           | 352000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3461
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -596     |
| loss/alpha                         | -0.0949  |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 18.9     |
| timestep                           | 353000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3575
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -596     |
| loss/alpha                         | -0.00766 |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20       |
| timestep                           | 354000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3270
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -596     |
| loss/alpha                         | -0.143   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 19.8     |
| timestep                           | 355000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3359
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -597     |
| loss/alpha                         | 0.0123   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.5     |
| timestep                           | 356000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3452
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -597     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.5     |
| timestep                           | 357000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3483
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -598     |
| loss/alpha                         | 0.0558   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.5     |
| timestep                           | 358000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3483
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -598     |
| loss/alpha                         | 0.0423   |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.7     |
| timestep                           | 359000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3425
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -598     |
| loss/alpha                         | -0.0556  |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.8     |
| timestep                           | 360000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3406
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -599     |
| loss/alpha                         | -0.0124  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.2     |
| timestep                           | 361000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3289
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -599     |
| loss/alpha                         | -0.0228  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 19.8     |
| timestep                           | 362000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3473
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -599     |
| loss/alpha                         | 0.0565   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19       |
| timestep                           | 363000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3601
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -600     |
| loss/alpha                         | -0.0446  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 18.7     |
| timestep                           | 364000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3390
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -600     |
| loss/alpha                         | 0.0345   |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.4     |
| timestep                           | 365000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3393
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -600     |
| loss/alpha                         | 0.0756   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 19.8     |
| timestep                           | 366000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3402
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -601     |
| loss/alpha                         | -0.0448  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.2     |
| timestep                           | 367000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3303
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -601     |
| loss/alpha                         | 0.0577   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19       |
| timestep                           | 368000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3379
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -601     |
| loss/alpha                         | -0.0331  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.4     |
| timestep                           | 369000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3508
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -601     |
| loss/alpha                         | -0.0842  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.6     |
| timestep                           | 370000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3422
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -602     |
| loss/alpha                         | 0.0351   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.6     |
| timestep                           | 371000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3411
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -602     |
| loss/alpha                         | 0.0434   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.3     |
| timestep                           | 372000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3556
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -602     |
| loss/alpha                         | 0.0353   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.3     |
| timestep                           | 373000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3521
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -602     |
| loss/alpha                         | 0.0175   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.7     |
| timestep                           | 374000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3394
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -603     |
| loss/alpha                         | 0.0976   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 17.9     |
| timestep                           | 375000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3459
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -603     |
| loss/alpha                         | -0.0954  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.4     |
| timestep                           | 376000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3465
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -603     |
| loss/alpha                         | -0.0616  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.5     |
| timestep                           | 377000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3496
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 8.57     |
| loss/actor                         | -603     |
| loss/alpha                         | -0.104   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.5     |
| timestep                           | 378000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3380
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 2.64     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.0545   |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.7     |
| timestep                           | 379000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3500
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -604     |
| loss/alpha                         | -0.00524 |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.5     |
| timestep                           | 380000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3357
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.0448   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 381000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3326
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -604     |
| loss/alpha                         | -0.0472  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.2     |
| timestep                           | 382000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3434
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.0376   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.4     |
| timestep                           | 383000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3379
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -604     |
| loss/alpha                         | -0.0732  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.3     |
| timestep                           | 384000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3405
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -604     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 385000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3600
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -604     |
| loss/alpha                         | -0.0175  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.7     |
| timestep                           | 386000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3543
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -605     |
| loss/alpha                         | 0.0451   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.1     |
| timestep                           | 387000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3587
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -605     |
| loss/alpha                         | -0.00601 |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.5     |
| timestep                           | 388000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3406
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 10       |
| loss/actor                         | -606     |
| loss/alpha                         | 0.0363   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.5     |
| timestep                           | 389000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3447
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -606     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.1     |
| timestep                           | 390000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3415
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -607     |
| loss/alpha                         | -0.0408  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.8     |
| timestep                           | 391000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3413
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -607     |
| loss/alpha                         | 0.0591   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 392000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3535
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -608     |
| loss/alpha                         | -0.00433 |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.1     |
| timestep                           | 393000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3415
-----------------------------------------------------------------------------------
| alpha                              | 0.178     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 67.3      |
| eval/normalized_episode_reward_std | 2.81      |
| loss/actor                         | -607      |
| loss/alpha                         | -0.000335 |
| loss/critic1                       | 18.9      |
| loss/critic2                       | 18.6      |
| timestep                           | 394000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3325
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -608     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 395000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3444
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -608     |
| loss/alpha                         | 0.0021   |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.3     |
| timestep                           | 396000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3561
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -608     |
| loss/alpha                         | -0.00977 |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 397000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3461
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -608     |
| loss/alpha                         | -0.0226  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17       |
| timestep                           | 398000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3496
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -608     |
| loss/alpha                         | 0.0243   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.2     |
| timestep                           | 399000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3455
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -608     |
| loss/alpha                         | -0.0104  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.2     |
| timestep                           | 400000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3479
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -608     |
| loss/alpha                         | -0.026   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 401000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3474
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -608     |
| loss/alpha                         | -0.0741  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.7     |
| timestep                           | 402000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3468
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -608     |
| loss/alpha                         | 0.0836   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 403000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3530
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -608     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.5     |
| timestep                           | 404000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3405
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -609     |
| loss/alpha                         | 0.032    |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.2     |
| timestep                           | 405000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3409
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -609     |
| loss/alpha                         | 0.0794   |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.8     |
| timestep                           | 406000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3383
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 6.75     |
| loss/actor                         | -610     |
| loss/alpha                         | 0.0164   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.3     |
| timestep                           | 407000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3386
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -610     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 408000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3509
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.0304  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.5     |
| timestep                           | 409000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3395
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -610     |
| loss/alpha                         | 0.0137   |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.4     |
| timestep                           | 410000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3232
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -610     |
| loss/alpha                         | 0.061    |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.6     |
| timestep                           | 411000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3513
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -610     |
| loss/alpha                         | 0.0228   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 17.9     |
| timestep                           | 412000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3321
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.0666  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.6     |
| timestep                           | 413000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3486
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.00309 |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.3     |
| timestep                           | 414000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3474
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.00074 |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.5     |
| timestep                           | 415000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3540
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0229   |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.4     |
| timestep                           | 416000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3496
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -611     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.3     |
| timestep                           | 417000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3296
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -611     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 17.8     |
| timestep                           | 418000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3474
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -611     |
| loss/alpha                         | -0.00199 |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.6     |
| timestep                           | 419000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3560
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0857   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.5     |
| timestep                           | 420000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3510
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 5.29     |
| loss/actor                         | -611     |
| loss/alpha                         | -0.0866  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.3     |
| timestep                           | 421000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3356
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -611     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 16.8     |
| timestep                           | 422000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3530
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -612     |
| loss/alpha                         | 0.00177  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 16.9     |
| timestep                           | 423000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3405
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 7.44     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.0146  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.7     |
| timestep                           | 424000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3687
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.2     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.00596 |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.3     |
| timestep                           | 425000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3495
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.089   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.6     |
| timestep                           | 426000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3550
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -613     |
| loss/alpha                         | 0.000779 |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 427000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3478
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -613     |
| loss/alpha                         | -0.0565  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.4     |
| timestep                           | 428000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3665
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.5     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -614     |
| loss/alpha                         | 0.0679   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.5     |
| timestep                           | 429000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3414
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.54     |
| loss/actor                         | -614     |
| loss/alpha                         | -0.034   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.7     |
| timestep                           | 430000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3812
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -614     |
| loss/alpha                         | -0.0348  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17       |
| timestep                           | 431000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3528
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.0235  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.2     |
| timestep                           | 432000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3618
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.4     |
| timestep                           | 433000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3611
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -616     |
| loss/alpha                         | 0.0543   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 434000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3421
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -616     |
| loss/alpha                         | -0.0132  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.7     |
| timestep                           | 435000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3453
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -616     |
| loss/alpha                         | -0.059   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 16.9     |
| timestep                           | 436000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3497
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -617     |
| loss/alpha                         | -0.0591  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.7     |
| timestep                           | 437000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3490
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -618     |
| loss/alpha                         | 0.0419   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 438000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3348
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -618     |
| loss/alpha                         | 0.114    |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18       |
| timestep                           | 439000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3492
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0526  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17       |
| timestep                           | 440000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3324
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0306  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.3     |
| timestep                           | 441000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3443
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0862   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.2     |
| timestep                           | 442000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3613
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.7     |
| eval/normalized_episode_reward_std | 28.9     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0455   |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.4     |
| timestep                           | 443000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3619
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.7     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0254   |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 20.9     |
| timestep                           | 444000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3458
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 8.05     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.117   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.3     |
| timestep                           | 445000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3580
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0354  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.6     |
| timestep                           | 446000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3502
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0337  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 17.8     |
| timestep                           | 447000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3411
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0979  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.5     |
| timestep                           | 448000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3599
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -618     |
| loss/alpha                         | 0.0505   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.3     |
| timestep                           | 449000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3517
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -618     |
| loss/alpha                         | 0.072    |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17       |
| timestep                           | 450000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3516
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.00259  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 451000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3517
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0161   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.3     |
| timestep                           | 452000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3322
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0182   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.5     |
| timestep                           | 453000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3506
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.036   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.4     |
| timestep                           | 454000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3449
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0526  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 455000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3418
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0824   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.1     |
| timestep                           | 456000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3449
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0384   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 457000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3340
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 458000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3486
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0576  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.4     |
| timestep                           | 459000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3423
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.00211 |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.3     |
| timestep                           | 460000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3574
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 6.16     |
| loss/actor                         | -621     |
| loss/alpha                         | -0.0212  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.6     |
| timestep                           | 461000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3413
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -620     |
| loss/alpha                         | 0.157    |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.7     |
| timestep                           | 462000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3600
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.135   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.5     |
| timestep                           | 463000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3684
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.00633  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 464000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3564
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.063   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.7     |
| timestep                           | 465000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3668
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0536  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.2     |
| timestep                           | 466000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3622
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.106   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.5     |
| timestep                           | 467000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3469
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0349  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.2     |
| timestep                           | 468000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3735
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -621     |
| loss/alpha                         | 0.0844   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.2     |
| timestep                           | 469000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3669
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -621     |
| loss/alpha                         | -0.0305  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17       |
| timestep                           | 470000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3572
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.5      |
| loss/actor                         | -621     |
| loss/alpha                         | -0.0601  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 17.8     |
| timestep                           | 471000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3581
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -622     |
| loss/alpha                         | 0.0607   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.4     |
| timestep                           | 472000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3610
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -622     |
| loss/alpha                         | 0.0281   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 473000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3614
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -623     |
| loss/alpha                         | -0.0193  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 474000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3520
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -623     |
| loss/alpha                         | 0.151    |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 475000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3485
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -623     |
| loss/alpha                         | 0.109    |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.3     |
| timestep                           | 476000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3413
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -623     |
| loss/alpha                         | 0.00247  |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.1     |
| timestep                           | 477000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3513
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -623     |
| loss/alpha                         | 0.0522   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 18.8     |
| timestep                           | 478000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3476
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -623     |
| loss/alpha                         | -0.0577  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.1     |
| timestep                           | 479000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3444
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -622     |
| loss/alpha                         | -0.0111  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.6     |
| timestep                           | 480000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3628
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -622     |
| loss/alpha                         | -0.0739  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.3     |
| timestep                           | 481000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3435
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -622     |
| loss/alpha                         | -0.162   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.1     |
| timestep                           | 482000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3466
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -623     |
| loss/alpha                         | 0.0461   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 483000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3458
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -623     |
| loss/alpha                         | -0.0303  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.7     |
| timestep                           | 484000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3434
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 10.3     |
| loss/actor                         | -624     |
| loss/alpha                         | -0.0282  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 485000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3534
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -624     |
| loss/alpha                         | 0.046    |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.2     |
| timestep                           | 486000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3513
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 10.3     |
| loss/actor                         | -624     |
| loss/alpha                         | 0.0949   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 487000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3599
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -624     |
| loss/alpha                         | 0.093    |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.4     |
| timestep                           | 488000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3438
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -624     |
| loss/alpha                         | -0.0204  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 17.6     |
| timestep                           | 489000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3607
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.0465  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.2     |
| timestep                           | 490000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3452
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -624     |
| loss/alpha                         | 0.0125   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 17.5     |
| timestep                           | 491000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3641
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.0595  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17       |
| timestep                           | 492000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3563
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 8.17     |
| loss/actor                         | -625     |
| loss/alpha                         | 0.0176   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 493000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3441
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -625     |
| loss/alpha                         | 0.068    |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 494000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3479
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.056   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.2     |
| timestep                           | 495000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3310
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0577  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 15.9     |
| timestep                           | 496000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3648
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0927  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.7     |
| timestep                           | 497000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3323
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.143    |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.6     |
| timestep                           | 498000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3545
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 499000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3670
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.0398   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.6     |
| timestep                           | 500000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3434
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0372  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.4     |
| timestep                           | 501000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3577
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.0498   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.4     |
| timestep                           | 502000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3484
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.0364   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.5     |
| timestep                           | 503000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3472
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.0904   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 504000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3505
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.05    |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.4     |
| timestep                           | 505000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3400
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0476  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.5     |
| timestep                           | 506000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3493
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.0949  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.8     |
| timestep                           | 507000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3583
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0337  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 508000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3545
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0523  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16       |
| timestep                           | 509000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3381
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 4.07     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.8     |
| timestep                           | 510000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3525
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.00671  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.4     |
| timestep                           | 511000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3332
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 4.71     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.5     |
| timestep                           | 512000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3698
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.0808   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.1     |
| timestep                           | 513000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3533
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0279  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19       |
| timestep                           | 514000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3593
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.00945  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 18.9     |
| timestep                           | 515000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3485
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.0731  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.5     |
| timestep                           | 516000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3482
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.0488  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.5     |
| timestep                           | 517000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3528
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0134  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 518000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3453
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.87     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0222  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.6     |
| timestep                           | 519000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3535
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.0457   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 520000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3492
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0253  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.4     |
| timestep                           | 521000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3593
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.3     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.0533   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.3     |
| timestep                           | 522000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3562
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -626     |
| loss/alpha                         | 0.015    |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.4     |
| timestep                           | 523000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3439
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -627     |
| loss/alpha                         | -0.156   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.5     |
| timestep                           | 524000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3455
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -627     |
| loss/alpha                         | 0.00683  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 525000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3674
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.0124   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 526000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3530
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0708   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 527000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3438
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 6.98     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0767  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.6     |
| timestep                           | 528000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3609
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 4.23     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.143    |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.6     |
| timestep                           | 529000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3466
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0797   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.5     |
| timestep                           | 530000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3615
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0196   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.3     |
| timestep                           | 531000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3483
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0729  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.2     |
| timestep                           | 532000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3589
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 2.64     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0205  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.6     |
| timestep                           | 533000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3302
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0468  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18       |
| timestep                           | 534000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3550
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.025    |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.4     |
| timestep                           | 535000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3578
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.6     |
| timestep                           | 536000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3607
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0897   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.4     |
| timestep                           | 537000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3497
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.00924  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.2     |
| timestep                           | 538000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3516
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 9.69     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0522   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.4     |
| timestep                           | 539000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3517
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.00471 |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 540000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3643
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0116  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 541000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3472
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 542000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3630
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.00543 |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17       |
| timestep                           | 543000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3543
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.00858  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.8     |
| timestep                           | 544000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3549
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0626   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.3     |
| timestep                           | 545000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3615
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0742  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 18.9     |
| timestep                           | 546000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3631
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0692  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.8     |
| timestep                           | 547000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3573
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0644  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 17.9     |
| timestep                           | 548000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3404
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.044    |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.5     |
| timestep                           | 549000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3466
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.061   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.5     |
| timestep                           | 550000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3551
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0686   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.4     |
| timestep                           | 551000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3544
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0762  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 17.9     |
| timestep                           | 552000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3388
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.9      |
| loss/actor                         | -634     |
| loss/alpha                         | 0.00413  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.7     |
| timestep                           | 553000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3327
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0744   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.4     |
| timestep                           | 554000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3598
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0427  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.3     |
| timestep                           | 555000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3305
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.00722 |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.7     |
| timestep                           | 556000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3477
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.119   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.8     |
| timestep                           | 557000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3397
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0338   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 15.9     |
| timestep                           | 558000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3591
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.076    |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 559000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3609
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0434   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 560000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3630
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0178   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.6     |
| timestep                           | 561000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3628
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0407  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.6     |
| timestep                           | 562000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3739
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0166   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.1     |
| timestep                           | 563000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3510
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0795   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.3     |
| timestep                           | 564000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3762
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0462  |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 565000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3466
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.00253  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17       |
| timestep                           | 566000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3701
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.125   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.8     |
| timestep                           | 567000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3607
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0442  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.1     |
| timestep                           | 568000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3424
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.00557 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 569000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3668
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0272   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.4     |
| timestep                           | 570000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3573
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0871   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.7     |
| timestep                           | 571000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3511
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0199   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 572000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3591
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.3     |
| timestep                           | 573000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3575
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0148   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.4     |
| timestep                           | 574000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3419
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 4.75     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0708  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.2     |
| timestep                           | 575000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3548
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.00602 |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 17.8     |
| timestep                           | 576000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3614
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.00104 |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.5     |
| timestep                           | 577000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3487
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 4.22     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0446   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 578000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3528
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0224   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.4     |
| timestep                           | 579000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3623
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0146   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17       |
| timestep                           | 580000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3654
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0438   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.5     |
| timestep                           | 581000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3557
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0233  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.2     |
| timestep                           | 582000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3622
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 9.36     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.5     |
| timestep                           | 583000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3573
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 8.83     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0335  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.2     |
| timestep                           | 584000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3486
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.00495 |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.3     |
| timestep                           | 585000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3584
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.00287  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.6     |
| timestep                           | 586000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3695
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0509  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.5     |
| timestep                           | 587000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3497
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0646   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 588000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3684
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.101   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.5     |
| timestep                           | 589000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3512
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 590000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3687
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17       |
| timestep                           | 591000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3569
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0489  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.8     |
| timestep                           | 592000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3634
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0833  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 593000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3624
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 6.6      |
| loss/actor                         | -635     |
| loss/alpha                         | 0.0793   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.7     |
| timestep                           | 594000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3494
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -635     |
| loss/alpha                         | 0.0923   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.5     |
| timestep                           | 595000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3515
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -635     |
| loss/alpha                         | -0.0369  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.2     |
| timestep                           | 596000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3542
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -635     |
| loss/alpha                         | -0.00572 |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.2     |
| timestep                           | 597000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3608
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -635     |
| loss/alpha                         | 0.0437   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.7     |
| timestep                           | 598000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3595
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -635     |
| loss/alpha                         | -0.116   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17       |
| timestep                           | 599000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3646
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.0199   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.8     |
| timestep                           | 600000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3481
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.00125 |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.7     |
| timestep                           | 601000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3632
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.6     |
| timestep                           | 602000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3561
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.0361   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.2     |
| timestep                           | 603000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3495
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.0243  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.8     |
| timestep                           | 604000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3755
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.021    |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.8     |
| timestep                           | 605000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3698
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.039   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 606000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3579
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0147   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 607000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3621
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0234   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.6     |
| timestep                           | 608000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3604
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -638     |
| loss/alpha                         | -0.0079  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16       |
| timestep                           | 609000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3629
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -638     |
| loss/alpha                         | 0.0359   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.6     |
| timestep                           | 610000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3517
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0115   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.5     |
| timestep                           | 611000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3401
-----------------------------------------------------------------------------------
| alpha                              | 0.162     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 67.3      |
| eval/normalized_episode_reward_std | 22.1      |
| loss/actor                         | -639      |
| loss/alpha                         | -0.000722 |
| loss/critic1                       | 16.6      |
| loss/critic2                       | 16.4      |
| timestep                           | 612000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3417
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0569   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.5     |
| timestep                           | 613000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3587
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0333   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.4     |
| timestep                           | 614000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3406
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0274   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 16.8     |
| timestep                           | 615000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3588
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0661  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 616000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3615
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0156   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.1     |
| timestep                           | 617000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3516
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0607  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 618000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3522
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.00506 |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.3     |
| timestep                           | 619000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3662
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0848  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.1     |
| timestep                           | 620000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3485
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0576  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.6     |
| timestep                           | 621000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3547
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0173   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17       |
| timestep                           | 622000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3390
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0401   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17       |
| timestep                           | 623000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3393
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0558   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.8     |
| timestep                           | 624000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3460
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0201   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 16.8     |
| timestep                           | 625000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3618
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0223  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.4     |
| timestep                           | 626000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3536
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0465  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.6     |
| timestep                           | 627000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3507
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0578   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.8     |
| timestep                           | 628000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3581
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0334  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.8     |
| timestep                           | 629000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3471
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0425  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.5     |
| timestep                           | 630000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3659
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0257  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 631000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3461
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0408   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.1     |
| timestep                           | 632000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3521
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.00852  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.4     |
| timestep                           | 633000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3609
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0303  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.8     |
| timestep                           | 634000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0579  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.3     |
| timestep                           | 635000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3401
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0419   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.6     |
| timestep                           | 636000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3636
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0236  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.3     |
| timestep                           | 637000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3684
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.59     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0871  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.4     |
| timestep                           | 638000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3651
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.174    |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17       |
| timestep                           | 639000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3460
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0037   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 16.8     |
| timestep                           | 640000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3522
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0571   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 17.7     |
| timestep                           | 641000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3770
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0294  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.1     |
| timestep                           | 642000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3485
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0351   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 643000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3700
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0544  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 644000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3522
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0681   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 645000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3553
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 4.51     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0117   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.5     |
| timestep                           | 646000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3630
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 647000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3562
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0688  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.1     |
| timestep                           | 648000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3759
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.057    |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 16.9     |
| timestep                           | 649000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3656
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17       |
| timestep                           | 650000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3511
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0396  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 651000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3543
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0865  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.5     |
| timestep                           | 652000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3525
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.6      |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0422  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 653000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3517
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.139    |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.8     |
| timestep                           | 654000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3615
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0251   |
| loss/critic1                       | 19       |
| loss/critic2                       | 19       |
| timestep                           | 655000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3443
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0428  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.7     |
| timestep                           | 656000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3677
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0376   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 657000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3420
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0638   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 17.8     |
| timestep                           | 658000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3554
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0276   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.3     |
| timestep                           | 659000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3579
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.129   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.6     |
| timestep                           | 660000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3406
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.6     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.5     |
| timestep                           | 661000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3614
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0477   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.5     |
| timestep                           | 662000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3548
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.00989 |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17       |
| timestep                           | 663000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3633
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0677  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.1     |
| timestep                           | 664000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3413
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 4.38     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0123  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 665000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3605
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0548   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 666000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3796
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.4     |
| timestep                           | 667000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3511
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0623  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 668000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3631
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0236  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 669000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3698
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 670000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3694
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 671000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3732
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0902  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.3     |
| timestep                           | 672000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3518
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0629   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.5     |
| timestep                           | 673000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3549
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0115  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 674000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3542
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0577  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 675000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3486
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -639     |
| loss/alpha                         | 0.123    |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.8     |
| timestep                           | 676000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3550
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0361   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.6     |
| timestep                           | 677000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3541
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.045    |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 678000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3676
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0629  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.5     |
| timestep                           | 679000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3608
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0439  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 680000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3498
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.12    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 681000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3534
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.118    |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 682000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3592
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0723  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 683000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3522
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0214   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.4     |
| timestep                           | 684000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3436
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0741   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.8     |
| timestep                           | 685000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3573
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0011   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.9     |
| timestep                           | 686000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3570
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0266  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 687000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3570
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.6     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0722  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 688000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3585
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.115    |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 15.9     |
| timestep                           | 689000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3627
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0136  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 690000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3568
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0715   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 691000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3665
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0799   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 692000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3608
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0181  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 693000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3571
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0826  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.4     |
| timestep                           | 694000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3701
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0107  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 695000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3555
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0209   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.3     |
| timestep                           | 696000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3530
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0887  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 697000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3659
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0207  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 698000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3494
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.022   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.7     |
| timestep                           | 699000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3653
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.033   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.2     |
| timestep                           | 700000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3536
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0163   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.8     |
| timestep                           | 701000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3594
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.00582 |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 15.8     |
| timestep                           | 702000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3406
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 703000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3475
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0485   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 704000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3573
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0175  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 705000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3600
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0529  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 706000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3695
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 9.73     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0303  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 707000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3762
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.00248 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 708000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3708
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0554  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 709000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3565
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0379   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15       |
| timestep                           | 710000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3642
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 711000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3858
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.00833  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.5     |
| timestep                           | 712000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3663
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0459  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 713000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3670
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 3.85     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0538  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.3     |
| timestep                           | 714000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3481
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0203   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.3     |
| timestep                           | 715000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3674
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.047   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.4     |
| timestep                           | 716000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3686
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0782   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.4     |
| timestep                           | 717000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.085    |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 718000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3451
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.91     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.163    |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.8     |
| timestep                           | 719000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3549
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.00683 |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 720000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3628
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0348  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.6     |
| timestep                           | 721000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3478
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0113   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.3     |
| timestep                           | 722000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3646
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0259   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16       |
| timestep                           | 723000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3512
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.035   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.4     |
| timestep                           | 724000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3704
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0491  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.1     |
| timestep                           | 725000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3579
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.00215  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 15.9     |
| timestep                           | 726000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3798
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.042   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 727000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3566
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.5     |
| timestep                           | 728000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3545
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.5     |
| timestep                           | 729000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3599
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0516   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.8     |
| timestep                           | 730000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3607
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0244   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.2     |
| timestep                           | 731000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3796
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0946   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 732000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3699
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0111  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 733000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3589
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0702   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 734000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3569
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0179   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 735000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3450
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.00419  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 736000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3567
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0641  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 737000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3644
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0485  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.8     |
| timestep                           | 738000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3595
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 8.74     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0172   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.5     |
| timestep                           | 739000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3702
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.00109 |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16       |
| timestep                           | 740000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3562
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 2.58     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0739   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 15.9     |
| timestep                           | 741000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3574
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.026   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 742000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3613
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0898  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 743000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3427
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0851   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 744000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3575
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0187   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 745000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3671
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -647     |
| loss/alpha                         | -0.00957 |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.7     |
| timestep                           | 746000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3702
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0181  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.8     |
| timestep                           | 747000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3737
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.021   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 748000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3647
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 5.9      |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0575   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 749000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3523
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 5.32     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0537  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.6     |
| timestep                           | 750000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3548
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0111  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 14.8     |
| timestep                           | 751000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3765
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0577  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 752000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3749
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.014    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.2     |
| timestep                           | 753000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3541
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0824   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.4     |
| timestep                           | 754000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3533
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0578   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.5     |
| timestep                           | 755000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3613
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.00215 |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.3     |
| timestep                           | 756000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3568
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.00521  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.1     |
| timestep                           | 757000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3582
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0271   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.4     |
| timestep                           | 758000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3579
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.106   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 759000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3537
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0302  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.2     |
| timestep                           | 760000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3597
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 4.35     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0713   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.6     |
| timestep                           | 761000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3601
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0796  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16       |
| timestep                           | 762000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3593
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0021  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.7     |
| timestep                           | 763000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3634
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 29.4     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0154   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.3     |
| timestep                           | 764000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3716
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0157   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.1     |
| timestep                           | 765000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3639
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 2.57     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0884   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 766000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3573
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0312  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 767000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3569
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.035   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 768000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3712
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.00818 |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 769000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3657
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0679  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.2     |
| timestep                           | 770000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3469
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.72     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0096   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 15.9     |
| timestep                           | 771000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3756
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0674   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.7     |
| timestep                           | 772000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3746
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0121  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.5     |
| timestep                           | 773000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3534
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.4     |
| timestep                           | 774000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3772
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0497  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.5     |
| timestep                           | 775000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3582
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.00476  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 776000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3794
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0355   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.3     |
| timestep                           | 777000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3677
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0988  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.4     |
| timestep                           | 778000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3550
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 779000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3700
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0745   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 780000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3698
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.00709 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.3     |
| timestep                           | 781000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3681
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.000451 |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 782000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3727
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.6     |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0446   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 783000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3635
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.00619 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 784000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3724
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.021   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 785000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3684
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0094   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 786000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3565
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0425   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 787000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3572
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0147  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 788000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3693
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0284  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 789000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3502
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.00582 |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 790000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3649
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0298   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 791000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3644
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0434   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.5     |
| timestep                           | 792000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3766
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0812   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.8     |
| timestep                           | 793000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3654
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.043   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.2     |
| timestep                           | 794000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3571
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 6.68     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0724  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.1     |
| timestep                           | 795000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3611
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0257   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.8     |
| timestep                           | 796000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3623
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0417   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 797000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3650
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.00292  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 798000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3719
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.00865 |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 799000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3630
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0543  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.1     |
| timestep                           | 800000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3657
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0851  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 801000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3839
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0257   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 802000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3583
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 8.4      |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0156  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 803000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3687
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0363  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 804000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3475
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0213   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.4     |
| timestep                           | 805000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3596
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15       |
| timestep                           | 806000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3749
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0398   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 807000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3557
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0577   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.3     |
| timestep                           | 808000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3653
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.029   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.4     |
| timestep                           | 809000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3650
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.00429 |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 15.9     |
| timestep                           | 810000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3616
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 9.82     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0335   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 811000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3563
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.4     |
| eval/normalized_episode_reward_std | 25.6     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0399  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.2     |
| timestep                           | 812000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3744
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.152    |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.8     |
| timestep                           | 813000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3673
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0172   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.2     |
| timestep                           | 814000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3774
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.107   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.2     |
| timestep                           | 815000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3934
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0405  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 816000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3663
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0254  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 817000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3583
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0158   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 818000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3591
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 819000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0356   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 820000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3547
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0068   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.3     |
| timestep                           | 821000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3640
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0228  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 822000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3480
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0837   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.2     |
| timestep                           | 823000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3609
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 4.47     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0381   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 824000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3419
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.00947 |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.6     |
| timestep                           | 825000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3577
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0476  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 826000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3657
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.3     |
| timestep                           | 827000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3746
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 828000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 829000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3605
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -649     |
| loss/alpha                         | 0.00895  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.6     |
| timestep                           | 830000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3570
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0219   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 831000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3555
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0412  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 16       |
| timestep                           | 832000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3625
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0486  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.6     |
| timestep                           | 833000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3717
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0487   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 834000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0541   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 835000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3554
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0545   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 836000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3686
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.000399 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 837000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3581
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0672   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.2     |
| timestep                           | 838000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3697
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0746  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.3     |
| timestep                           | 839000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3576
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.00326 |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.6     |
| timestep                           | 840000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3696
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -650     |
| loss/alpha                         | -0.00546 |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.6     |
| timestep                           | 841000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3782
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 842000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3683
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0509  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.3     |
| timestep                           | 843000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3701
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0136  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.5     |
| timestep                           | 844000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3700
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.00669 |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 845000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0824   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 846000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3673
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.2     |
| timestep                           | 847000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3473
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0968   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 848000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3612
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 849000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3503
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0376  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 850000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3537
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.5     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0807  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 851000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3604
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.026    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 852000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3659
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0921  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 853000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3641
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0118  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 854000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3626
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0323   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 855000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3644
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0508  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 856000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3574
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0213  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 857000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3708
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0317   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 858000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3559
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0957   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 859000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3579
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 27.4     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.00804 |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.2     |
| timestep                           | 860000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3563
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 4.99     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0456  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 861000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3667
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0685  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 862000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3727
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0107   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15       |
| timestep                           | 863000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3794
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0328   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 864000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3775
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.00504 |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 865000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3779
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0323   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 866000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3686
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0551   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 867000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3647
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.000881 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 868000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3859
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 7.87     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.018    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 869000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3599
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.87     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0258   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 870000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3741
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0224  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 871000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3537
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0171  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 872000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3635
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0605  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.2     |
| timestep                           | 873000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3677
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0735   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 874000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3735
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 4.74     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0353   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 875000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3815
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0349  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 16.9     |
| timestep                           | 876000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3730
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 877000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3564
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0416  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 878000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3761
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 39.9     |
| eval/normalized_episode_reward_std | 31.2     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0744   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 879000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3502
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0408  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 880000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3714
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.044    |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 881000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3618
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.038    |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.4     |
| timestep                           | 882000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3603
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.109    |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.5     |
| timestep                           | 883000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3588
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0105  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 884000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3651
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.121   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 885000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3553
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 8.48     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.00339 |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15       |
| timestep                           | 886000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3520
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0211  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 887000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3705
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0187  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 888000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3664
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.02     |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 889000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3707
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0937   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.4     |
| timestep                           | 890000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3571
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0568  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.2     |
| timestep                           | 891000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3678
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 7.33     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00112  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.3     |
| timestep                           | 892000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3647
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0335  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 893000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3619
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0222  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 894000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3612
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00474  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 895000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3776
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 11.2     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0278  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.5     |
| timestep                           | 896000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3656
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 4.72     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0846   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.3     |
| timestep                           | 897000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3661
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0482  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.7     |
| timestep                           | 898000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3679
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0645  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.2     |
| timestep                           | 899000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3662
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0654   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 900000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3689
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00893 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 901000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3886
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.109   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 902000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3725
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0458   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.6     |
| timestep                           | 903000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3551
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0549   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 904000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3500
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00946  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 905000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3631
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 6        |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0101   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.7     |
| timestep                           | 906000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3610
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.104    |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.7     |
| timestep                           | 907000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3667
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 9.4      |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 908000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3533
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0155  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.7     |
| timestep                           | 909000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3746
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00304 |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.1     |
| timestep                           | 910000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3662
-----------------------------------------------------------------------------------
| alpha                              | 0.159     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 66.9      |
| eval/normalized_episode_reward_std | 2.82      |
| loss/actor                         | -654      |
| loss/alpha                         | -0.000817 |
| loss/critic1                       | 17        |
| loss/critic2                       | 16.8      |
| timestep                           | 911000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3601
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0276  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 912000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3869
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0813  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.8     |
| timestep                           | 913000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3686
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0198  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 914000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3600
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0168  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 915000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3642
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -654     |
| loss/alpha                         | 0.01     |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.2     |
| timestep                           | 916000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3611
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0502   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.3     |
| timestep                           | 917000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3828
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0422   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 918000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3580
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0421  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.4     |
| timestep                           | 919000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3554
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.88     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0108  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 920000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3749
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0783   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 921000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3769
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 922000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3699
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00391  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 923000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3613
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 4.09     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00444  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 924000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3572
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0114  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.6     |
| timestep                           | 925000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3469
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.024    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.3     |
| timestep                           | 926000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3510
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0529   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.5     |
| timestep                           | 927000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3758
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 7.64     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00171  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 928000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3632
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 8.47     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0208  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 929000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3587
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0126   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.8     |
| timestep                           | 930000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3645
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.00164 |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15       |
| timestep                           | 931000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3553
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 9.08     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00718  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 932000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3847
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0153  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 933000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3584
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.049   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 934000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3660
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0807   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.8     |
| timestep                           | 935000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3567
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -652     |
| loss/alpha                         | -0.068   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.3     |
| timestep                           | 936000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3664
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.106    |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15       |
| timestep                           | 937000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3689
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0479  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.2     |
| timestep                           | 938000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3747
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 9.61     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0408  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 939000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3770
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0318  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 940000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3737
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.4     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0278   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 941000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3821
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0431   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 942000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3714
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0169   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.4     |
| timestep                           | 943000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3633
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0034  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 944000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3634
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0497   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 945000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3679
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0492  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 946000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3680
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0678  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 947000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3669
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 948000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3713
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.68     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0364   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 949000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3539
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0313   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 950000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3673
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0416  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.8     |
| timestep                           | 951000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3723
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.016   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.8     |
| timestep                           | 952000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0622  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 953000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3624
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0394   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 954000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3622
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0276  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.6     |
| timestep                           | 955000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3783
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0549  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 956000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3663
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0535  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.2     |
| timestep                           | 957000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3680
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00219  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 958000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3579
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0404   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 959000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3655
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.00437 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 960000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3500
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00706  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.6     |
| timestep                           | 961000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3760
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0458   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 962000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3628
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0273  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 963000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3746
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0213  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 964000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3484
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0234  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 965000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3719
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0343   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 966000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3663
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 967000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3687
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0722  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 968000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3692
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 969000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3646
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0156  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.2     |
| timestep                           | 970000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3693
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0596  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 971000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3677
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0551   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 972000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3532
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 5.28     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.166    |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 973000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3602
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0401  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 974000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3545
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0754  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 975000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3572
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0447   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.5     |
| timestep                           | 976000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3571
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0317  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 977000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3672
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0121   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 978000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3731
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 979000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3539
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0356  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 980000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3645
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0235   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 981000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3677
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0578   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 982000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3738
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0267   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 983000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3648
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.00856  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 984000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3511
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0121   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 985000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3668
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0299   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 986000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3789
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.109   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 987000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3550
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0986  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 988000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3777
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.74     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.072   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 989000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3692
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 5.53     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0746   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 990000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3528
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0517  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 991000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3712
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0123  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 992000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3574
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.135    |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 993000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3650
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0293   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.4     |
| timestep                           | 994000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3625
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0339   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 995000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3561
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 996000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3626
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.141   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 997000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3636
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 4.71     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0115  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 998000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3831
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0135   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 999000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3590
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0546  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1000000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3491
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0491  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1001000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3683
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0237  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1002000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3736
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0153   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1003000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3590
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0739   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 1004000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3765
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 1005000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3476
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0713  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.6     |
| timestep                           | 1006000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3549
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0371   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1007000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3655
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 4.85     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.047    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1008000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3652
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0838  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1009000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3709
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0622  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 1010000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3713
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 7.3      |
| loss/actor                         | -656     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.3     |
| timestep                           | 1011000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3707
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0416  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.5     |
| timestep                           | 1012000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0132   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 1013000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0439   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 1014000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3697
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0665   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1015000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3804
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 5.08     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0269  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.6     |
| timestep                           | 1016000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3761
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.5     |
| eval/normalized_episode_reward_std | 26.7     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0571  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.1     |
| timestep                           | 1017000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3744
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0399   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.7     |
| timestep                           | 1018000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3612
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 4.05     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0491  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.8     |
| timestep                           | 1019000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3592
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00139  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 1020000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3643
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.14     |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.1     |
| timestep                           | 1021000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3681
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0958  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 1022000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3647
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0335   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.8     |
| timestep                           | 1023000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3633
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0735   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.8     |
| timestep                           | 1024000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3557
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0509  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.3     |
| timestep                           | 1025000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3655
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.105   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1026000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3774
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.019    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1027000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 6.76     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00285  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1028000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3757
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.072   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1029000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0543  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1030000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3819
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.052   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.8     |
| timestep                           | 1031000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3789
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.081    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1032000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3758
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0494  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1033000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3695
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0402   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 1034000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3727
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.073    |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.8     |
| timestep                           | 1035000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3789
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0582   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 1036000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3651
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.00617 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1037000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3577
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0479   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1038000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3763
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0107   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.6     |
| timestep                           | 1039000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3543
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 4.67     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0453  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1040000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0761  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1041000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3747
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.4     |
| eval/normalized_episode_reward_std | 32.4     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0022   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1042000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3618
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0373  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1043000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3633
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0227  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1044000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3617
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0262   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1045000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3737
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0179   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1046000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3558
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00519  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 1047000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3642
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00114  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1048000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3534
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -655     |
| loss/alpha                         | -0.00641 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1049000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3556
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.108    |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1050000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3788
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0568  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1051000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3695
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0167   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1052000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3577
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0315   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 1053000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3700
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0594  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 1054000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3744
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0725  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1055000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3711
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0748   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1056000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3619
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0215   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 1057000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3412
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.82     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00577  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1058000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3714
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0369   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1059000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3549
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0454  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.4     |
| timestep                           | 1060000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3677
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0349   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1061000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3662
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0514  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 1062000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3584
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.038    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1063000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3552
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0326  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1064000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3782
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.00125 |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 1065000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.4     |
| eval/normalized_episode_reward_std | 26.4     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0108   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1066000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3686
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.00106 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.5     |
| timestep                           | 1067000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3600
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.074    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1068000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3614
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0269   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1069000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3584
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.118   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1070000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3492
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0115   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1071000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3658
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0586  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1072000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3721
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.00919  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1073000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3721
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0428   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1074000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3589
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1075000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3664
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0964  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1076000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3672
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0607  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1077000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3734
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.059    |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1078000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3751
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0422  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1079000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3762
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0119   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1080000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3696
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.00177  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1081000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3646
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0123  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1082000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0829   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 1083000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3631
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0603   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 1084000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3595
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.2     |
| eval/normalized_episode_reward_std | 25.9     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.088   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1085000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3579
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0848   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1086000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3547
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0372  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1087000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3708
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -658     |
| loss/alpha                         | -7.2e-05 |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1088000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3590
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0892  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17       |
| timestep                           | 1089000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3745
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0239   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15       |
| timestep                           | 1090000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3610
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0192  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1091000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3601
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0474   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 1092000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3639
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0401   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 1093000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3633
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.00939  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1094000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3428
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.00778 |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1095000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3903
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.043    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1096000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3737
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0142   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1097000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3679
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0332   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.6     |
| timestep                           | 1098000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3690
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0718  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.2     |
| timestep                           | 1099000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3554
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0715  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 1100000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3735
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.022    |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1101000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3635
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0507  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1102000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3815
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.12     |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 1103000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3667
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0915   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.7     |
| timestep                           | 1104000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.00525  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1105000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3781
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.97     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.1     |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1106000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3630
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0975   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1107000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3647
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.00955  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 1108000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3718
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0435  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1109000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3687
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0241   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.2     |
| timestep                           | 1110000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3684
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0434  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1111000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3720
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1112000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3701
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0318  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1113000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3696
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00847 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1114000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3632
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.063    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 1115000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3490
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0393   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1116000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3716
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.026   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1117000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3706
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.115   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1118000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3599
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0908   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1119000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3790
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0742  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1120000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3774
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 1121000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3678
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0628   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1122000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3733
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -661     |
| loss/alpha                         | 0.021    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1123000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3772
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0443   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1124000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3643
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00595 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1125000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3816
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0737  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 13.9     |
| timestep                           | 1126000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3723
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0932  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1127000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3809
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 7        |
| loss/actor                         | -661     |
| loss/alpha                         | 0.021    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1128000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3683
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0584   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1129000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3814
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0466   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1130000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3639
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.013    |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1131000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3553
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0202   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.6     |
| timestep                           | 1132000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3918
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0439  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 1133000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3726
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.6      |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0496   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.2     |
| timestep                           | 1134000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3612
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0212  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.4     |
| timestep                           | 1135000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3623
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0354   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 1136000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3741
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0126   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.2     |
| timestep                           | 1137000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3567
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.00308  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1138000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3730
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 8.92     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0327  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.8     |
| timestep                           | 1139000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3618
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00489 |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1140000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3702
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0151   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 1141000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3598
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0284  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.4     |
| timestep                           | 1142000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3669
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.00529  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.2     |
| timestep                           | 1143000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3778
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0656   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1144000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0813  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 1145000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3687
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0368   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1146000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3663
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00636 |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1147000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3695
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.00741  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1148000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3707
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00215 |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 1149000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3624
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.095    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1150000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3662
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.117   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1151000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3690
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 6.26     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0555   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1152000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3741
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 8.82     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0354   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1153000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3637
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0657   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1154000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3635
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0104  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1155000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3597
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 9.88     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.147   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1156000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3602
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.031   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1157000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3736
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0572  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 1158000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3677
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0795  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.8     |
| timestep                           | 1159000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3751
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 1160000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3721
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00854 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1161000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3730
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0141  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.4     |
| timestep                           | 1162000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3642
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0245  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1163000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0938   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1164000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3677
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -661     |
| loss/alpha                         | -0.012   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1165000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3799
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00586 |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 1166000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3812
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0441  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1167000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3723
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 4.05     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0477  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1168000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3942
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 3.88     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0198  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1169000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3554
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.00453  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1170000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3646
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0671   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1171000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3891
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0711  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.3     |
| timestep                           | 1172000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3890
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.3     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0191  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1173000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3615
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.02    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1174000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3883
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0093   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 1175000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3757
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.151    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1176000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3741
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.024   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1177000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3682
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1178000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00109 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.5     |
| timestep                           | 1179000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3730
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0721   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1180000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3602
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0134   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1181000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3733
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0412   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1182000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3714
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0324   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1183000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3759
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0891  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 1184000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3636
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0132  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 1185000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00637  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1186000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3641
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.78     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0948   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.3     |
| timestep                           | 1187000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3552
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0416   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1188000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3650
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.044   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1189000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3571
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0292   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 1190000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3599
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 9.98     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0489  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1191000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3855
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -662     |
| loss/alpha                         | -0.046   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1192000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3864
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0468  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 1193000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0377   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1194000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3733
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0436  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1195000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3768
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0412  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1196000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3584
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0527   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 1197000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3763
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0192   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 1198000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0326  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1199000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0102   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1200000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3707
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0325  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1201000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3771
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 4.64     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0061   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1202000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3822
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0133  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1203000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0181  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1204000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3681
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0569  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1205000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3603
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.034    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1206000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3705
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00695  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1207000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3666
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 42.5     |
| eval/normalized_episode_reward_std | 27.8     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00747 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1208000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3616
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 6.34     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0755   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.4     |
| timestep                           | 1209000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3770
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0184  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 1210000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3690
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0487   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 1211000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3666
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 4.21     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0255   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.7     |
| timestep                           | 1212000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3677
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0478  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1213000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3581
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0131   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1214000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3522
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.051   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1215000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3696
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0574  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1216000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3582
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 9.77     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.00293 |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1217000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3629
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.106    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 1218000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3742
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0411   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1219000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3680
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.000785 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1220000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3627
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0342   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1221000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3739
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 6.97     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0168  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.8     |
| timestep                           | 1222000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3733
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0798  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1223000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3636
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0146  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.6     |
| timestep                           | 1224000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3644
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00667  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.6     |
| timestep                           | 1225000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3630
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.1     |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1226000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3698
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0309   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1227000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3690
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0439   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.8     |
| timestep                           | 1228000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3746
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 8.03     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0112  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1229000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3729
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0341   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1230000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3573
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0099  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1231000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3711
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.8     |
| timestep                           | 1232000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3669
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0397   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1233000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3574
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.123    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1234000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3779
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.64     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00664  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1235000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3760
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0745  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1236000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3788
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0252   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.8     |
| timestep                           | 1237000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 5.06     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0698   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 1238000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3825
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0742  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1239000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3701
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0631   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1240000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3650
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 13.2     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0841  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1241000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0297   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.7     |
| timestep                           | 1242000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3702
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0668   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1243000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3712
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0352  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1244000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3678
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00162 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1245000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3749
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0418  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1246000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3699
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00127 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1247000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3863
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 4.05     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0238  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1248000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3811
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0132   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1249000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3731
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1250000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0223  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1251000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3671
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0677  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1252000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3623
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0043   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1253000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3725
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0239  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1254000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3564
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00582  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1255000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3744
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0149   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1256000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3701
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0581   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.4     |
| timestep                           | 1257000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 8.97     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00384 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1258000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3823
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0233   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1259000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3681
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0727  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1260000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3652
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00578  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1261000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3715
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1262000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3727
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 7.27     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00147  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1263000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3886
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.012    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1264000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3733
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0572   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1265000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3771
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1266000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3666
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.1     |
| eval/normalized_episode_reward_std | 28.6     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00552  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1267000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3858
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0361   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1268000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3817
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0614  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1269000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3738
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0626   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1270000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3787
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0652  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1271000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3829
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.8     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0338   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.3     |
| timestep                           | 1272000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3680
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0362   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1273000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3638
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -664     |
| loss/alpha                         | 0.018    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 1274000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3796
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0166  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1275000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3865
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0506   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1276000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3849
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1277000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3809
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0156   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1278000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3706
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 1279000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3703
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0202  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1280000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0348  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1281000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3775
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00211  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1282000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3519
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0122   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1283000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3775
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.077    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 1284000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3669
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0216  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1285000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3720
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0109  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1286000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3763
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00854  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1287000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3732
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0187   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1288000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3806
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0359  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1289000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3816
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.109   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1290000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3773
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0106   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1291000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3687
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0736   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1292000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3702
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1293000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3947
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0169   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1294000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 6.85     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0189   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1295000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00178 |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1296000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3689
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 8.95     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0143   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 13.9     |
| timestep                           | 1297000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3710
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1298000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3696
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0134   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1299000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3930
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0576  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 1300000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3829
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.019   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 1301000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3705
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0203  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1302000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3887
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0418   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1303000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.4     |
| timestep                           | 1304000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3821
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0279  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 1305000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3800
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0139   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1306000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3870
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0395   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1307000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3913
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0725  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.3     |
| timestep                           | 1308000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3721
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0112   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1309000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3642
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0151   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 1310000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3621
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.059   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1311000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3644
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0194  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.8     |
| timestep                           | 1312000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3801
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 4.4      |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0111   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1313000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3798
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0914  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1314000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3713
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.05     |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1315000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3807
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00402  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1316000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3904
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00528 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1317000  |
----------------------------------------------------------------------------------
num rollout transitions: 249999, reward mean: 4.3847
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0312   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.2     |
| timestep                           | 1318000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3869
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0011   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1319000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3806
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0425   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1320000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3621
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0268  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1321000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3768
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0481   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1322000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3714
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.112    |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 1323000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3666
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0151  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1324000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3618
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0831  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1325000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3949
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.066   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1326000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3683
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0779   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1327000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3675
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 4.72     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0219  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 1328000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3693
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0203  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1329000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3766
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.091   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1330000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3799
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.122    |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1331000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3778
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.123    |
| loss/critic1                       | 26.6     |
| loss/critic2                       | 26.3     |
| timestep                           | 1332000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3601
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1333000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3761
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 1334000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3865
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1335000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3833
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0133   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1336000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3752
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0754   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1337000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3623
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 7.05     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0375   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1338000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3785
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0104   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1339000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3870
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.8      |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0201   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1340000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3533
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0266  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1341000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3673
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0245   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1342000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3726
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 4.38     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.00786  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1343000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3622
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0752   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1344000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3719
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0783  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1345000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3724
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0406   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1346000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3690
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0188   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1347000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3579
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0413   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.8     |
| timestep                           | 1348000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3637
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.116   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1349000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3726
-----------------------------------------------------------------------------------
| alpha                              | 0.152     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 77.3      |
| eval/normalized_episode_reward_std | 2.98      |
| loss/actor                         | -666      |
| loss/alpha                         | -0.000873 |
| loss/critic1                       | 14.7      |
| loss/critic2                       | 14.4      |
| timestep                           | 1350000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3743
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1351000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3850
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.013   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1352000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3782
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0306   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1353000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3771
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0609   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1354000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3768
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0327  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1355000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3963
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0418   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1356000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3781
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.095   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.5     |
| timestep                           | 1357000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3623
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.08     |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1358000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3861
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0533  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1359000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3773
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 8.54     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0703   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1360000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3648
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0388   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.8     |
| timestep                           | 1361000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3682
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0929   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1362000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3789
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.104   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1363000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3737
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 9.11     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0223  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1364000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3652
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0817   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1365000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3806
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0574   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1366000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3823
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.074   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1367000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3721
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0275  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.5     |
| timestep                           | 1368000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.12     |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 1369000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3710
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -666     |
| loss/alpha                         | -0.195   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1370000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.131    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1371000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3651
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 4.07     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1372000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3831
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0612   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1373000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3840
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.121   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.2     |
| timestep                           | 1374000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3731
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1375000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3757
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0355   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 1376000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0611   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1377000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3663
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0746  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1378000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3666
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1379000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3852
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0443   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1380000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3688
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 8.47     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.17    |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1381000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0468   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1382000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3796
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00718  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1383000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3711
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00656 |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 1384000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3686
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0142  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1385000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3745
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.104    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.7     |
| timestep                           | 1386000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3648
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0771   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.4     |
| timestep                           | 1387000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3699
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.68     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.064   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1388000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3673
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0323  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 1389000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3632
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0542   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1390000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3650
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0334   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1391000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3767
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0398   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1392000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3564
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0449  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1393000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3669
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0274   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.4     |
| timestep                           | 1394000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3804
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.00575  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1395000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3656
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0203  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1396000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3718
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00729 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1397000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3724
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 6.22     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0331   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1398000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3788
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0549   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1399000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3621
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0709  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1400000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3739
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0784  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1401000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3763
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0681  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1402000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3577
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 9.64     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0152  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1403000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3819
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 4.93     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0737   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.5     |
| timestep                           | 1404000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3711
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 8.09     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0671   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1405000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3737
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00375 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1406000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3841
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0308   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1407000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3706
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00606 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1408000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3767
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0375  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1409000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3732
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0288  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1410000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3759
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00894 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1411000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3790
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0415   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1412000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3664
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0064   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1413000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3638
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1414000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0374  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1415000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3787
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0228  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1416000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3635
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.094    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1417000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3717
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 7.59     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0489   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1418000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3843
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 7.1      |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0301  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1419000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3751
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0402  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1420000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3811
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 1421000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3656
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.4     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0206  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1422000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3647
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0222   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1423000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3722
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0754  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1424000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3631
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00783 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1425000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3841
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 9.98     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0457   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1426000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3703
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0659   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1427000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3702
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.00361  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 1428000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3710
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0579   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1429000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3704
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0288   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1430000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3731
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0597  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1431000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3674
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.94     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.075   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1432000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3684
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.139   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1433000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3673
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 11       |
| loss/actor                         | -667     |
| loss/alpha                         | 0.00236  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.4     |
| timestep                           | 1434000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3773
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0457  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1435000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3849
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.178    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1436000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3772
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0493  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.8     |
| timestep                           | 1437000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3637
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.6      |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0185   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1438000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3657
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 10.3     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0581   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1439000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3748
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0305   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1440000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3639
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.000454 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1441000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3737
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 7.31     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0358  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1442000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3698
-----------------------------------------------------------------------------------
| alpha                              | 0.151     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 71.9      |
| eval/normalized_episode_reward_std | 3.27      |
| loss/actor                         | -667      |
| loss/alpha                         | -0.000426 |
| loss/critic1                       | 14.6      |
| loss/critic2                       | 14.5      |
| timestep                           | 1443000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3823
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0723  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1444000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3882
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0797  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1445000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3700
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0751   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1446000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3606
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.018   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 1447000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3755
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0237  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1448000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -667     |
| loss/alpha                         | -6.7e-05 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1449000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3834
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -666     |
| loss/alpha                         | 0.053    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1450000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3898
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.000172 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 1451000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3746
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0461  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1452000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3770
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0302   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1453000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3778
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0282  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1454000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3880
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0907  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1455000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3840
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.038    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1456000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3676
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 7.85     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.013    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1457000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3853
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0837   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.7     |
| timestep                           | 1458000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3798
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0297  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 1459000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3776
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0855  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1460000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3663
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.093    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1461000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3845
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0847  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1462000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3761
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0292   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1463000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3798
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0102   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1464000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3844
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0613   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1465000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3803
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 6        |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0107  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1466000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3800
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0717   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1467000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3592
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0288  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1468000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0412  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1469000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3941
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0702  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 1470000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3972
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00277 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 1471000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3864
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0294  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 1472000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3701
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0643  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 1473000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3767
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.084    |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.8     |
| timestep                           | 1474000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3734
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 11.2     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00436 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 1475000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3771
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0318   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1476000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3949
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1477000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3822
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1478000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3809
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0504  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 1479000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3861
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.00749  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.8     |
| timestep                           | 1480000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3898
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0686   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1481000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0356   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1482000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3697
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0025  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1483000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3740
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0053  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 1484000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3822
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0261  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1485000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0378  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1486000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3762
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0164  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1487000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3705
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0251  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1488000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3685
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0581   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 1489000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3771
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0253  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1490000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3780
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0411   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 1491000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3762
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0332   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1492000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.00163 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1493000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3814
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0344  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1494000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3903
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0614   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1495000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3650
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.00233  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1496000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3771
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0325  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1497000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3618
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0808   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1498000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3748
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0546  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 1499000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3828
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0501   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1500000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3640
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0599  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1501000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0183   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1502000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3861
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0926  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1503000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3794
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 5.25     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0305  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1504000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3784
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.179    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1505000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3574
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00966 |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1506000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3587
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0168   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1507000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3765
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 6.18     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0114   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1508000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3897
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0334  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1509000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3702
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1510000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3800
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0709  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1511000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3769
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0169  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1512000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3791
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0197   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1513000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3581
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0196  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1514000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3740
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0478   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1515000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3717
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00246 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1516000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3837
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0263   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1517000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3727
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00374 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1518000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3605
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00783 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1519000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3726
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0153   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1520000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3775
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.126   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1521000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0569   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1522000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3732
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.042    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.7     |
| timestep                           | 1523000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3758
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0711  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.6     |
| timestep                           | 1524000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3821
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0593  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 1525000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3689
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.62     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0275   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1526000  |
----------------------------------------------------------------------------------
num rollout transitions: 249999, reward mean: 4.3701
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0496   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 1527000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3773
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0776  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1528000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3803
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.026    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1529000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3719
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1530000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3873
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0111  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.5     |
| timestep                           | 1531000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3773
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0839   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.5     |
| timestep                           | 1532000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3780
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0768   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1533000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3787
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0254   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 13.9     |
| timestep                           | 1534000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3867
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 8.67     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.000937 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1535000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3812
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0874  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1536000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3838
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0768   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1537000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3776
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0151   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1538000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3783
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0403   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1539000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3767
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0259  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1540000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3715
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0754  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1541000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3885
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0163  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1542000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3694
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0235   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1543000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3730
-----------------------------------------------------------------------------------
| alpha                              | 0.151     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 77.5      |
| eval/normalized_episode_reward_std | 4.06      |
| loss/actor                         | -671      |
| loss/alpha                         | -0.000389 |
| loss/critic1                       | 14.8      |
| loss/critic2                       | 14.6      |
| timestep                           | 1544000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3792
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1545000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3779
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0283   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1546000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3786
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0247   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 1547000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3740
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.156   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1548000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3855
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.129    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1549000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3687
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 9.39     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0481  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 1550000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3755
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.01    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1551000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3923
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0757   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.1     |
| timestep                           | 1552000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3711
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0687  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1553000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3808
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0155  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1554000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3781
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0936   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1555000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0341   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 1556000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3721
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.06     |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1557000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3848
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0965  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1558000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3863
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1559000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3697
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0834   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1560000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3804
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -670     |
| loss/alpha                         | 0.000565 |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1561000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3800
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0858  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1562000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0377   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1563000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3733
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0487   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1564000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3835
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00931 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1565000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3716
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 5.28     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.158   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1566000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0446  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1567000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3842
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0342  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1568000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3770
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0383   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1569000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3885
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00296 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1570000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3700
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0203  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1571000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3731
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0354   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1572000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3854
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0372   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1573000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3686
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0765   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1574000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3722
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0136  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1575000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00757 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1576000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3725
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0864  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1577000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3635
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.5     |
| timestep                           | 1578000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3691
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0284  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1579000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3761
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0544   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1580000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3886
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.118    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1581000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3732
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0226   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1582000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3751
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.63     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0655   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1583000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3774
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0123  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1584000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3717
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0314  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 1585000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3818
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0454  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1586000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3996
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0405  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1587000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3850
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1588000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3749
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0908  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1589000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3703
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0127   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1590000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3762
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0615   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 1591000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3667
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0962  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1592000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3775
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0769   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1593000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3646
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0205  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 1594000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3661
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0201  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1595000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3780
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0424  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1596000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3711
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0387   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1597000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3990
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0754   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1598000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3902
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0983   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.8     |
| timestep                           | 1599000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3937
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.000654 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1600000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3811
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.048   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1601000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3796
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0195   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1602000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3775
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0277  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1603000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3833
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00803  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 1604000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3786
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.000575 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.8     |
| timestep                           | 1605000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3600
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0388   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1606000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3721
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0263  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1607000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3708
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00824 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1608000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3908
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0134  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1609000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3852
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.02     |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.6     |
| timestep                           | 1610000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3666
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 6.11     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.041   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1611000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3838
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0229   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1612000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3846
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0498  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1613000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3941
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00151 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1614000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3709
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0786   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1615000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3699
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0587  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1616000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3731
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0429  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1617000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3715
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0546   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1618000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3811
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0224   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1619000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00848  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1620000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3683
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 8.37     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.024   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1621000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3606
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.146   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1622000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1623000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3660
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1624000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0416   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1625000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3815
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0753  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 1626000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3698
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0115  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1627000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3866
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0342   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.4     |
| timestep                           | 1628000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3789
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.085   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 19.1     |
| timestep                           | 1629000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3860
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0522   |
| loss/critic1                       | 34.9     |
| loss/critic2                       | 34.5     |
| timestep                           | 1630000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3974
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0501  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1631000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3806
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0298  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1632000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3722
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0948   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 1633000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3760
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0535   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1634000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0468   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1635000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3723
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0252  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1636000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0324   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1637000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3855
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0212   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1638000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3735
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0179   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1639000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.71     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0512  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1640000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3769
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00239 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1641000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0792   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1642000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3816
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.148   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1643000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3815
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0164   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1644000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3901
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 1645000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3721
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0495   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1646000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3782
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00161  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1647000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3691
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 7.73     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00405 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 1648000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1649000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3828
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0395  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1650000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3784
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0337  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1651000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -674     |
| loss/alpha                         | 0.109    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1652000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3591
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00981 |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1653000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3763
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0648  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1654000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3801
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0221  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 1655000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3823
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0795  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1656000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3705
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0726  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1657000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3765
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0175   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1658000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3742
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.076    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1659000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3688
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00859  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1660000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3670
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00573 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1661000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3841
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0444  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1662000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3800
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 9.61     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0576   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1663000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3830
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 8.27     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0455  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1664000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3619
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00252 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1665000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3849
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0355   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1666000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3668
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.033    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1667000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3767
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0632   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1668000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3885
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0442   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1669000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3779
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.105   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1670000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3851
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0644   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1671000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3826
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0814  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1672000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3671
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 8.55     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0704   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1673000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3708
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0451  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1674000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -673     |
| loss/alpha                         | -0.224   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1675000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3883
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.09     |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1676000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3944
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 7.33     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0426   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1677000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3813
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0479   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1678000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3712
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0734   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1679000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0224   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1680000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3787
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0533  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1681000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3807
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0146  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1682000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3916
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0262  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 1683000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3748
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.026    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1684000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3798
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1685000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3669
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0352  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1686000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3828
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 7.55     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0945   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.2     |
| timestep                           | 1687000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3811
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.159    |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1688000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3705
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.14    |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.6     |
| timestep                           | 1689000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3798
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0876  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1690000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3745
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 5.32     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.037   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.6     |
| timestep                           | 1691000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3875
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0189  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1692000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3722
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0542  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1693000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3931
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0638   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1694000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3833
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00827 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1695000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3826
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0997  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1696000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3779
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0592  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1697000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3638
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 10.2     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00444  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1698000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3758
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0214   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1699000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3861
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0285  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15       |
| timestep                           | 1700000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3820
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0886  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1701000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3778
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.161    |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 1702000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3945
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00827  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 1703000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3847
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0275  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1704000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3869
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0443   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 1705000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3728
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0399  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 1706000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3769
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 5.13     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0382  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1707000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3769
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0421   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1708000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3826
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0492  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1709000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3678
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.027    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1710000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3762
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.000925 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1711000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3821
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1712000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3718
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0694   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1713000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3815
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0208   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1714000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3820
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1715000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3821
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.033    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1716000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3862
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1717000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00219  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1718000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3669
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.134   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1719000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3811
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0546   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1720000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3723
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0789   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1721000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3755
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.117    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1722000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3712
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1723000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3719
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0536  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1724000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3760
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0147  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1725000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3853
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0418  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1726000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3786
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0452  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1727000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3858
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.7     |
| eval/normalized_episode_reward_std | 29.3     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0658   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1728000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3746
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 8.74     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0732   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1729000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3847
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.09    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1730000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3740
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0349   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1731000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3798
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0727  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1732000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0513   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1733000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3932
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0161  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1734000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3844
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.044    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.5     |
| timestep                           | 1735000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3669
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.086    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1736000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3824
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1737000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3817
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.044   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1738000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3660
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.000436 |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1739000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3802
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 5.07     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0569   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1740000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3970
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 5.85     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0659   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1741000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3700
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0436  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1742000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3813
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.119   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1743000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3910
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1744000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3800
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1745000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3839
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0582  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1746000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3777
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0069   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1747000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3779
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0742   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1748000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3748
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0743   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1749000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3784
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0202  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1750000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3687
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0533  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1751000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3910
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1752000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3915
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.125   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1753000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0898   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1754000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3665
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0204  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1755000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3806
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0902   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1756000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3787
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.78     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0715   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1757000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3696
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0054   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1758000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3778
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.03     |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1759000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3932
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0157  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1760000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3894
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -675     |
| loss/alpha                         | 3.66e-05 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1761000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3650
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0182   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1762000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.78     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0997  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1763000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3647
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0622  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1764000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3714
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00291 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1765000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.096    |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1766000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3751
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0218   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 14.9     |
| timestep                           | 1767000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3755
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0898   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1768000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3812
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0727  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1769000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3815
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0603   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1770000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3616
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 8.57     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0552   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1771000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3758
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0305  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1772000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.053   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1773000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3823
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -673     |
| loss/alpha                         | -0.147   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1774000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3768
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0198   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 1775000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3781
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0274   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1776000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3821
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00688  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1777000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3728
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0425   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1778000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3751
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0606  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1779000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3789
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0501  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1780000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3775
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0334   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1781000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3547
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 4.43     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0842   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1782000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3786
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0556  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1783000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3738
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.3     |
| timestep                           | 1784000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3666
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0441   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1785000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3765
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00355 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.5     |
| timestep                           | 1786000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3742
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0401  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 1787000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3763
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0366   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1788000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3773
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0275   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1789000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3841
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0385   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1790000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3770
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00975 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1791000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3824
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00975  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.7     |
| timestep                           | 1792000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 7.43     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0248   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1793000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3818
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0386  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1794000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3620
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.058   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1795000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3681
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00628 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1796000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3767
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 1797000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3704
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -674     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1798000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3835
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0277  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1799000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3712
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0561  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1800000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3818
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0642  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1801000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3859
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 5.01     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1802000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4005
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0645  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1803000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3784
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0386   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1804000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3812
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 5.47     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0178   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1805000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3866
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00647  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1806000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3757
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0215  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1807000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3851
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1808000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0572  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1809000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3681
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0664   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1810000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3851
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0998   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1811000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3788
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 4.09     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0198  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1812000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4002
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 9.18     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0137  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1813000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0713   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1814000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3748
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0472  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1815000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3824
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0287   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1816000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3731
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0472  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1817000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3920
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 1818000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3919
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0561  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1819000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3794
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 9.14     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0275   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1820000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3742
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 7.03     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0023  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1821000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3758
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0594   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1822000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3739
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.1     |
| timestep                           | 1823000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0136  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1824000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3695
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0779   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1825000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00737 |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1826000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3859
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0429   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1827000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3675
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0426   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1828000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3815
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0095  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1829000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3822
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.116   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1830000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3737
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0616  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 1831000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3710
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.8      |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0764   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1832000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00567  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1833000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3724
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -674     |
| loss/alpha                         | 0.08     |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1834000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3727
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.101   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1835000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3991
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0923   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1836000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3809
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0415  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1837000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3887
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0244  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1838000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3768
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1839000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3767
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0273   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1840000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3839
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0282   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1841000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3731
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0722  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1842000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3815
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.037    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1843000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3874
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00397  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 1844000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3814
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1845000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3792
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0408   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1846000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3873
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1847000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3922
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0362   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1848000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3867
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0109   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 1849000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3773
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0287  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1850000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3850
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0616   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1851000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3774
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1852000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3771
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.041   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1853000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3790
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00126  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1854000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3841
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0128   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1855000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3794
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0124   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1856000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3890
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0217   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1857000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1858000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3785
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.068    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1859000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3706
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0135   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1860000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3631
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -675     |
| loss/alpha                         | -0.107   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1861000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3857
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00815 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1862000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3813
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0641  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1863000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3936
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.029   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1864000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3666
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0553   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1865000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3726
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0498   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1866000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3689
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0871  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1867000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0118  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1868000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3818
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 7.53     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0569  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1869000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3887
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.065    |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1870000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0507   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1871000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3851
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0318  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1872000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3862
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1873000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3854
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0825   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1874000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3986
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0132   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1875000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0123   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1876000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3906
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0294  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 1877000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3935
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0226   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1878000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3843
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00206 |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13       |
| timestep                           | 1879000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3759
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0188  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.8     |
| timestep                           | 1880000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3691
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0675  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.8     |
| timestep                           | 1881000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3846
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0378  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 1882000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3790
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0554  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 1883000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3748
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0585   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 1884000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3752
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -676     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1885000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3824
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0377   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1886000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3895
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0898  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1887000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3910
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1888000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4001
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0212   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1889000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3709
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 1890000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3807
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0935  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 1891000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3862
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0821   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.8     |
| timestep                           | 1892000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3739
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00652 |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 1893000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3780
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00013 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 1894000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3811
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -676     |
| loss/alpha                         | 0.025    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 1895000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3936
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0015  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 1896000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3920
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0342   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 1897000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0127   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 1898000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3770
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.03     |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1899000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3901
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0462   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1900000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3780
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0263  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 1901000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3678
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0922  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1902000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3903
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0826   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1903000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3790
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.013   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1904000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3881
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00601 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 1905000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3892
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0273  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1906000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3886
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0618  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 1907000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3674
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0638  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1908000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3874
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0417   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 1909000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4011
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0113  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 1910000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3784
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0363   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 1911000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3745
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00422 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.2     |
| timestep                           | 1912000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3865
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00178 |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.1     |
| timestep                           | 1913000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3761
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0501   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 1914000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3832
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0289  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1915000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0449   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1916000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3920
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.61     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0844   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1917000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3747
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0493   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 1918000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3731
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0449  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1919000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3780
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0592  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1920000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0589   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1921000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3944
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0683  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1922000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3882
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0031   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 1923000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0273   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 1924000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3853
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 9.95     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0381   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.3     |
| timestep                           | 1925000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3838
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0104  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1926000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1927000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3879
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 7.64     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.025   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 1928000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3723
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00331 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1929000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4000
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.6      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0833  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1930000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3776
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0186  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1931000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3990
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0109  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1932000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3815
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.08     |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 1933000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3977
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00565 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 1934000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3792
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0281   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1935000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3725
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.042    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1936000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3819
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1937000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3881
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0267   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 1938000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3816
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00997 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1939000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3688
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.00982  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 1940000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0548  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1941000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.087   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1942000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3994
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.022    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1943000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3909
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0428   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1944000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3893
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0128   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 1945000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3755
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0602   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1946000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3931
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0533  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 1947000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0971  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1948000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3780
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0488   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 1949000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3773
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0265   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 1950000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3834
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0792  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 1951000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3789
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0198  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 1952000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4008
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0942   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1953000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3898
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.000924 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 1954000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3752
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0563   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1955000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3865
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.03     |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1956000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3882
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0799  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 1957000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3681
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00424 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 12.9     |
| timestep                           | 1958000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3996
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.099    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1959000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3842
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 1960000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3861
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 1961000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3895
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0281   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 1962000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3828
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0331  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 1963000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0274   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 1964000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3859
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 1965000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3798
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0497   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1966000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3866
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0786   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1967000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3760
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0155  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1968000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3771
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0166  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1969000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3773
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.033   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1970000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3736
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0426  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1971000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3806
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0331  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 1972000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3862
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 7.78     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0817   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 1973000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3893
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0443   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 1974000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3880
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0252   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1975000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3880
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0339  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 1976000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3916
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.117   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1977000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3784
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 9.28     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0301   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1978000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3960
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.6      |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0403  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1979000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3821
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0149   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 1980000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3898
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0251   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1981000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3804
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0337   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1982000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3860
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00502 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1983000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3777
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0456  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.2     |
| timestep                           | 1984000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1985000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3854
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.106    |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 1986000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3917
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0405   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 1987000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3796
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00258  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 1988000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0271  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.5     |
| timestep                           | 1989000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3941
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 1990000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3668
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0124   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 1991000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3745
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0624   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 1992000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3739
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0126  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 1993000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3784
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0372   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 1994000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3680
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0493   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1995000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3837
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0491  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1996000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3711
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0643  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 1997000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3796
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0502  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 1998000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3927
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0298   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 1999000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3750
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0466  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2000000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3852
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -678     |
| loss/alpha                         | -0.00661 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2001000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3971
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.045    |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2002000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3879
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0361   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2003000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3779
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0525   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2004000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.024    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 2005000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3831
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.086   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2006000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.124    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2007000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4000
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0512  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2008000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3933
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0182  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2009000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4006
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.125    |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2010000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3832
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0441  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2011000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3807
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0352  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2012000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3831
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0953  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2013000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3833
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0239  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 2014000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3872
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0376   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 2015000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3816
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0428   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2016000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3790
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.043   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2017000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3898
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0691   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2018000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0294  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2019000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0524  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2020000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3782
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2021000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3804
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.123    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2022000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3840
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0491   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2023000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3851
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0724  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2024000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3693
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00885  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 2025000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3910
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.042   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2026000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3731
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0183  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2027000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3888
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00364 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2028000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3801
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.02     |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.1     |
| timestep                           | 2029000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3800
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00718 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 2030000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3801
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0108  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2031000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3694
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00763 |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2032000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3763
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0621  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2033000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3728
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0561  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2034000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3722
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00972  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2035000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3879
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0515  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2036000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3881
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0271  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2037000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0206  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.3     |
| timestep                           | 2038000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3875
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2039000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3917
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0454   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2040000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3724
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0347  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.7     |
| timestep                           | 2041000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3877
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0891   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.3     |
| timestep                           | 2042000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3821
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0123  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2043000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3822
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0283   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2044000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.065   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2045000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3890
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0453   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2046000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3863
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0761   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2047000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3988
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0132  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2048000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3828
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0418   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2049000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3850
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0275  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 2050000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3754
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0828  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2051000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.138    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2052000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4007
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0492   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2053000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3886
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00804 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2054000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3808
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00967  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2055000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3903
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00964  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.5     |
| timestep                           | 2056000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3790
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0256  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2057000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3964
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 4.47     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0588  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2058000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3812
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.94     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0715   |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.6     |
| timestep                           | 2059000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3821
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0403  |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.6     |
| timestep                           | 2060000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3801
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0269   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 2061000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0396  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2062000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3820
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00417  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2063000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0339  |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.6     |
| timestep                           | 2064000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3891
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.6     |
| timestep                           | 2065000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3758
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 10       |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0659  |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.6     |
| timestep                           | 2066000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3816
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0819   |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.7     |
| timestep                           | 2067000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3992
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0687   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2068000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3855
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.61     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2069000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3888
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0475   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2070000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3899
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.00856 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2071000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3820
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.00965 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2072000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3917
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.111   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2073000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3875
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0254  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2074000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3892
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0275  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2075000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3893
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0308   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2076000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.57     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0474   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2077000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3803
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.00223  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2078000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3958
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0706   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2079000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3842
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0146   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2080000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3682
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -679     |
| loss/alpha                         | -0.032   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2081000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0288  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2082000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3794
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0287   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2083000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3864
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0559  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2084000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3860
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.103    |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2085000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3755
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.057    |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2086000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3930
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 5.78     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.00702 |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2087000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3801
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0191   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2088000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3745
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0975  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2089000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3758
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -678     |
| loss/alpha                         | 0.00937  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2090000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3645
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0157  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 2091000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3774
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.00247  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2092000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3785
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0957  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2093000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3757
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0401  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2094000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3912
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0612  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2095000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3776
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 4.09     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0626   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.8     |
| timestep                           | 2096000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3814
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.031    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2097000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3838
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0927   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2098000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3828
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -678     |
| loss/alpha                         | -0.177   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2099000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3834
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.00445  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2100000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3915
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.028   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2101000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3952
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2102000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3851
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0121  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2103000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3878
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0475   |
| loss/critic1                       | 12.5     |
| loss/critic2                       | 12.4     |
| timestep                           | 2104000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3786
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.158    |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2105000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3866
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 6.85     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0643  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2106000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3874
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0479   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2107000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3876
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -679     |
| loss/alpha                         | 0.112    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2108000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3806
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0243   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2109000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3928
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0686  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2110000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3792
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.056   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.1     |
| timestep                           | 2111000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4067
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0159   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2112000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3931
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.046    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2113000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3941
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0279  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2114000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3879
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0742   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2115000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3822
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0158   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2116000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3892
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0268  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2117000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3949
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0859  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.4     |
| timestep                           | 2118000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0223   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2119000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3863
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.00654  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2120000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3788
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0514  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2121000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3857
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0192  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2122000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3815
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.55     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0879   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2123000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3837
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.121    |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2124000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3821
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00836  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2125000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3808
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0653  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2126000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4002
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00324  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2127000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3860
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0122   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2128000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3927
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0239  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2129000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3829
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0645  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2130000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3886
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00577 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2131000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3706
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0676   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.3     |
| timestep                           | 2132000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3736
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0503   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2133000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3788
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.119   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2134000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0336  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2135000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0819   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2136000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3758
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0591  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 2137000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.03     |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2138000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3881
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0365  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.1     |
| timestep                           | 2139000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0399   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2140000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0562  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2141000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3772
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00751  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2142000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3946
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0191  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2143000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3863
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0877   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2144000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3839
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2145000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3866
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00608  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2146000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3779
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00661 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2147000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3955
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2148000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3899
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00348  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2149000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3884
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00812 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2150000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3891
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00885 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2151000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3813
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0663  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.5     |
| timestep                           | 2152000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.144    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2153000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3897
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0629   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2154000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3837
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0235   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.6     |
| timestep                           | 2155000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3746
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0884  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2156000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3903
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.055    |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2157000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0963   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2158000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3948
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0418   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2159000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3716
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0552  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2160000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3875
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0046   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2161000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3771
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0578  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2162000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3812
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0482  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2163000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00553  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2164000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3767
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0619  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2165000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0203   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 2166000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3710
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0436  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2167000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3888
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0525  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2168000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3915
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0801   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2169000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3835
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0759   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2170000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0457   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2171000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3858
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0521  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2172000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3974
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.033    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2173000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3829
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.129   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2174000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0735   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2175000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3833
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0355   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2176000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3794
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0243  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2177000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3921
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.154   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2178000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3863
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0939   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2179000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2180000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3743
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.099   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2181000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3849
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 13.9     |
| timestep                           | 2182000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3784
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0629  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2183000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3919
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0155   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2184000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3849
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0029   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 2185000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3892
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0193  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2186000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3969
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0402  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2187000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3915
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0208  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2188000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3809
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0696   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2189000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3905
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2190000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3706
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0325  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2191000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3722
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0436  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 2192000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3799
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.128    |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.2     |
| timestep                           | 2193000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0368  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2194000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3843
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0043  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 2195000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3809
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0285  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.7     |
| timestep                           | 2196000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3716
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0612  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2197000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3919
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0365  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2198000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0289   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2199000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3904
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2200000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3776
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0491   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2201000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3790
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0482   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2202000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3872
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0686  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2203000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3686
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00991  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2204000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3796
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0911  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2205000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3883
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0889   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2206000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3903
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 7.47     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.107    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2207000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0525  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2208000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3891
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 4.8      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0763  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2209000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3841
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0348   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2210000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3960
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.047    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2211000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3915
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00241 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2212000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3881
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00258  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2213000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3953
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0335  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2214000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3948
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0114   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2215000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0214   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2216000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3735
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.00477  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2217000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3813
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.91     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0031   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2218000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3870
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.00639  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2219000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3742
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 9.68     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0524  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2220000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3697
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0207  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2221000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3936
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0267   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2222000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3885
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0381  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2223000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3760
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.00049 |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2224000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3941
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0884   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2225000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3704
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2226000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3835
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0861   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2227000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3760
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0108   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2228000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3816
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0755  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2229000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3888
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00487 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2230000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3906
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 5.14     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2231000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3754
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.11    |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2232000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2233000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3943
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0297  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2234000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3776
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.004   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2235000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3803
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0515  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2236000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3747
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00242 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2237000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3903
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.026   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2238000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0108  |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.5     |
| timestep                           | 2239000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0473   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2240000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3729
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0111  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2241000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3966
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 9.93     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0905   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2242000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3842
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.121   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2243000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3832
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0206   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2244000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3845
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.00276 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2245000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3956
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0287  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.8     |
| timestep                           | 2246000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3957
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.044    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2247000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3779
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0846   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2248000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3725
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0556  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2249000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3877
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.123   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2250000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3896
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 8.54     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0598   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 2251000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3777
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.00109 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2252000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3876
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0408   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2253000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3878
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0664   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2254000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3916
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.4     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0307  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2255000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3954
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0378  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2256000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3963
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.022    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2257000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3949
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0808   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2258000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3825
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0493  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2259000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3932
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0186   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 2260000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3744
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0102   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2261000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3851
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 9.8      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0236  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2262000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3899
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0653  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.6     |
| timestep                           | 2263000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3919
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0354  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2264000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3930
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.63     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.019    |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.1     |
| timestep                           | 2265000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3931
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0955  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 16       |
| timestep                           | 2266000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3687
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0224   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2267000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4000
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.8     |
| timestep                           | 2268000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3910
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -681     |
| loss/alpha                         | 0.032    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 2269000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3884
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2270000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.133   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2271000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3847
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0356  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2272000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3922
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0611  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2273000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3940
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0868   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2274000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0026   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2275000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3745
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.126   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 2276000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3848
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0189   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2277000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3826
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0936   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2278000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3904
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00441  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2279000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3844
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0807   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2280000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3800
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0178   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2281000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3885
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0379  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2282000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3893
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0681   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2283000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3775
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.142   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2284000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3743
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0825  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2285000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3789
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0408   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2286000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3714
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.059    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2287000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3908
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0429  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2288000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3931
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0442   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2289000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3764
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0632  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2290000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3818
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.053   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2291000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3835
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0842   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2292000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3797
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0556   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2293000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3817
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0306   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2294000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3765
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00574 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2295000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3825
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0345  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2296000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3641
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.119   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2297000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0948   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2298000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3823
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.00405  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2299000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3790
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0166   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2300000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3909
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.79     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0157  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2301000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3940
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0976   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2302000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3918
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0135   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2303000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3845
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.115   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2304000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3923
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2305000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3925
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.57     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0624  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2306000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3965
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0855  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2307000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3927
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0566   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2308000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3937
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0385   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2309000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3870
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0389  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2310000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3917
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0708   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2311000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0104  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2312000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3939
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0557  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2313000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3785
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.068    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2314000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3916
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0092   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2315000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0373  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2316000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3865
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.061   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2317000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2318000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3850
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0763   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2319000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4037
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.116   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2320000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3896
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0406   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2321000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3877
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0967   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2322000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3802
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0176   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2323000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3867
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0386   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2324000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3853
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0168   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2325000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4000
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0373  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.3     |
| timestep                           | 2326000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3888
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0124  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2327000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3829
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0391  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2328000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4012
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0501  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2329000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3994
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0318  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2330000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3971
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0407  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2331000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3906
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0106   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2332000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3835
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0788   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.2     |
| timestep                           | 2333000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3953
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0399   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2334000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3923
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2335000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3860
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0562   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2336000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3835
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0293   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2337000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4005
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0436   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2338000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3904
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0803  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2339000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3938
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0712  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2340000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4029
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0557   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2341000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3891
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0254   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2342000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3942
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0496   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2343000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3892
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0827  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2344000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3928
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0137   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 2345000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3946
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0924   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 2346000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3983
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0411  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2347000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3799
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.1     |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2348000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3884
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0506   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2349000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3880
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0411  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2350000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4027
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0946  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.8     |
| timestep                           | 2351000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2352000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3948
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0541   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2353000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4050
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00628 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 2354000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3944
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0601   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 2355000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3872
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0832   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 2356000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3987
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0964  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2357000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3747
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0208   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2358000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3967
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0487  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2359000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3971
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00438 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2360000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3792
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00284 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2361000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3881
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0579   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2362000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3869
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0875  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2363000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3936
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.121    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2364000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3869
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0095   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2365000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00547 |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 2366000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3866
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0529  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2367000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00236  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2368000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3932
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0353  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2369000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3813
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0551  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2370000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3943
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0433   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2371000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3853
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.106    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2372000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3856
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.025    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2373000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3883
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.54     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0799  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2374000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3964
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0969  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2375000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3883
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0405   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2376000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3850
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0793   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2377000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3965
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0012   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2378000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3830
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0646  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2379000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3907
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.13     |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2380000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3814
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0445   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14       |
| timestep                           | 2381000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3780
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2382000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3782
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00319 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 2383000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3842
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0119   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2384000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3883
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.109    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2385000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3803
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.199   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2386000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3766
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0312   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2387000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3879
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0505   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2388000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3931
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.61     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0138   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2389000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4051
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 11.2     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0407  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2390000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3895
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0323  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2391000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3866
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0643   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2392000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3833
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.00386  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2393000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3872
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0923  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 2394000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.031   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2395000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0104   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2396000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.063   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2397000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3983
-----------------------------------------------------------------------------------
| alpha                              | 0.143     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 75.8      |
| eval/normalized_episode_reward_std | 3.03      |
| loss/actor                         | -679      |
| loss/alpha                         | -0.000511 |
| loss/critic1                       | 14        |
| loss/critic2                       | 13.9      |
| timestep                           | 2398000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3970
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0879   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2399000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3951
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0212   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.2     |
| timestep                           | 2400000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0347   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2401000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3904
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0305  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2402000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3923
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.023    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2403000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3873
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2404000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4056
-----------------------------------------------------------------------------------
| alpha                              | 0.146     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 74.3      |
| eval/normalized_episode_reward_std | 2.95      |
| loss/actor                         | -680      |
| loss/alpha                         | -0.000743 |
| loss/critic1                       | 14.3      |
| loss/critic2                       | 14.1      |
| timestep                           | 2405000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3867
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0246  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2406000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3990
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00508  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2407000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3917
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0484  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2408000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4025
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.073    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2409000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3933
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0108  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2410000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3902
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00879  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2411000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3889
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00487 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2412000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3927
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0109  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2413000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3913
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00599  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2414000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3963
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0239   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2415000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3787
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0202  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 2416000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3864
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0351   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 2417000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3765
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0574   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 2418000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3847
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0215  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 2419000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3875
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0352  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2420000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3813
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0378   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2421000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3869
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2422000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3721
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0532  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2423000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3811
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.138   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2424000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3877
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0466  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2425000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3981
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.128    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2426000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3891
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00597  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2427000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3828
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0695  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2428000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3908
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00118  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2429000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3965
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0978   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2430000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3808
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00218  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2431000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4041
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0769  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2432000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3985
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.115   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.7     |
| timestep                           | 2433000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3915
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0263  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2434000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3998
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0607   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.8     |
| timestep                           | 2435000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3910
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.011   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2436000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3991
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0271  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2437000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3948
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0897   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2438000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3869
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0837  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2439000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4018
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0159   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2440000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3872
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0687   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2441000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3919
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2442000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3937
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0563   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2443000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3879
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.067    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 2444000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3793
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.121   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2445000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3788
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00917  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 2446000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3877
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.028   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2447000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3944
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.00333 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2448000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3862
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0347  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2449000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3931
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2450000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4019
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0882   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2451000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3902
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0724   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2452000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3922
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -682     |
| loss/alpha                         | 0.00012  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.9     |
| timestep                           | 2453000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3959
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0837   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2454000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3930
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0689   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 2455000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3805
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0424  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2456000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0194  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2457000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3906
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.138   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2458000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3851
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0295  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2459000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3826
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.123    |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2460000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3964
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0869   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2461000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3977
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0117  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2462000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3889
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0934  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2463000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3884
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0489  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2464000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4014
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0674   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2465000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3915
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0942   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2466000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3893
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0582   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2467000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 4.29     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0316   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2468000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0922  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2469000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3792
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0539  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2470000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3979
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 7.42     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0671   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2471000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3890
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0236  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2472000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.00481  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.4     |
| timestep                           | 2473000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4073
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2474000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3884
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.00789 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2475000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3907
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 7.7      |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0664  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.3     |
| timestep                           | 2476000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3884
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0118  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2477000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3913
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 7.77     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00974 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2478000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3784
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0252   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2479000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3842
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0373  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2480000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3791
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0415  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2481000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3844
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2482000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3957
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0269   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2483000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3998
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0502   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2484000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3910
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0706   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2485000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3795
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0853  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2486000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3908
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00492 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2487000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3872
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2488000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3904
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0458   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2489000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00923  |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.6     |
| timestep                           | 2490000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3767
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0498   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2491000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3926
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0414  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2492000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3846
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0381  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2493000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3830
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0511   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 2494000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3861
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0395   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 2495000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3850
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0174  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2496000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3965
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00686  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2497000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3976
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0771   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2498000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3849
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2499000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3906
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.036    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2500000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3788
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.141   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2501000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3884
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0226  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2502000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3934
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.069    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2503000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3867
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0457  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 2504000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3800
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.077    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2505000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3854
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0529   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2506000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0563  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2507000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3850
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.084    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2508000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3856
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0379  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2509000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3840
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0651  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2510000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3940
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.56     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0337  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2511000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3923
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.00366  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2512000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3873
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.68     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0244  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2513000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4021
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0428  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2514000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3950
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0782   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2515000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3922
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -681     |
| loss/alpha                         | 0.106    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2516000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3903
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0928  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2517000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3974
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0487   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2518000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3880
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00672  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2519000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3753
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0711  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2520000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3856
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 2521000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3864
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.69     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.021    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2522000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3876
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.112    |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 2523000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4038
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0303  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2524000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2525000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3843
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0592  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 2526000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3893
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.107   |
| loss/critic1                       | 26.8     |
| loss/critic2                       | 28.4     |
| timestep                           | 2527000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3859
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.164   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2528000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4108
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.106   |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 14.9     |
| timestep                           | 2529000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3969
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.112    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2530000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3921
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0402  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2531000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3932
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0819   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2532000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4004
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 9.04     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0008   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2533000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3963
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0424   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2534000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3960
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0127   |
| loss/critic1                       | 12.4     |
| loss/critic2                       | 12.3     |
| timestep                           | 2535000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3976
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.075   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.3     |
| timestep                           | 2536000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3938
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0548   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2537000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3948
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0147  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2538000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3938
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0557  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2539000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3964
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0895   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2540000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3886
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.00347  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2541000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3987
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0444   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 2542000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4113
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0948  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2543000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3896
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0519  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2544000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3843
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0344  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2545000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3942
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 2546000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4001
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.12    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2547000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4011
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.107    |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2548000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4000
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0602  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2549000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4072
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0666   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2550000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3882
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0813   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2551000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3938
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.7     |
| timestep                           | 2552000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3874
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00295 |
| loss/critic1                       | 12.4     |
| loss/critic2                       | 12.3     |
| timestep                           | 2553000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3812
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00562 |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2554000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3787
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0444  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2555000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3944
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0793  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2556000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3938
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2557000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0263  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2558000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3879
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0518  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2559000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3945
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00189 |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.6     |
| timestep                           | 2560000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3841
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0675   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2561000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4005
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0375   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2562000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3882
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0297   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.3     |
| timestep                           | 2563000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3887
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00944  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2564000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3789
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0129  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.6     |
| timestep                           | 2565000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3886
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00474 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2566000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3895
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0721  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2567000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3905
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0464   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2568000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3952
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00994 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2569000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3976
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2570000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3810
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0106   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2571000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3840
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0356   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2572000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3810
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0342   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2573000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3878
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0945  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2574000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3916
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2575000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3835
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.088   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2576000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3972
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0116   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2577000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4078
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0142  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2578000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3946
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.6     |
| timestep                           | 2579000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3985
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0175   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2580000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0151   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2581000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3861
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00124  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2582000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3957
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0411  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2583000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3883
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0475  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2584000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3975
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0274   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2585000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3909
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0991   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2586000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3896
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0715  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2587000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3895
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0598  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2588000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3892
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0271   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2589000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3857
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00939 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2590000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3982
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00914  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2591000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3989
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00664 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2592000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4048
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.017   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 2593000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3999
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0928   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 2594000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3889
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0815   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2595000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3936
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 5.27     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0545   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2596000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3943
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0559  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.7     |
| timestep                           | 2597000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3778
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 13       |
| timestep                           | 2598000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3919
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0174   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2599000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3974
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0311  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2600000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3921
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0193  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2601000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3913
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.151   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2602000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3995
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0199  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2603000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3936
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.6      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.13     |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2604000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3943
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0346  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2605000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3890
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0497   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 2606000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3896
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0231   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2607000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3880
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0854   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2608000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4062
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2609000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3970
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0967  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 2610000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3848
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0401  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 2611000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3874
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0707   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2612000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3878
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0439   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2613000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3852
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2614000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3853
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.155   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2615000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0698   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2616000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3959
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 7.87     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0306   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2617000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3850
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.065    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2618000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3927
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0652  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2619000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3845
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.046   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2620000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3912
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2621000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3957
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0658  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2622000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3960
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0929   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2623000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4047
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0536   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2624000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3882
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0316   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2625000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3853
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0474  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2626000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3901
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0395  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2627000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3840
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0508  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2628000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3945
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0533   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2629000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3955
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0688   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2630000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3846
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0717  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2631000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3901
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0537   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2632000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3922
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.044    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2633000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3869
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2634000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3881
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0101   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.1     |
| timestep                           | 2635000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3955
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0289  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2636000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3822
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 4.07     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0273   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 2637000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3957
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 9.85     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0084   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2638000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3896
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.135   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2639000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3869
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0332  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 16.5     |
| timestep                           | 2640000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3936
----------------------------------------------------------------------------------
| alpha                              | 0.138    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -679     |
| loss/alpha                         | -0.162   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 16.8     |
| timestep                           | 2641000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4087
----------------------------------------------------------------------------------
| alpha                              | 0.137    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0451   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2642000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4032
----------------------------------------------------------------------------------
| alpha                              | 0.137    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.72     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0536   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2643000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3926
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0694   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2644000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4053
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00258  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2645000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.161    |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 2646000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3978
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0368   |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.5     |
| timestep                           | 2647000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3912
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0617  |
| loss/critic1                       | 12.4     |
| loss/critic2                       | 12.3     |
| timestep                           | 2648000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3977
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 5.37     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0178   |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.6     |
| timestep                           | 2649000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3898
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2650000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0561  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2651000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4064
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0253   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2652000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3964
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.048   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2653000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3985
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0758  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2654000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4048
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.044   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2655000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4042
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0561   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2656000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3936
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0704   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2657000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4005
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0392   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2658000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3874
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2659000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3946
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.11    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2660000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3920
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0157   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2661000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3847
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.133    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2662000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00695  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2663000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4041
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0317  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2664000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3872
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0103   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2665000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3983
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0614  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2666000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0137   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2667000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3838
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.091    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2668000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3831
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0275  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2669000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3950
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.08    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2670000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3943
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0497   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2671000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3894
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0482  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2672000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3881
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0344  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2673000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00176 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2674000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3991
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0834   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2675000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3945
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00571  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2676000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3916
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -680     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2677000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4001
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00412  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2678000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3966
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0369   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2679000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3970
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0105  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 2680000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3831
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 2681000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3984
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0486  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2682000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4098
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0797  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2683000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3902
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0211  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2684000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3981
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0127   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2685000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3980
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0473   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2686000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3947
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00126  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2687000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3827
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0771   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2688000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4003
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.054    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2689000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0478  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2690000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3936
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0319  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2691000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3928
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0737  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2692000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3966
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0254   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2693000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3920
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0652   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2694000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3993
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.09    |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2695000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3934
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0279   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2696000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3944
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00418 |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2697000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3919
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0206  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2698000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3913
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0119   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2699000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3980
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0286  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2700000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3998
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0768   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2701000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3944
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0809   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2702000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3997
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0192   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2703000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3992
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00436 |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 2704000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3944
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0268   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2705000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3997
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0747  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2706000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3916
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0443  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2707000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3982
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2708000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3788
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.04    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2709000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4064
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0894   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2710000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4074
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00867 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2711000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3942
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0753   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2712000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3978
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 2713000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3960
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0498  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2714000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3912
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0233  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2715000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3716
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0274  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 2716000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3901
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0495  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2717000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 7.34     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0803  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.2     |
| timestep                           | 2718000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4011
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.00991  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2719000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3981
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2720000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0709   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2721000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3948
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.00661 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2722000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3964
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 6.42     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0735  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2723000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.000876 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2724000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3886
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.024    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2725000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3856
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -680     |
| loss/alpha                         | 0.0855   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2726000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3744
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0941  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2727000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3918
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0217  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2728000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3904
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0479   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2729000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3925
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0418   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2730000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3910
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0177  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2731000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3971
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0561  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2732000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3954
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0399   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2733000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4020
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 6.18     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0788   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2734000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3899
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -680     |
| loss/alpha                         | -0.028   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2735000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3954
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -680     |
| loss/alpha                         | -0.0488  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2736000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4065
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.019   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2737000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4012
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0933   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2738000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3952
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0542  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2739000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3935
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 7.32     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0687  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2740000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3987
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0791   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2741000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3895
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0604  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2742000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3992
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0425   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2743000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3866
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.17     |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.8     |
| timestep                           | 2744000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3894
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0857  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2745000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3919
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.11    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.7     |
| timestep                           | 2746000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4036
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0758  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2747000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3968
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0979   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 2748000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3905
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 6        |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0657  |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2749000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3944
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0305  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 12.9     |
| timestep                           | 2750000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3852
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0579   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2751000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.024   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2752000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3942
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0594   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2753000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4050
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.00638  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2754000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3878
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2755000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3838
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0559  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2756000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3773
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0229   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2757000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3881
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0577  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2758000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3880
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0245   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2759000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3934
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.073    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2760000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3939
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -683     |
| loss/alpha                         | -0.117   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2761000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3907
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.00721 |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2762000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3893
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -682     |
| loss/alpha                         | -0.128   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2763000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3877
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.00948 |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2764000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4045
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.00581 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2765000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.055   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2766000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3930
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0839   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2767000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3877
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0748   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2768000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4133
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0702  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2769000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3915
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0593   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2770000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3882
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.092    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2771000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3859
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0263   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2772000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3926
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -683     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2773000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3895
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0826  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2774000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3952
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.133    |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2775000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3906
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0939   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2776000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3948
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.00554  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2777000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3947
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0549   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2778000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3964
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.172   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2779000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3908
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0326  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2780000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4005
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0421  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2781000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4001
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0291  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2782000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4009
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0234   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2783000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4060
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0252   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2784000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3984
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.00252  |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2785000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3893
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0048  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2786000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3884
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0402   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2787000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3882
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0759  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2788000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3891
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2789000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3778
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.84     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.084    |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2790000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3892
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2791000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4041
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.00274 |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2792000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3884
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0561  |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.7     |
| timestep                           | 2793000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3865
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0351  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2794000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3843
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2795000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3823
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.3     |
| timestep                           | 2796000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3803
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0245   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2797000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3962
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0943  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2798000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3887
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0213  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2799000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3947
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0498   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.1     |
| timestep                           | 2800000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3895
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0291   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.3     |
| timestep                           | 2801000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3920
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0286  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2802000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3836
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.046   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 2803000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3800
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0825   |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.9     |
| timestep                           | 2804000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3953
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0508  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2805000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3894
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00773 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2806000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3949
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0236  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2807000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4032
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0543  |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.5     |
| timestep                           | 2808000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3964
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0726   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.3     |
| timestep                           | 2809000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4044
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0392   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2810000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3912
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0704   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2811000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3820
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0781  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2812000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3875
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0164   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2813000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0287  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2814000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3871
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.00435  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2815000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3928
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.0533  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2816000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3885
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.132   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2817000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4035
----------------------------------------------------------------------------------
| alpha                              | 0.138    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.00836 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2818000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3893
----------------------------------------------------------------------------------
| alpha                              | 0.139    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0668   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2819000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3920
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0799   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2820000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3947
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.00961 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2821000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3966
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0124   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2822000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0756   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.5     |
| timestep                           | 2823000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3959
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.083   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2824000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3907
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0658   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2825000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4013
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.000739 |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2826000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4072
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.00882  |
| loss/critic1                       | 12.3     |
| loss/critic2                       | 12.3     |
| timestep                           | 2827000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3863
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0783  |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.6     |
| timestep                           | 2828000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3827
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0614  |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.6     |
| timestep                           | 2829000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3857
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 5.28     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0267  |
| loss/critic1                       | 12.6     |
| loss/critic2                       | 12.6     |
| timestep                           | 2830000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3946
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0265   |
| loss/critic1                       | 12.5     |
| loss/critic2                       | 12.4     |
| timestep                           | 2831000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3956
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0761   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2832000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3868
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0658   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2833000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0173  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.6     |
| timestep                           | 2834000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3933
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0767   |
| loss/critic1                       | 12.4     |
| loss/critic2                       | 12.4     |
| timestep                           | 2835000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3923
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0593   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2836000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0617  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2837000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3982
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.00403 |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2838000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3858
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.047    |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2839000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3899
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.061   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2840000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3861
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2841000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3866
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.00725 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2842000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3877
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0188   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2843000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3883
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0108   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2844000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4027
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.141   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2845000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4025
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.139   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2846000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3909
----------------------------------------------------------------------------------
| alpha                              | 0.138    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.05    |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2847000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3972
----------------------------------------------------------------------------------
| alpha                              | 0.139    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.159    |
| loss/critic1                       | 12.9     |
| loss/critic2                       | 12.7     |
| timestep                           | 2848000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3954
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -683     |
| loss/alpha                         | 0.132    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2849000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3969
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0546  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2850000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3985
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0316  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2851000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4033
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0189  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2852000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3916
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.152    |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2853000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3879
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0692  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2854000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3926
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.132   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2855000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3908
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -683     |
| loss/alpha                         | 0.112    |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2856000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3951
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.00778  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2857000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3979
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0105  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2858000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3982
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0315  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2859000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4058
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.146    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2860000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3926
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0666   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2861000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3977
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.00796 |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2862000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3912
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0332  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.8     |
| timestep                           | 2863000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3961
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.111   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2864000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3970
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.109   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2865000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3879
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0242  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2866000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3854
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0468  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2867000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3887
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2868000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3884
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0125   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2869000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4009
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0529   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2870000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3905
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0026  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2871000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3865
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0476   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2872000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4005
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0752   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2873000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3936
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.083    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2874000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3866
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0393  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.4     |
| timestep                           | 2875000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3817
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0377   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.5     |
| timestep                           | 2876000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3854
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0557   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2877000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0657  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2878000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3929
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0953  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.4     |
| timestep                           | 2879000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3854
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.085   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2880000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3877
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0488  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2881000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3831
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0579   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2882000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3848
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0456   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2883000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4003
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.069    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2884000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3906
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0649   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2885000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3849
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.043   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2886000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3933
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0859  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2887000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3997
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0709  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2888000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3921
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.081    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2889000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3955
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.108    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2890000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3930
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0327   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 2891000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3894
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0826  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2892000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3934
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0934  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2893000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4006
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0909  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2894000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3896
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0182   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2895000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3834
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0773   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2896000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3907
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2897000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4003
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0504   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2898000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3926
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 5.34     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.00277 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2899000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3964
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.1     |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2900000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3826
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.68     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0145   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2901000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3872
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0213   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.2     |
| timestep                           | 2902000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4062
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -683     |
| loss/alpha                         | 0.00964  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2903000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4031
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0248   |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2904000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3930
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0725   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 2905000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0524   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2906000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3874
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.64     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0296   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2907000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3844
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.109   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2908000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3996
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0946  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2909000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3941
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.024   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2910000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3961
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0391  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2911000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3904
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0242   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2912000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3965
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -683     |
| loss/alpha                         | 0.11     |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2913000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3892
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.11     |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2914000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3926
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0473   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2915000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3984
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -683     |
| loss/alpha                         | -0.00384 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2916000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3810
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.03    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2917000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3859
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0643  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 2918000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3959
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2919000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3919
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0508  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2920000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3853
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0389  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2921000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3912
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.7     |
| timestep                           | 2922000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3948
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.00675 |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2923000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3980
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.1     |
| eval/normalized_episode_reward_std | 27.7     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0294   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2924000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3995
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0167   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2925000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3816
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.012   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2926000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3945
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.00204 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2927000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3883
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0187   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2928000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3864
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.0311  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2929000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3878
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0456   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2930000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4031
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -685     |
| loss/alpha                         | 0.0271   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2931000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3890
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0698   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2932000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3994
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0876   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2933000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3945
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.00307 |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13       |
| timestep                           | 2934000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4070
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.000591 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2935000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4016
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.0249  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2936000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3958
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.0225  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2937000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3967
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.0377  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2938000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3974
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.038   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2939000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3906
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.00368 |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2940000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3926
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.00714  |
| loss/critic1                       | 12.8     |
| loss/critic2                       | 12.8     |
| timestep                           | 2941000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3954
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.00875  |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.9     |
| timestep                           | 2942000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3880
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.00332  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2943000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3997
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0163   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.1     |
| timestep                           | 2944000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3933
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0315   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2945000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3939
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0398   |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2946000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3876
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 5.63     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0261   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2947000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3902
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0136  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2948000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3920
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2949000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3966
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0534  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2950000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3852
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0757  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2951000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4012
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.0345  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2952000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3914
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.00224  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2953000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4071
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0284   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2954000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4033
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.72     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0354   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2955000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3904
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -685     |
| loss/alpha                         | 0.0697   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2956000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3900
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -685     |
| loss/alpha                         | 0.085    |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2957000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3870
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -685     |
| loss/alpha                         | 0.0379   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2958000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3893
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0326   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2959000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3987
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0289   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2960000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4053
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.035    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2961000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3880
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.65     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0102   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2962000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3970
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.0261  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2963000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3892
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.039   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2964000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3973
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0858  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2965000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3882
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.039   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 2966000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3938
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.087   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2967000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3889
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.042   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2968000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3951
----------------------------------------------------------------------------------
| alpha                              | 0.142    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0432  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2969000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3989
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.0387  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2970000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3894
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -683     |
| loss/alpha                         | -0.00809 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2971000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4064
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.0254  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2972000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3971
----------------------------------------------------------------------------------
| alpha                              | 0.139    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -684     |
| loss/alpha                         | -0.00368 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2973000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4004
----------------------------------------------------------------------------------
| alpha                              | 0.139    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -684     |
| loss/alpha                         | 8.9e-05  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2974000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3923
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -684     |
| loss/alpha                         | 0.029    |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2975000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3886
----------------------------------------------------------------------------------
| alpha                              | 0.14     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0314   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2976000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3961
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -685     |
| loss/alpha                         | -0.0155  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2977000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3870
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.78     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.03     |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2978000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4000
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -685     |
| loss/alpha                         | -0.00283 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2979000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3978
----------------------------------------------------------------------------------
| alpha                              | 0.141    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -685     |
| loss/alpha                         | 0.0331   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2980000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3920
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -685     |
| loss/alpha                         | 0.0317   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2981000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3921
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 6.78     |
| loss/actor                         | -685     |
| loss/alpha                         | 0.0412   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2982000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3816
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0519   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2983000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3897
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -685     |
| loss/alpha                         | 0.0305   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2984000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3863
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0252   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2985000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3839
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0351   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2986000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3923
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -684     |
| loss/alpha                         | 0.0012   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2987000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3969
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -684     |
| loss/alpha                         | -0.00675 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2988000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.4030
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0355   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2989000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3984
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.0218   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2990000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3902
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -683     |
| loss/alpha                         | 0.00937  |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.5     |
| timestep                           | 2991000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3888
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0079   |
| loss/critic1                       | 12.7     |
| loss/critic2                       | 12.6     |
| timestep                           | 2992000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3951
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.0199   |
| loss/critic1                       | 13       |
| loss/critic2                       | 12.8     |
| timestep                           | 2993000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3968
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -682     |
| loss/alpha                         | 0.00997  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2994000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3917
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.0239  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.2     |
| timestep                           | 2995000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3980
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -682     |
| loss/alpha                         | -0.00747 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2996000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3961
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -681     |
| loss/alpha                         | -0.00283 |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13       |
| timestep                           | 2997000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3924
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0115   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2998000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3989
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0157   |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2999000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3906
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.8      |
| loss/actor                         | -681     |
| loss/alpha                         | 0.0183   |
| loss/critic1                       | 13       |
| loss/critic2                       | 13       |
| timestep                           | 3000000  |
----------------------------------------------------------------------------------
total time: 118911.94s
