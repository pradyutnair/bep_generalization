Training dynamics:
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.78254807 |
| loss/dynamics_train_loss   | -8.68      |
| timestep                   | 1          |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.64929503 |
| loss/dynamics_train_loss   | -27.2      |
| timestep                   | 2          |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.6255342 |
| loss/dynamics_train_loss   | -31.3     |
| timestep                   | 3         |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.60599685 |
| loss/dynamics_train_loss   | -33.3      |
| timestep                   | 4          |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.57804906 |
| loss/dynamics_train_loss   | -34.5      |
| timestep                   | 5          |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.55619836 |
| loss/dynamics_train_loss   | -35.4      |
| timestep                   | 6          |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.5314258 |
| loss/dynamics_train_loss   | -36.2     |
| timestep                   | 7         |
---------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.5184853 |
| loss/dynamics_train_loss   | -36.8     |
| timestep                   | 8         |
---------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.4987238 |
| loss/dynamics_train_loss   | -37.2     |
| timestep                   | 9         |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.48591262 |
| loss/dynamics_train_loss   | -37.7      |
| timestep                   | 10         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.48163995 |
| loss/dynamics_train_loss   | -38.1      |
| timestep                   | 11         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.47209892 |
| loss/dynamics_train_loss   | -38.4      |
| timestep                   | 12         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.4683157 |
| loss/dynamics_train_loss   | -38.7     |
| timestep                   | 13        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.45907697 |
| loss/dynamics_train_loss   | -39        |
| timestep                   | 14         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.4484585 |
| loss/dynamics_train_loss   | -39.2     |
| timestep                   | 15        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.43688983 |
| loss/dynamics_train_loss   | -39.5      |
| timestep                   | 16         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.43482223 |
| loss/dynamics_train_loss   | -39.7      |
| timestep                   | 17         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.41274348 |
| loss/dynamics_train_loss   | -39.9      |
| timestep                   | 18         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.4073897 |
| loss/dynamics_train_loss   | -40.1     |
| timestep                   | 19        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.39496845 |
| loss/dynamics_train_loss   | -40.3      |
| timestep                   | 20         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.39774355 |
| loss/dynamics_train_loss   | -40.3      |
| timestep                   | 21         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.37691984 |
| loss/dynamics_train_loss   | -40.6      |
| timestep                   | 22         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.37157172 |
| loss/dynamics_train_loss   | -40.7      |
| timestep                   | 23         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.36817333 |
| loss/dynamics_train_loss   | -40.9      |
| timestep                   | 24         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.35895967 |
| loss/dynamics_train_loss   | -41.1      |
| timestep                   | 25         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.35483822 |
| loss/dynamics_train_loss   | -41.2      |
| timestep                   | 26         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.3455003 |
| loss/dynamics_train_loss   | -41.3     |
| timestep                   | 27        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.34386423 |
| loss/dynamics_train_loss   | -41.4      |
| timestep                   | 28         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.33628985 |
| loss/dynamics_train_loss   | -41.4      |
| timestep                   | 29         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.33407658 |
| loss/dynamics_train_loss   | -41.6      |
| timestep                   | 30         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.32224932 |
| loss/dynamics_train_loss   | -41.7      |
| timestep                   | 31         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.31967533 |
| loss/dynamics_train_loss   | -41.8      |
| timestep                   | 32         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.3128371 |
| loss/dynamics_train_loss   | -41.8     |
| timestep                   | 33        |
---------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.3156568 |
| loss/dynamics_train_loss   | -42       |
| timestep                   | 34        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.30077213 |
| loss/dynamics_train_loss   | -42.1      |
| timestep                   | 35         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.28750262 |
| loss/dynamics_train_loss   | -42.1      |
| timestep                   | 36         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.29135257 |
| loss/dynamics_train_loss   | -42.3      |
| timestep                   | 37         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.2842109 |
| loss/dynamics_train_loss   | -42.3     |
| timestep                   | 38        |
---------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.2753592 |
| loss/dynamics_train_loss   | -42.4     |
| timestep                   | 39        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.27435356 |
| loss/dynamics_train_loss   | -42.4      |
| timestep                   | 40         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.2711202 |
| loss/dynamics_train_loss   | -42.5     |
| timestep                   | 41        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.26395488 |
| loss/dynamics_train_loss   | -42.6      |
| timestep                   | 42         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.26311138 |
| loss/dynamics_train_loss   | -42.7      |
| timestep                   | 43         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.24962668 |
| loss/dynamics_train_loss   | -42.8      |
| timestep                   | 44         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.25221664 |
| loss/dynamics_train_loss   | -42.8      |
| timestep                   | 45         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.24725835 |
| loss/dynamics_train_loss   | -42.8      |
| timestep                   | 46         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.24005425 |
| loss/dynamics_train_loss   | -43        |
| timestep                   | 47         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.23036988 |
| loss/dynamics_train_loss   | -43        |
| timestep                   | 48         |
----------------------------------------------------------------------------
--------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.23438  |
| loss/dynamics_train_loss   | -43      |
| timestep                   | 49       |
--------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.22593288 |
| loss/dynamics_train_loss   | -43.1      |
| timestep                   | 50         |
----------------------------------------------------------------------------
--------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.231101 |
| loss/dynamics_train_loss   | -43.2    |
| timestep                   | 51       |
--------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.22286828 |
| loss/dynamics_train_loss   | -43.2      |
| timestep                   | 52         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.21889403 |
| loss/dynamics_train_loss   | -43.2      |
| timestep                   | 53         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.22397299 |
| loss/dynamics_train_loss   | -43.4      |
| timestep                   | 54         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.21648988 |
| loss/dynamics_train_loss   | -43.3      |
| timestep                   | 55         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.21094632 |
| loss/dynamics_train_loss   | -43.4      |
| timestep                   | 56         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.21065679 |
| loss/dynamics_train_loss   | -43.4      |
| timestep                   | 57         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.2183834 |
| loss/dynamics_train_loss   | -43.5     |
| timestep                   | 58        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.21205068 |
| loss/dynamics_train_loss   | -43.5      |
| timestep                   | 59         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.20827165 |
| loss/dynamics_train_loss   | -43.6      |
| timestep                   | 60         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.20103213 |
| loss/dynamics_train_loss   | -43.6      |
| timestep                   | 61         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.2051867 |
| loss/dynamics_train_loss   | -43.7     |
| timestep                   | 62        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.20087495 |
| loss/dynamics_train_loss   | -43.7      |
| timestep                   | 63         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.20637953 |
| loss/dynamics_train_loss   | -43.8      |
| timestep                   | 64         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.19866723 |
| loss/dynamics_train_loss   | -43.9      |
| timestep                   | 65         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.19781116 |
| loss/dynamics_train_loss   | -43.8      |
| timestep                   | 66         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.20131573 |
| loss/dynamics_train_loss   | -43.9      |
| timestep                   | 67         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.2009128 |
| loss/dynamics_train_loss   | -43.9     |
| timestep                   | 68        |
---------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1983726 |
| loss/dynamics_train_loss   | -43.9     |
| timestep                   | 69        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.19124101 |
| loss/dynamics_train_loss   | -44.1      |
| timestep                   | 70         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.19325973 |
| loss/dynamics_train_loss   | -44.1      |
| timestep                   | 71         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.19219127 |
| loss/dynamics_train_loss   | -43.9      |
| timestep                   | 72         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.19743635 |
| loss/dynamics_train_loss   | -44.1      |
| timestep                   | 73         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18549724 |
| loss/dynamics_train_loss   | -44.3      |
| timestep                   | 74         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18959323 |
| loss/dynamics_train_loss   | -44.2      |
| timestep                   | 75         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.19080234 |
| loss/dynamics_train_loss   | -44.2      |
| timestep                   | 76         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18427935 |
| loss/dynamics_train_loss   | -44.4      |
| timestep                   | 77         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18329132 |
| loss/dynamics_train_loss   | -44.4      |
| timestep                   | 78         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18320894 |
| loss/dynamics_train_loss   | -44.3      |
| timestep                   | 79         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18301988 |
| loss/dynamics_train_loss   | -44.4      |
| timestep                   | 80         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18572459 |
| loss/dynamics_train_loss   | -44.4      |
| timestep                   | 81         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1879413 |
| loss/dynamics_train_loss   | -44.5     |
| timestep                   | 82        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17838016 |
| loss/dynamics_train_loss   | -44.5      |
| timestep                   | 83         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17966376 |
| loss/dynamics_train_loss   | -44.5      |
| timestep                   | 84         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17787455 |
| loss/dynamics_train_loss   | -44.6      |
| timestep                   | 85         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17954935 |
| loss/dynamics_train_loss   | -44.5      |
| timestep                   | 86         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17771058 |
| loss/dynamics_train_loss   | -44.5      |
| timestep                   | 87         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17674783 |
| loss/dynamics_train_loss   | -44.7      |
| timestep                   | 88         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17703542 |
| loss/dynamics_train_loss   | -44.7      |
| timestep                   | 89         |
----------------------------------------------------------------------------
--------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.178407 |
| loss/dynamics_train_loss   | -44.7    |
| timestep                   | 90       |
--------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17567873 |
| loss/dynamics_train_loss   | -44.7      |
| timestep                   | 91         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17383413 |
| loss/dynamics_train_loss   | -44.9      |
| timestep                   | 92         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1729302 |
| loss/dynamics_train_loss   | -44.9     |
| timestep                   | 93        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17535876 |
| loss/dynamics_train_loss   | -44.8      |
| timestep                   | 94         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17695618 |
| loss/dynamics_train_loss   | -44.8      |
| timestep                   | 95         |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1712715 |
| loss/dynamics_train_loss   | -45       |
| timestep                   | 96        |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16955706 |
| loss/dynamics_train_loss   | -45        |
| timestep                   | 97         |
----------------------------------------------------------------------------
--------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.169921 |
| loss/dynamics_train_loss   | -45      |
| timestep                   | 98       |
--------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17413071 |
| loss/dynamics_train_loss   | -45        |
| timestep                   | 99         |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17028174 |
| loss/dynamics_train_loss   | -45.1      |
| timestep                   | 100        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16895476 |
| loss/dynamics_train_loss   | -45.1      |
| timestep                   | 101        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16964972 |
| loss/dynamics_train_loss   | -45.2      |
| timestep                   | 102        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16930346 |
| loss/dynamics_train_loss   | -45.2      |
| timestep                   | 103        |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1701889 |
| loss/dynamics_train_loss   | -45.2     |
| timestep                   | 104       |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16742869 |
| loss/dynamics_train_loss   | -45.2      |
| timestep                   | 105        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16884609 |
| loss/dynamics_train_loss   | -45.2      |
| timestep                   | 106        |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1645012 |
| loss/dynamics_train_loss   | -45.2     |
| timestep                   | 107       |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.18297112 |
| loss/dynamics_train_loss   | -45.3      |
| timestep                   | 108        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16315448 |
| loss/dynamics_train_loss   | -45.3      |
| timestep                   | 109        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16475475 |
| loss/dynamics_train_loss   | -45.4      |
| timestep                   | 110        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16373466 |
| loss/dynamics_train_loss   | -45.3      |
| timestep                   | 111        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16578212 |
| loss/dynamics_train_loss   | -45.5      |
| timestep                   | 112        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16538611 |
| loss/dynamics_train_loss   | -45.5      |
| timestep                   | 113        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16838273 |
| loss/dynamics_train_loss   | -45.4      |
| timestep                   | 114        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16138922 |
| loss/dynamics_train_loss   | -45.5      |
| timestep                   | 115        |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1598651 |
| loss/dynamics_train_loss   | -45.5     |
| timestep                   | 116       |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16233553 |
| loss/dynamics_train_loss   | -45.5      |
| timestep                   | 117        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.15914251 |
| loss/dynamics_train_loss   | -45.4      |
| timestep                   | 118        |
----------------------------------------------------------------------------
---------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.1660864 |
| loss/dynamics_train_loss   | -45.6     |
| timestep                   | 119       |
---------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17093812 |
| loss/dynamics_train_loss   | -45.5      |
| timestep                   | 120        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.17787914 |
| loss/dynamics_train_loss   | -45.3      |
| timestep                   | 121        |
----------------------------------------------------------------------------
----------------------------------------------------------------------------
| loss/dynamics_holdout_loss | 0.16421513 |
| loss/dynamics_train_loss   | -45.6      |
| timestep                   | 122        |
----------------------------------------------------------------------------
elites:[0, 5, 6, 1, 3] , holdout loss: 0.15538302063941956
num rollout transitions: 250000, reward mean: 3.6505
----------------------------------------------------------------------------------
| alpha                              | 0.951    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.25     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -23.6    |
| loss/alpha                         | -0.502   |
| loss/critic1                       | 2.91     |
| loss/critic2                       | 3.07     |
| timestep                           | 1000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.6923
----------------------------------------------------------------------------------
| alpha                              | 0.861    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.24     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -48.9    |
| loss/alpha                         | -1.5     |
| loss/critic1                       | 4.02     |
| loss/critic2                       | 4.3      |
| timestep                           | 2000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.7205
----------------------------------------------------------------------------------
| alpha                              | 0.779    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.24     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -69.5    |
| loss/alpha                         | -2.44    |
| loss/critic1                       | 7.51     |
| loss/critic2                       | 7.95     |
| timestep                           | 3000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.7882
----------------------------------------------------------------------------------
| alpha                              | 0.706    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.23     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -85.6    |
| loss/alpha                         | -3.28    |
| loss/critic1                       | 11       |
| loss/critic2                       | 11.4     |
| timestep                           | 4000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.8527
----------------------------------------------------------------------------------
| alpha                              | 0.642    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.23     |
| eval/normalized_episode_reward_std | 2.26     |
| loss/actor                         | -98.7    |
| loss/alpha                         | -3.96    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 5000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.8842
----------------------------------------------------------------------------------
| alpha                              | 0.584    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 1.07     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -110     |
| loss/alpha                         | -4.39    |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 6000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.8947
----------------------------------------------------------------------------------
| alpha                              | 0.533    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 0.697    |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -120     |
| loss/alpha                         | -4.58    |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.9     |
| timestep                           | 7000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.8874
----------------------------------------------------------------------------------
| alpha                              | 0.487    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -0.441   |
| eval/normalized_episode_reward_std | 4.34     |
| loss/actor                         | -129     |
| loss/alpha                         | -4.67    |
| loss/critic1                       | 23.9     |
| loss/critic2                       | 23.8     |
| timestep                           | 8000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9152
----------------------------------------------------------------------------------
| alpha                              | 0.446    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -4.77    |
| eval/normalized_episode_reward_std | 4.08     |
| loss/actor                         | -137     |
| loss/alpha                         | -4.65    |
| loss/critic1                       | 27.1     |
| loss/critic2                       | 27.1     |
| timestep                           | 9000     |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9199
----------------------------------------------------------------------------------
| alpha                              | 0.409    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -3.4     |
| eval/normalized_episode_reward_std | 6.52     |
| loss/actor                         | -144     |
| loss/alpha                         | -4.68    |
| loss/critic1                       | 31.9     |
| loss/critic2                       | 32.1     |
| timestep                           | 10000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9374
----------------------------------------------------------------------------------
| alpha                              | 0.374    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -2.17    |
| eval/normalized_episode_reward_std | 8.72     |
| loss/actor                         | -149     |
| loss/alpha                         | -4.66    |
| loss/critic1                       | 33.7     |
| loss/critic2                       | 34       |
| timestep                           | 11000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9777
----------------------------------------------------------------------------------
| alpha                              | 0.342    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -3.37    |
| eval/normalized_episode_reward_std | 6.65     |
| loss/actor                         | -154     |
| loss/alpha                         | -4.59    |
| loss/critic1                       | 36.1     |
| loss/critic2                       | 36.1     |
| timestep                           | 12000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9723
----------------------------------------------------------------------------------
| alpha                              | 0.313    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | -5.4     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -157     |
| loss/alpha                         | -4.35    |
| loss/critic1                       | 38.4     |
| loss/critic2                       | 38.1     |
| timestep                           | 13000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9906
----------------------------------------------------------------------------------
| alpha                              | 0.287    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 2.17     |
| eval/normalized_episode_reward_std | 7.66     |
| loss/actor                         | -161     |
| loss/alpha                         | -3.96    |
| loss/critic1                       | 41.6     |
| loss/critic2                       | 40.9     |
| timestep                           | 14000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9852
----------------------------------------------------------------------------------
| alpha                              | 0.264    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 1.71     |
| eval/normalized_episode_reward_std | 6.88     |
| loss/actor                         | -164     |
| loss/alpha                         | -3.52    |
| loss/critic1                       | 45.8     |
| loss/critic2                       | 44.7     |
| timestep                           | 15000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9992
----------------------------------------------------------------------------------
| alpha                              | 0.245    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 1.05     |
| eval/normalized_episode_reward_std | 6.02     |
| loss/actor                         | -168     |
| loss/alpha                         | -2.66    |
| loss/critic1                       | 52.4     |
| loss/critic2                       | 51       |
| timestep                           | 16000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9938
----------------------------------------------------------------------------------
| alpha                              | 0.229    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 0.497    |
| eval/normalized_episode_reward_std | 5.89     |
| loss/actor                         | -171     |
| loss/alpha                         | -1.73    |
| loss/critic1                       | 56.9     |
| loss/critic2                       | 55.2     |
| timestep                           | 17000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9980
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 4.25     |
| eval/normalized_episode_reward_std | 6.29     |
| loss/actor                         | -174     |
| loss/alpha                         | -1.11    |
| loss/critic1                       | 69.6     |
| loss/critic2                       | 67.7     |
| timestep                           | 18000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 3.9934
----------------------------------------------------------------------------------
| alpha                              | 0.207    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 4.96     |
| eval/normalized_episode_reward_std | 8.21     |
| loss/actor                         | -178     |
| loss/alpha                         | -0.704   |
| loss/critic1                       | 76.4     |
| loss/critic2                       | 74.2     |
| timestep                           | 19000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0312
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 11.3     |
| eval/normalized_episode_reward_std | 9.19     |
| loss/actor                         | -180     |
| loss/alpha                         | -0.339   |
| loss/critic1                       | 80.1     |
| loss/critic2                       | 77.6     |
| timestep                           | 20000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0376
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 30.6     |
| eval/normalized_episode_reward_std | 11.2     |
| loss/actor                         | -183     |
| loss/alpha                         | -0.239   |
| loss/critic1                       | 78.6     |
| loss/critic2                       | 76.4     |
| timestep                           | 21000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0829
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 13.9     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -186     |
| loss/alpha                         | 0.0395   |
| loss/critic1                       | 77.1     |
| loss/critic2                       | 75.2     |
| timestep                           | 22000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0846
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 13       |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -189     |
| loss/alpha                         | 0.242    |
| loss/critic1                       | 72.3     |
| loss/critic2                       | 70.9     |
| timestep                           | 23000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0787
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 36.6     |
| eval/normalized_episode_reward_std | 9.98     |
| loss/actor                         | -192     |
| loss/alpha                         | 0.196    |
| loss/critic1                       | 72.9     |
| loss/critic2                       | 71.1     |
| timestep                           | 24000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0619
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 10.1     |
| eval/normalized_episode_reward_std | 8.62     |
| loss/actor                         | -195     |
| loss/alpha                         | 0.134    |
| loss/critic1                       | 74       |
| loss/critic2                       | 72.1     |
| timestep                           | 25000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0779
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 20.7     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -198     |
| loss/alpha                         | 0.142    |
| loss/critic1                       | 80.6     |
| loss/critic2                       | 78.6     |
| timestep                           | 26000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0476
----------------------------------------------------------------------------------
| alpha                              | 0.225    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 41.1     |
| eval/normalized_episode_reward_std | 8.6      |
| loss/actor                         | -201     |
| loss/alpha                         | 0.213    |
| loss/critic1                       | 82.7     |
| loss/critic2                       | 80.6     |
| timestep                           | 27000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0395
----------------------------------------------------------------------------------
| alpha                              | 0.23     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 30.9     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -204     |
| loss/alpha                         | -0.0009  |
| loss/critic1                       | 78.5     |
| loss/critic2                       | 76.3     |
| timestep                           | 28000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0793
----------------------------------------------------------------------------------
| alpha                              | 0.234    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 32.9     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -207     |
| loss/alpha                         | 0.136    |
| loss/critic1                       | 79.8     |
| loss/critic2                       | 77.8     |
| timestep                           | 29000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.0950
----------------------------------------------------------------------------------
| alpha                              | 0.239    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 42       |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -209     |
| loss/alpha                         | 0.0462   |
| loss/critic1                       | 84.9     |
| loss/critic2                       | 82.3     |
| timestep                           | 30000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1180
----------------------------------------------------------------------------------
| alpha                              | 0.244    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 21.9     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -212     |
| loss/alpha                         | 0.11     |
| loss/critic1                       | 77.1     |
| loss/critic2                       | 75.1     |
| timestep                           | 31000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1199
----------------------------------------------------------------------------------
| alpha                              | 0.251    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 27       |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -215     |
| loss/alpha                         | 0.14     |
| loss/critic1                       | 80.8     |
| loss/critic2                       | 78.8     |
| timestep                           | 32000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1211
----------------------------------------------------------------------------------
| alpha                              | 0.256    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 19       |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -218     |
| loss/alpha                         | 0.0263   |
| loss/critic1                       | 79.8     |
| loss/critic2                       | 77.8     |
| timestep                           | 33000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1230
----------------------------------------------------------------------------------
| alpha                              | 0.258    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 17.2     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -220     |
| loss/alpha                         | 0.0918   |
| loss/critic1                       | 78.3     |
| loss/critic2                       | 76.5     |
| timestep                           | 34000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1261
----------------------------------------------------------------------------------
| alpha                              | 0.271    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 20.4     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -223     |
| loss/alpha                         | 0.27     |
| loss/critic1                       | 79.3     |
| loss/critic2                       | 77.2     |
| timestep                           | 35000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1220
----------------------------------------------------------------------------------
| alpha                              | 0.283    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 17.4     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -225     |
| loss/alpha                         | 0.121    |
| loss/critic1                       | 75.1     |
| loss/critic2                       | 73.3     |
| timestep                           | 36000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1165
----------------------------------------------------------------------------------
| alpha                              | 0.289    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 45.4     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -227     |
| loss/alpha                         | 0.0263   |
| loss/critic1                       | 77.2     |
| loss/critic2                       | 75.3     |
| timestep                           | 37000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1413
----------------------------------------------------------------------------------
| alpha                              | 0.288    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.3     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -228     |
| loss/alpha                         | -0.0151  |
| loss/critic1                       | 78.9     |
| loss/critic2                       | 77       |
| timestep                           | 38000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1378
----------------------------------------------------------------------------------
| alpha                              | 0.289    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 42.3     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -230     |
| loss/alpha                         | 0.00908  |
| loss/critic1                       | 73.3     |
| loss/critic2                       | 71.6     |
| timestep                           | 39000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1568
----------------------------------------------------------------------------------
| alpha                              | 0.289    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 39.8     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -232     |
| loss/alpha                         | 0.0124   |
| loss/critic1                       | 61.8     |
| loss/critic2                       | 60.1     |
| timestep                           | 40000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1588
----------------------------------------------------------------------------------
| alpha                              | 0.29     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 39.5     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -235     |
| loss/alpha                         | -0.00683 |
| loss/critic1                       | 60.8     |
| loss/critic2                       | 59.4     |
| timestep                           | 41000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1543
----------------------------------------------------------------------------------
| alpha                              | 0.288    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 30.7     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -238     |
| loss/alpha                         | -0.021   |
| loss/critic1                       | 51.6     |
| loss/critic2                       | 50       |
| timestep                           | 42000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1582
----------------------------------------------------------------------------------
| alpha                              | 0.289    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.4     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -241     |
| loss/alpha                         | 0.0397   |
| loss/critic1                       | 55.5     |
| loss/critic2                       | 54.5     |
| timestep                           | 43000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1461
----------------------------------------------------------------------------------
| alpha                              | 0.293    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.7     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -244     |
| loss/alpha                         | 0.0589   |
| loss/critic1                       | 56.9     |
| loss/critic2                       | 55.7     |
| timestep                           | 44000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1324
----------------------------------------------------------------------------------
| alpha                              | 0.293    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52       |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -247     |
| loss/alpha                         | -0.049   |
| loss/critic1                       | 59.1     |
| loss/critic2                       | 58       |
| timestep                           | 45000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1558
----------------------------------------------------------------------------------
| alpha                              | 0.292    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 33       |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -249     |
| loss/alpha                         | -0.00645 |
| loss/critic1                       | 57.3     |
| loss/critic2                       | 56.4     |
| timestep                           | 46000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1553
----------------------------------------------------------------------------------
| alpha                              | 0.293    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.4     |
| eval/normalized_episode_reward_std | 5.16     |
| loss/actor                         | -252     |
| loss/alpha                         | 0.0561   |
| loss/critic1                       | 59.5     |
| loss/critic2                       | 58.6     |
| timestep                           | 47000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1631
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.9     |
| eval/normalized_episode_reward_std | 5.52     |
| loss/actor                         | -255     |
| loss/alpha                         | 0.0546   |
| loss/critic1                       | 57.3     |
| loss/critic2                       | 56.1     |
| timestep                           | 48000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1206
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 38.4     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -258     |
| loss/alpha                         | -0.0458  |
| loss/critic1                       | 51.1     |
| loss/critic2                       | 50.4     |
| timestep                           | 49000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1586
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.9     |
| eval/normalized_episode_reward_std | 9.21     |
| loss/actor                         | -261     |
| loss/alpha                         | -0.00202 |
| loss/critic1                       | 58.2     |
| loss/critic2                       | 57.2     |
| timestep                           | 50000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1546
----------------------------------------------------------------------------------
| alpha                              | 0.296    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.6     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -264     |
| loss/alpha                         | 0.0113   |
| loss/critic1                       | 53.9     |
| loss/critic2                       | 53.1     |
| timestep                           | 51000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1547
----------------------------------------------------------------------------------
| alpha                              | 0.297    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.5     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -266     |
| loss/alpha                         | -0.00569 |
| loss/critic1                       | 53.3     |
| loss/critic2                       | 52.8     |
| timestep                           | 52000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1382
----------------------------------------------------------------------------------
| alpha                              | 0.297    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.7     |
| eval/normalized_episode_reward_std | 8.24     |
| loss/actor                         | -269     |
| loss/alpha                         | 0.00858  |
| loss/critic1                       | 50       |
| loss/critic2                       | 49.6     |
| timestep                           | 53000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1361
----------------------------------------------------------------------------------
| alpha                              | 0.298    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 40.4     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -272     |
| loss/alpha                         | -0.0232  |
| loss/critic1                       | 48.9     |
| loss/critic2                       | 48.3     |
| timestep                           | 54000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1726
----------------------------------------------------------------------------------
| alpha                              | 0.293    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.6     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -276     |
| loss/alpha                         | -0.0715  |
| loss/critic1                       | 43.2     |
| loss/critic2                       | 42.6     |
| timestep                           | 55000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1553
----------------------------------------------------------------------------------
| alpha                              | 0.287    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.9     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -279     |
| loss/alpha                         | -0.0519  |
| loss/critic1                       | 46.9     |
| loss/critic2                       | 46       |
| timestep                           | 56000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1650
----------------------------------------------------------------------------------
| alpha                              | 0.286    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47       |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -282     |
| loss/alpha                         | 0.0171   |
| loss/critic1                       | 47.3     |
| loss/critic2                       | 46.9     |
| timestep                           | 57000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1565
----------------------------------------------------------------------------------
| alpha                              | 0.287    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.3     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -286     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 50.9     |
| loss/critic2                       | 50       |
| timestep                           | 58000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1371
----------------------------------------------------------------------------------
| alpha                              | 0.291    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.6     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -289     |
| loss/alpha                         | 0.0325   |
| loss/critic1                       | 48.6     |
| loss/critic2                       | 48       |
| timestep                           | 59000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1820
----------------------------------------------------------------------------------
| alpha                              | 0.291    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.5     |
| eval/normalized_episode_reward_std | 2.59     |
| loss/actor                         | -292     |
| loss/alpha                         | -0.0326  |
| loss/critic1                       | 48.3     |
| loss/critic2                       | 47.3     |
| timestep                           | 60000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1643
----------------------------------------------------------------------------------
| alpha                              | 0.29     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.9     |
| eval/normalized_episode_reward_std | 8.37     |
| loss/actor                         | -295     |
| loss/alpha                         | -0.0214  |
| loss/critic1                       | 47.9     |
| loss/critic2                       | 47.4     |
| timestep                           | 61000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1702
----------------------------------------------------------------------------------
| alpha                              | 0.286    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.4     |
| eval/normalized_episode_reward_std | 4.49     |
| loss/actor                         | -298     |
| loss/alpha                         | -0.0208  |
| loss/critic1                       | 43.7     |
| loss/critic2                       | 43.1     |
| timestep                           | 62000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1672
----------------------------------------------------------------------------------
| alpha                              | 0.282    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.6     |
| eval/normalized_episode_reward_std | 7.19     |
| loss/actor                         | -302     |
| loss/alpha                         | -0.121   |
| loss/critic1                       | 45.9     |
| loss/critic2                       | 45.2     |
| timestep                           | 63000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1783
----------------------------------------------------------------------------------
| alpha                              | 0.278    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.9     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -305     |
| loss/alpha                         | 0.0223   |
| loss/critic1                       | 44.4     |
| loss/critic2                       | 43.8     |
| timestep                           | 64000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1740
----------------------------------------------------------------------------------
| alpha                              | 0.281    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.2     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -308     |
| loss/alpha                         | 0.0313   |
| loss/critic1                       | 44.4     |
| loss/critic2                       | 43.9     |
| timestep                           | 65000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1841
----------------------------------------------------------------------------------
| alpha                              | 0.281    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 36.7     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -312     |
| loss/alpha                         | -0.0239  |
| loss/critic1                       | 44.4     |
| loss/critic2                       | 44       |
| timestep                           | 66000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1649
----------------------------------------------------------------------------------
| alpha                              | 0.28     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.5     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -315     |
| loss/alpha                         | 0.0416   |
| loss/critic1                       | 46.1     |
| loss/critic2                       | 45.8     |
| timestep                           | 67000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1636
----------------------------------------------------------------------------------
| alpha                              | 0.284    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 34.1     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -318     |
| loss/alpha                         | 0.0534   |
| loss/critic1                       | 42.6     |
| loss/critic2                       | 42.1     |
| timestep                           | 68000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1761
----------------------------------------------------------------------------------
| alpha                              | 0.286    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.4     |
| eval/normalized_episode_reward_std | 5.87     |
| loss/actor                         | -321     |
| loss/alpha                         | -0.00194 |
| loss/critic1                       | 48.5     |
| loss/critic2                       | 48.5     |
| timestep                           | 69000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1626
----------------------------------------------------------------------------------
| alpha                              | 0.287    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.9     |
| eval/normalized_episode_reward_std | 4.66     |
| loss/actor                         | -324     |
| loss/alpha                         | 0.00591  |
| loss/critic1                       | 47.7     |
| loss/critic2                       | 47.1     |
| timestep                           | 70000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1832
----------------------------------------------------------------------------------
| alpha                              | 0.284    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.4     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -326     |
| loss/alpha                         | -0.0758  |
| loss/critic1                       | 46.7     |
| loss/critic2                       | 46.3     |
| timestep                           | 71000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1677
----------------------------------------------------------------------------------
| alpha                              | 0.278    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.1     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -329     |
| loss/alpha                         | -0.0734  |
| loss/critic1                       | 45.1     |
| loss/critic2                       | 44.5     |
| timestep                           | 72000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1881
----------------------------------------------------------------------------------
| alpha                              | 0.273    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.2     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -332     |
| loss/alpha                         | -0.0495  |
| loss/critic1                       | 42.9     |
| loss/critic2                       | 42.2     |
| timestep                           | 73000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1937
----------------------------------------------------------------------------------
| alpha                              | 0.272    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 46.7     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -335     |
| loss/alpha                         | -0.0567  |
| loss/critic1                       | 37.2     |
| loss/critic2                       | 36.5     |
| timestep                           | 74000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1983
----------------------------------------------------------------------------------
| alpha                              | 0.269    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 45.6     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -338     |
| loss/alpha                         | -0.0056  |
| loss/critic1                       | 39.9     |
| loss/critic2                       | 39.5     |
| timestep                           | 75000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1877
----------------------------------------------------------------------------------
| alpha                              | 0.272    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 41.9     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -341     |
| loss/alpha                         | 0.0926   |
| loss/critic1                       | 39.8     |
| loss/critic2                       | 39.5     |
| timestep                           | 76000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1937
----------------------------------------------------------------------------------
| alpha                              | 0.274    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.1     |
| eval/normalized_episode_reward_std | 7.62     |
| loss/actor                         | -344     |
| loss/alpha                         | -0.0162  |
| loss/critic1                       | 41.5     |
| loss/critic2                       | 41.2     |
| timestep                           | 77000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2130
----------------------------------------------------------------------------------
| alpha                              | 0.274    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.1     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -346     |
| loss/alpha                         | 0.00579  |
| loss/critic1                       | 41.2     |
| loss/critic2                       | 40.9     |
| timestep                           | 78000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2129
----------------------------------------------------------------------------------
| alpha                              | 0.275    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.6     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -349     |
| loss/alpha                         | 0.0264   |
| loss/critic1                       | 39.8     |
| loss/critic2                       | 39.4     |
| timestep                           | 79000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1978
----------------------------------------------------------------------------------
| alpha                              | 0.275    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.1     |
| eval/normalized_episode_reward_std | 8.41     |
| loss/actor                         | -352     |
| loss/alpha                         | -0.0305  |
| loss/critic1                       | 37.8     |
| loss/critic2                       | 37.5     |
| timestep                           | 80000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1888
----------------------------------------------------------------------------------
| alpha                              | 0.27     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.1     |
| eval/normalized_episode_reward_std | 7.42     |
| loss/actor                         | -355     |
| loss/alpha                         | -0.106   |
| loss/critic1                       | 39.7     |
| loss/critic2                       | 39.1     |
| timestep                           | 81000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2051
----------------------------------------------------------------------------------
| alpha                              | 0.265    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.1     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -359     |
| loss/alpha                         | -0.0254  |
| loss/critic1                       | 36.4     |
| loss/critic2                       | 36.4     |
| timestep                           | 82000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2042
----------------------------------------------------------------------------------
| alpha                              | 0.266    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 38.5     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -362     |
| loss/alpha                         | -0.0029  |
| loss/critic1                       | 36.6     |
| loss/critic2                       | 36.3     |
| timestep                           | 83000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2141
----------------------------------------------------------------------------------
| alpha                              | 0.264    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 2.61     |
| loss/actor                         | -364     |
| loss/alpha                         | -0.00709 |
| loss/critic1                       | 41.4     |
| loss/critic2                       | 41.1     |
| timestep                           | 84000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1968
----------------------------------------------------------------------------------
| alpha                              | 0.264    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.9     |
| eval/normalized_episode_reward_std | 9.61     |
| loss/actor                         | -367     |
| loss/alpha                         | -0.00222 |
| loss/critic1                       | 41.4     |
| loss/critic2                       | 41.1     |
| timestep                           | 85000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2074
----------------------------------------------------------------------------------
| alpha                              | 0.265    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.9     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -370     |
| loss/alpha                         | 0.000946 |
| loss/critic1                       | 40.7     |
| loss/critic2                       | 40.3     |
| timestep                           | 86000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2079
----------------------------------------------------------------------------------
| alpha                              | 0.264    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.2     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -372     |
| loss/alpha                         | 0.00917  |
| loss/critic1                       | 39.7     |
| loss/critic2                       | 39.8     |
| timestep                           | 87000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2066
----------------------------------------------------------------------------------
| alpha                              | 0.265    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.5     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -374     |
| loss/alpha                         | 0.00582  |
| loss/critic1                       | 37.1     |
| loss/critic2                       | 36.7     |
| timestep                           | 88000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2156
----------------------------------------------------------------------------------
| alpha                              | 0.264    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 11       |
| loss/actor                         | -377     |
| loss/alpha                         | -0.0452  |
| loss/critic1                       | 32.5     |
| loss/critic2                       | 32.3     |
| timestep                           | 89000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2226
----------------------------------------------------------------------------------
| alpha                              | 0.263    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58       |
| eval/normalized_episode_reward_std | 7.95     |
| loss/actor                         | -379     |
| loss/alpha                         | 0.0589   |
| loss/critic1                       | 36.2     |
| loss/critic2                       | 35.9     |
| timestep                           | 90000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1959
----------------------------------------------------------------------------------
| alpha                              | 0.265    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.8     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -381     |
| loss/alpha                         | -0.0167  |
| loss/critic1                       | 34.7     |
| loss/critic2                       | 34.5     |
| timestep                           | 91000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2107
----------------------------------------------------------------------------------
| alpha                              | 0.262    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.7     |
| eval/normalized_episode_reward_std | 4.37     |
| loss/actor                         | -384     |
| loss/alpha                         | -0.0674  |
| loss/critic1                       | 35.6     |
| loss/critic2                       | 35.2     |
| timestep                           | 92000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1873
----------------------------------------------------------------------------------
| alpha                              | 0.26     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.5     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -386     |
| loss/alpha                         | 0.00323  |
| loss/critic1                       | 33.4     |
| loss/critic2                       | 33       |
| timestep                           | 93000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2142
----------------------------------------------------------------------------------
| alpha                              | 0.261    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.3     |
| eval/normalized_episode_reward_std | 9.45     |
| loss/actor                         | -388     |
| loss/alpha                         | 0.0145   |
| loss/critic1                       | 35.6     |
| loss/critic2                       | 35.6     |
| timestep                           | 94000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2005
----------------------------------------------------------------------------------
| alpha                              | 0.261    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.3     |
| eval/normalized_episode_reward_std | 6.9      |
| loss/actor                         | -391     |
| loss/alpha                         | -0.0668  |
| loss/critic1                       | 38.2     |
| loss/critic2                       | 37.7     |
| timestep                           | 95000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2031
----------------------------------------------------------------------------------
| alpha                              | 0.257    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.1     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -393     |
| loss/alpha                         | 0.0166   |
| loss/critic1                       | 39       |
| loss/critic2                       | 38.8     |
| timestep                           | 96000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1998
----------------------------------------------------------------------------------
| alpha                              | 0.258    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.6     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -395     |
| loss/alpha                         | -0.0553  |
| loss/critic1                       | 39.4     |
| loss/critic2                       | 39.1     |
| timestep                           | 97000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2232
----------------------------------------------------------------------------------
| alpha                              | 0.256    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.7     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -397     |
| loss/alpha                         | 0.0225   |
| loss/critic1                       | 38.3     |
| loss/critic2                       | 38.2     |
| timestep                           | 98000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2148
----------------------------------------------------------------------------------
| alpha                              | 0.254    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.2     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -399     |
| loss/alpha                         | -0.0525  |
| loss/critic1                       | 36       |
| loss/critic2                       | 35.6     |
| timestep                           | 99000    |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2179
----------------------------------------------------------------------------------
| alpha                              | 0.253    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.2     |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -402     |
| loss/alpha                         | -0.0264  |
| loss/critic1                       | 33.8     |
| loss/critic2                       | 33.3     |
| timestep                           | 100000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1950
----------------------------------------------------------------------------------
| alpha                              | 0.252    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.7     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -405     |
| loss/alpha                         | 0.0143   |
| loss/critic1                       | 33.9     |
| loss/critic2                       | 33.7     |
| timestep                           | 101000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2004
----------------------------------------------------------------------------------
| alpha                              | 0.252    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.1     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -407     |
| loss/alpha                         | -0.0308  |
| loss/critic1                       | 32.9     |
| loss/critic2                       | 32.4     |
| timestep                           | 102000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2151
----------------------------------------------------------------------------------
| alpha                              | 0.252    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.4     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -409     |
| loss/alpha                         | 0.0175   |
| loss/critic1                       | 33.8     |
| loss/critic2                       | 33.5     |
| timestep                           | 103000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1858
----------------------------------------------------------------------------------
| alpha                              | 0.254    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -412     |
| loss/alpha                         | 0.0654   |
| loss/critic1                       | 34.4     |
| loss/critic2                       | 34       |
| timestep                           | 104000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2059
----------------------------------------------------------------------------------
| alpha                              | 0.256    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.5     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -414     |
| loss/alpha                         | 0.00838  |
| loss/critic1                       | 35.1     |
| loss/critic2                       | 35       |
| timestep                           | 105000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1912
----------------------------------------------------------------------------------
| alpha                              | 0.256    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.2     |
| eval/normalized_episode_reward_std | 4.8      |
| loss/actor                         | -416     |
| loss/alpha                         | -0.00769 |
| loss/critic1                       | 33.7     |
| loss/critic2                       | 33.3     |
| timestep                           | 106000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2038
----------------------------------------------------------------------------------
| alpha                              | 0.252    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -418     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 34.5     |
| loss/critic2                       | 34.1     |
| timestep                           | 107000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2091
----------------------------------------------------------------------------------
| alpha                              | 0.253    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.8     |
| eval/normalized_episode_reward_std | 4.27     |
| loss/actor                         | -420     |
| loss/alpha                         | 0.0742   |
| loss/critic1                       | 34.4     |
| loss/critic2                       | 34.3     |
| timestep                           | 108000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2202
----------------------------------------------------------------------------------
| alpha                              | 0.253    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.4     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -422     |
| loss/alpha                         | -0.0573  |
| loss/critic1                       | 32.6     |
| loss/critic2                       | 32.7     |
| timestep                           | 109000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2097
----------------------------------------------------------------------------------
| alpha                              | 0.25     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.2     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -424     |
| loss/alpha                         | -0.00309 |
| loss/critic1                       | 34.2     |
| loss/critic2                       | 34       |
| timestep                           | 110000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2174
----------------------------------------------------------------------------------
| alpha                              | 0.251    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57       |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -426     |
| loss/alpha                         | -0.0131  |
| loss/critic1                       | 34.6     |
| loss/critic2                       | 34.3     |
| timestep                           | 111000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2043
----------------------------------------------------------------------------------
| alpha                              | 0.249    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.3     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -427     |
| loss/alpha                         | -0.0314  |
| loss/critic1                       | 33.3     |
| loss/critic2                       | 33       |
| timestep                           | 112000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2065
----------------------------------------------------------------------------------
| alpha                              | 0.251    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.6     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -429     |
| loss/alpha                         | 0.0616   |
| loss/critic1                       | 37.9     |
| loss/critic2                       | 37.5     |
| timestep                           | 113000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1973
----------------------------------------------------------------------------------
| alpha                              | 0.253    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.2     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -429     |
| loss/alpha                         | 0.0021   |
| loss/critic1                       | 35.9     |
| loss/critic2                       | 35.3     |
| timestep                           | 114000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2205
----------------------------------------------------------------------------------
| alpha                              | 0.251    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.4     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -430     |
| loss/alpha                         | -0.0776  |
| loss/critic1                       | 35.2     |
| loss/critic2                       | 34.7     |
| timestep                           | 115000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2101
----------------------------------------------------------------------------------
| alpha                              | 0.245    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.2     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -431     |
| loss/alpha                         | -0.0719  |
| loss/critic1                       | 33.5     |
| loss/critic2                       | 33.1     |
| timestep                           | 116000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2228
----------------------------------------------------------------------------------
| alpha                              | 0.243    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -432     |
| loss/alpha                         | -0.0222  |
| loss/critic1                       | 34.3     |
| loss/critic2                       | 33.8     |
| timestep                           | 117000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2004
----------------------------------------------------------------------------------
| alpha                              | 0.24     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.2     |
| eval/normalized_episode_reward_std | 5.36     |
| loss/actor                         | -433     |
| loss/alpha                         | -0.121   |
| loss/critic1                       | 29.4     |
| loss/critic2                       | 29.1     |
| timestep                           | 118000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2211
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -435     |
| loss/alpha                         | -0.0412  |
| loss/critic1                       | 28.5     |
| loss/critic2                       | 28.1     |
| timestep                           | 119000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2188
----------------------------------------------------------------------------------
| alpha                              | 0.236    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.1     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -436     |
| loss/alpha                         | 0.0476   |
| loss/critic1                       | 32       |
| loss/critic2                       | 31.6     |
| timestep                           | 120000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2320
----------------------------------------------------------------------------------
| alpha                              | 0.237    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -438     |
| loss/alpha                         | 0.0178   |
| loss/critic1                       | 32.9     |
| loss/critic2                       | 32.3     |
| timestep                           | 121000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2255
----------------------------------------------------------------------------------
| alpha                              | 0.239    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.5     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -440     |
| loss/alpha                         | 0.0309   |
| loss/critic1                       | 31.4     |
| loss/critic2                       | 31.1     |
| timestep                           | 122000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2415
----------------------------------------------------------------------------------
| alpha                              | 0.239    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58       |
| eval/normalized_episode_reward_std | 11       |
| loss/actor                         | -441     |
| loss/alpha                         | 0.0185   |
| loss/critic1                       | 31.9     |
| loss/critic2                       | 31.6     |
| timestep                           | 123000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.1990
----------------------------------------------------------------------------------
| alpha                              | 0.241    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -442     |
| loss/alpha                         | 0.011    |
| loss/critic1                       | 32.1     |
| loss/critic2                       | 31.8     |
| timestep                           | 124000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2220
----------------------------------------------------------------------------------
| alpha                              | 0.24     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.4     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -444     |
| loss/alpha                         | -0.0213  |
| loss/critic1                       | 31.9     |
| loss/critic2                       | 31.7     |
| timestep                           | 125000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2256
----------------------------------------------------------------------------------
| alpha                              | 0.24     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -445     |
| loss/alpha                         | -0.031   |
| loss/critic1                       | 30.3     |
| loss/critic2                       | 29.9     |
| timestep                           | 126000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2326
----------------------------------------------------------------------------------
| alpha                              | 0.238    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.4     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -446     |
| loss/alpha                         | -0.0208  |
| loss/critic1                       | 30.8     |
| loss/critic2                       | 30.4     |
| timestep                           | 127000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2372
----------------------------------------------------------------------------------
| alpha                              | 0.237    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.2     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -448     |
| loss/alpha                         | -0.00942 |
| loss/critic1                       | 31.7     |
| loss/critic2                       | 31.1     |
| timestep                           | 128000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2520
----------------------------------------------------------------------------------
| alpha                              | 0.237    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -449     |
| loss/alpha                         | 0.0389   |
| loss/critic1                       | 31       |
| loss/critic2                       | 30.6     |
| timestep                           | 129000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2255
----------------------------------------------------------------------------------
| alpha                              | 0.237    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.4     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -451     |
| loss/alpha                         | -0.0658  |
| loss/critic1                       | 30.2     |
| loss/critic2                       | 29.8     |
| timestep                           | 130000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2360
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.3     |
| eval/normalized_episode_reward_std | 7.7      |
| loss/actor                         | -452     |
| loss/alpha                         | -0.016   |
| loss/critic1                       | 30.1     |
| loss/critic2                       | 29.6     |
| timestep                           | 131000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2336
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.2     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -454     |
| loss/alpha                         | 0.0212   |
| loss/critic1                       | 31       |
| loss/critic2                       | 30.7     |
| timestep                           | 132000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2195
----------------------------------------------------------------------------------
| alpha                              | 0.235    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 2.74     |
| loss/actor                         | -455     |
| loss/alpha                         | -0.0173  |
| loss/critic1                       | 30.2     |
| loss/critic2                       | 30.2     |
| timestep                           | 133000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2309
----------------------------------------------------------------------------------
| alpha                              | 0.234    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.4     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -456     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 27.4     |
| loss/critic2                       | 27.2     |
| timestep                           | 134000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2239
----------------------------------------------------------------------------------
| alpha                              | 0.232    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.8     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -458     |
| loss/alpha                         | -0.0462  |
| loss/critic1                       | 25.5     |
| loss/critic2                       | 25.4     |
| timestep                           | 135000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2392
----------------------------------------------------------------------------------
| alpha                              | 0.232    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.1     |
| eval/normalized_episode_reward_std | 9.88     |
| loss/actor                         | -460     |
| loss/alpha                         | 0.0385   |
| loss/critic1                       | 26.5     |
| loss/critic2                       | 26.3     |
| timestep                           | 136000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2322
----------------------------------------------------------------------------------
| alpha                              | 0.232    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.2     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -461     |
| loss/alpha                         | -0.00723 |
| loss/critic1                       | 27.9     |
| loss/critic2                       | 27.3     |
| timestep                           | 137000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2158
----------------------------------------------------------------------------------
| alpha                              | 0.231    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.2     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -462     |
| loss/alpha                         | -0.0767  |
| loss/critic1                       | 25.9     |
| loss/critic2                       | 25.6     |
| timestep                           | 138000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2454
----------------------------------------------------------------------------------
| alpha                              | 0.228    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -464     |
| loss/alpha                         | -0.0343  |
| loss/critic1                       | 27.8     |
| loss/critic2                       | 27.8     |
| timestep                           | 139000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2291
----------------------------------------------------------------------------------
| alpha                              | 0.227    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59       |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -465     |
| loss/alpha                         | -0.0178  |
| loss/critic1                       | 28.6     |
| loss/critic2                       | 28.2     |
| timestep                           | 140000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2368
----------------------------------------------------------------------------------
| alpha                              | 0.225    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.5     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -466     |
| loss/alpha                         | -0.0559  |
| loss/critic1                       | 27.8     |
| loss/critic2                       | 27.9     |
| timestep                           | 141000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2289
----------------------------------------------------------------------------------
| alpha                              | 0.224    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.9     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -467     |
| loss/alpha                         | 0.0255   |
| loss/critic1                       | 27.5     |
| loss/critic2                       | 27.2     |
| timestep                           | 142000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2283
----------------------------------------------------------------------------------
| alpha                              | 0.225    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.8     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -469     |
| loss/alpha                         | -0.0422  |
| loss/critic1                       | 25.8     |
| loss/critic2                       | 25.7     |
| timestep                           | 143000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2315
----------------------------------------------------------------------------------
| alpha                              | 0.223    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.6     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -470     |
| loss/alpha                         | 0.0271   |
| loss/critic1                       | 24.7     |
| loss/critic2                       | 24.3     |
| timestep                           | 144000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2301
----------------------------------------------------------------------------------
| alpha                              | 0.224    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 7.3      |
| loss/actor                         | -472     |
| loss/alpha                         | -0.00921 |
| loss/critic1                       | 25.4     |
| loss/critic2                       | 25       |
| timestep                           | 145000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2313
----------------------------------------------------------------------------------
| alpha                              | 0.221    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.8     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -474     |
| loss/alpha                         | -0.0984  |
| loss/critic1                       | 25.2     |
| loss/critic2                       | 25       |
| timestep                           | 146000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2472
----------------------------------------------------------------------------------
| alpha                              | 0.219    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.3     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -475     |
| loss/alpha                         | 0.00162  |
| loss/critic1                       | 26.6     |
| loss/critic2                       | 26.3     |
| timestep                           | 147000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2469
----------------------------------------------------------------------------------
| alpha                              | 0.22     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -477     |
| loss/alpha                         | 0.0679   |
| loss/critic1                       | 28.3     |
| loss/critic2                       | 27.9     |
| timestep                           | 148000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2386
----------------------------------------------------------------------------------
| alpha                              | 0.221    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.6     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -478     |
| loss/alpha                         | 0.0071   |
| loss/critic1                       | 26.5     |
| loss/critic2                       | 26.4     |
| timestep                           | 149000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2548
----------------------------------------------------------------------------------
| alpha                              | 0.225    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -480     |
| loss/alpha                         | 0.0677   |
| loss/critic1                       | 25.6     |
| loss/critic2                       | 25.4     |
| timestep                           | 150000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2408
----------------------------------------------------------------------------------
| alpha                              | 0.226    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -481     |
| loss/alpha                         | -0.0235  |
| loss/critic1                       | 26.5     |
| loss/critic2                       | 26.2     |
| timestep                           | 151000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2553
----------------------------------------------------------------------------------
| alpha                              | 0.223    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.1     |
| eval/normalized_episode_reward_std | 8.03     |
| loss/actor                         | -482     |
| loss/alpha                         | -0.067   |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 25.2     |
| timestep                           | 152000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2408
----------------------------------------------------------------------------------
| alpha                              | 0.219    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -484     |
| loss/alpha                         | -0.0922  |
| loss/critic1                       | 25.5     |
| loss/critic2                       | 25.2     |
| timestep                           | 153000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2344
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.1     |
| eval/normalized_episode_reward_std | 5.89     |
| loss/actor                         | -485     |
| loss/alpha                         | 0.0327   |
| loss/critic1                       | 25.8     |
| loss/critic2                       | 25.7     |
| timestep                           | 154000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2612
----------------------------------------------------------------------------------
| alpha                              | 0.219    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.2     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -486     |
| loss/alpha                         | -0.0276  |
| loss/critic1                       | 26.5     |
| loss/critic2                       | 26.3     |
| timestep                           | 155000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2567
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47       |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -488     |
| loss/alpha                         | -0.0469  |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 25.3     |
| timestep                           | 156000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2515
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.6     |
| eval/normalized_episode_reward_std | 6.69     |
| loss/actor                         | -488     |
| loss/alpha                         | 0.0513   |
| loss/critic1                       | 28.5     |
| loss/critic2                       | 28.2     |
| timestep                           | 157000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2326
----------------------------------------------------------------------------------
| alpha                              | 0.22     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.1     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -489     |
| loss/alpha                         | 0.0635   |
| loss/critic1                       | 27.4     |
| loss/critic2                       | 27.2     |
| timestep                           | 158000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2574
----------------------------------------------------------------------------------
| alpha                              | 0.22     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.3     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -490     |
| loss/alpha                         | -0.0596  |
| loss/critic1                       | 26.8     |
| loss/critic2                       | 26.6     |
| timestep                           | 159000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2613
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.1     |
| eval/normalized_episode_reward_std | 8.31     |
| loss/actor                         | -491     |
| loss/alpha                         | -0.0829  |
| loss/critic1                       | 25.8     |
| loss/critic2                       | 25.5     |
| timestep                           | 160000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2493
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.1     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -492     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 26.9     |
| loss/critic2                       | 26.7     |
| timestep                           | 161000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2490
----------------------------------------------------------------------------------
| alpha                              | 0.221    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 6.19     |
| loss/actor                         | -494     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 24       |
| timestep                           | 162000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2387
----------------------------------------------------------------------------------
| alpha                              | 0.22     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60       |
| eval/normalized_episode_reward_std | 9.94     |
| loss/actor                         | -495     |
| loss/alpha                         | -0.0408  |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.2     |
| timestep                           | 163000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2301
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.3     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -497     |
| loss/alpha                         | -0.0215  |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.4     |
| timestep                           | 164000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2243
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.5     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -498     |
| loss/alpha                         | -0.042   |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.4     |
| timestep                           | 165000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2374
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -499     |
| loss/alpha                         | -0.0346  |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 25.2     |
| timestep                           | 166000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2460
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.4     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -500     |
| loss/alpha                         | 0.068    |
| loss/critic1                       | 27.5     |
| loss/critic2                       | 27.3     |
| timestep                           | 167000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2237
----------------------------------------------------------------------------------
| alpha                              | 0.219    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -501     |
| loss/alpha                         | 0.00347  |
| loss/critic1                       | 26.4     |
| loss/critic2                       | 26.3     |
| timestep                           | 168000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2436
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -502     |
| loss/alpha                         | 0.0113   |
| loss/critic1                       | 26.4     |
| loss/critic2                       | 26.1     |
| timestep                           | 169000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2377
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -503     |
| loss/alpha                         | 0.00536  |
| loss/critic1                       | 26.6     |
| loss/critic2                       | 26.4     |
| timestep                           | 170000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2511
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 3.87     |
| loss/actor                         | -504     |
| loss/alpha                         | -0.0614  |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.3     |
| timestep                           | 171000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2493
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 41.6     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -505     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.3     |
| timestep                           | 172000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2394
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -505     |
| loss/alpha                         | 0.031    |
| loss/critic1                       | 26       |
| loss/critic2                       | 26.1     |
| timestep                           | 173000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2463
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -506     |
| loss/alpha                         | -0.0299  |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.4     |
| timestep                           | 174000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2512
----------------------------------------------------------------------------------
| alpha                              | 0.214    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -507     |
| loss/alpha                         | -0.0504  |
| loss/critic1                       | 23.3     |
| loss/critic2                       | 23.4     |
| timestep                           | 175000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2279
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -508     |
| loss/alpha                         | 0.00184  |
| loss/critic1                       | 23.4     |
| loss/critic2                       | 23.3     |
| timestep                           | 176000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2319
----------------------------------------------------------------------------------
| alpha                              | 0.215    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -509     |
| loss/alpha                         | 0.0487   |
| loss/critic1                       | 23.4     |
| loss/critic2                       | 23       |
| timestep                           | 177000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2437
----------------------------------------------------------------------------------
| alpha                              | 0.212    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.2     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -510     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 22.7     |
| loss/critic2                       | 22.5     |
| timestep                           | 178000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2240
----------------------------------------------------------------------------------
| alpha                              | 0.212    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.4     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -511     |
| loss/alpha                         | 0.0655   |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.3     |
| timestep                           | 179000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2189
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 3.69     |
| loss/actor                         | -512     |
| loss/alpha                         | 0.00864  |
| loss/critic1                       | 23.4     |
| loss/critic2                       | 23.4     |
| timestep                           | 180000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2503
----------------------------------------------------------------------------------
| alpha                              | 0.215    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.3     |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -513     |
| loss/alpha                         | 0.0726   |
| loss/critic1                       | 25.6     |
| loss/critic2                       | 25.4     |
| timestep                           | 181000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2386
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -514     |
| loss/alpha                         | 0.0599   |
| loss/critic1                       | 24.7     |
| loss/critic2                       | 24.7     |
| timestep                           | 182000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2290
----------------------------------------------------------------------------------
| alpha                              | 0.221    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.2     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -515     |
| loss/alpha                         | 0.0493   |
| loss/critic1                       | 24.9     |
| loss/critic2                       | 24.7     |
| timestep                           | 183000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2376
----------------------------------------------------------------------------------
| alpha                              | 0.222    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.5     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -516     |
| loss/alpha                         | -0.0189  |
| loss/critic1                       | 26       |
| loss/critic2                       | 25.9     |
| timestep                           | 184000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2260
----------------------------------------------------------------------------------
| alpha                              | 0.219    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 42.7     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -517     |
| loss/alpha                         | -0.098   |
| loss/critic1                       | 27       |
| loss/critic2                       | 26.6     |
| timestep                           | 185000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2430
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.5     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -518     |
| loss/alpha                         | 0.0708   |
| loss/critic1                       | 26.5     |
| loss/critic2                       | 26.4     |
| timestep                           | 186000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2192
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47       |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -519     |
| loss/alpha                         | -0.0905  |
| loss/critic1                       | 24.4     |
| loss/critic2                       | 24       |
| timestep                           | 187000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2379
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 5.24     |
| loss/actor                         | -519     |
| loss/alpha                         | 0.0119   |
| loss/critic1                       | 30.5     |
| loss/critic2                       | 30.3     |
| timestep                           | 188000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2532
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47.6     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -519     |
| loss/alpha                         | -0.00776 |
| loss/critic1                       | 27.7     |
| loss/critic2                       | 27.3     |
| timestep                           | 189000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2625
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -520     |
| loss/alpha                         | -0.0261  |
| loss/critic1                       | 27.5     |
| loss/critic2                       | 27.2     |
| timestep                           | 190000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2390
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -520     |
| loss/alpha                         | -0.0747  |
| loss/critic1                       | 26.1     |
| loss/critic2                       | 25.7     |
| timestep                           | 191000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2640
----------------------------------------------------------------------------------
| alpha                              | 0.212    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.1     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -520     |
| loss/alpha                         | 0.0428   |
| loss/critic1                       | 26.3     |
| loss/critic2                       | 26       |
| timestep                           | 192000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2426
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.7     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -521     |
| loss/alpha                         | -0.036   |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 21.9     |
| timestep                           | 193000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2315
----------------------------------------------------------------------------------
| alpha                              | 0.212    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.7     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -521     |
| loss/alpha                         | 0.0345   |
| loss/critic1                       | 23.1     |
| loss/critic2                       | 23       |
| timestep                           | 194000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2319
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 46       |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -522     |
| loss/alpha                         | -0.0504  |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.3     |
| timestep                           | 195000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2372
----------------------------------------------------------------------------------
| alpha                              | 0.21     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -522     |
| loss/alpha                         | -0.0553  |
| loss/critic1                       | 24.2     |
| loss/critic2                       | 24.1     |
| timestep                           | 196000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2292
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -523     |
| loss/alpha                         | -0.0416  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22       |
| timestep                           | 197000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2268
-----------------------------------------------------------------------------------
| alpha                              | 0.207     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 65.1      |
| eval/normalized_episode_reward_std | 2.78      |
| loss/actor                         | -524      |
| loss/alpha                         | -0.000979 |
| loss/critic1                       | 24.3      |
| loss/critic2                       | 24.1      |
| timestep                           | 198000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2413
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -525     |
| loss/alpha                         | 0.0465   |
| loss/critic1                       | 25.2     |
| loss/critic2                       | 24.9     |
| timestep                           | 199000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2462
----------------------------------------------------------------------------------
| alpha                              | 0.21     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -525     |
| loss/alpha                         | 0.0336   |
| loss/critic1                       | 25.2     |
| loss/critic2                       | 24.9     |
| timestep                           | 200000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2396
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64       |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -526     |
| loss/alpha                         | 0.00985  |
| loss/critic1                       | 23.8     |
| loss/critic2                       | 23.8     |
| timestep                           | 201000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2301
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -527     |
| loss/alpha                         | 0.051    |
| loss/critic1                       | 24.2     |
| loss/critic2                       | 24.2     |
| timestep                           | 202000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2396
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -528     |
| loss/alpha                         | 0.00138  |
| loss/critic1                       | 23.1     |
| loss/critic2                       | 22.7     |
| timestep                           | 203000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2386
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.2     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -529     |
| loss/alpha                         | -0.0226  |
| loss/critic1                       | 23.2     |
| loss/critic2                       | 23.2     |
| timestep                           | 204000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2281
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 5.84     |
| loss/actor                         | -531     |
| loss/alpha                         | -0.0032  |
| loss/critic1                       | 24.9     |
| loss/critic2                       | 24.6     |
| timestep                           | 205000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2366
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.5     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -531     |
| loss/alpha                         | 0.00461  |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 25.2     |
| timestep                           | 206000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2301
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.5     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -532     |
| loss/alpha                         | 0.0235   |
| loss/critic1                       | 23.8     |
| loss/critic2                       | 23.5     |
| timestep                           | 207000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2429
----------------------------------------------------------------------------------
| alpha                              | 0.214    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -532     |
| loss/alpha                         | 0.0436   |
| loss/critic1                       | 24.7     |
| loss/critic2                       | 24.6     |
| timestep                           | 208000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2545
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -532     |
| loss/alpha                         | 0.057    |
| loss/critic1                       | 25       |
| loss/critic2                       | 24.9     |
| timestep                           | 209000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2368
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -533     |
| loss/alpha                         | -0.0896  |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.9     |
| timestep                           | 210000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2491
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.3     |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -533     |
| loss/alpha                         | 0.000751 |
| loss/critic1                       | 23       |
| loss/critic2                       | 22.8     |
| timestep                           | 211000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2371
----------------------------------------------------------------------------------
| alpha                              | 0.215    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -534     |
| loss/alpha                         | 0.0643   |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.4     |
| timestep                           | 212000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2424
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -534     |
| loss/alpha                         | -0.0339  |
| loss/critic1                       | 22.9     |
| loss/critic2                       | 22.6     |
| timestep                           | 213000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2491
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -535     |
| loss/alpha                         | -0.0709  |
| loss/critic1                       | 23.6     |
| loss/critic2                       | 23.4     |
| timestep                           | 214000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2383
----------------------------------------------------------------------------------
| alpha                              | 0.214    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60       |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -536     |
| loss/alpha                         | 0.0946   |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 25.3     |
| timestep                           | 215000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2426
----------------------------------------------------------------------------------
| alpha                              | 0.216    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.1     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -537     |
| loss/alpha                         | -0.0476  |
| loss/critic1                       | 25.2     |
| loss/critic2                       | 24.9     |
| timestep                           | 216000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2426
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -537     |
| loss/alpha                         | -0.00645 |
| loss/critic1                       | 24.8     |
| loss/critic2                       | 24.5     |
| timestep                           | 217000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2370
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -538     |
| loss/alpha                         | -0.0693  |
| loss/critic1                       | 24.5     |
| loss/critic2                       | 24.3     |
| timestep                           | 218000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2343
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.4     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -538     |
| loss/alpha                         | 0.043    |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 23.8     |
| timestep                           | 219000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2292
----------------------------------------------------------------------------------
| alpha                              | 0.212    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -539     |
| loss/alpha                         | -0.0486  |
| loss/critic1                       | 22.5     |
| loss/critic2                       | 22.4     |
| timestep                           | 220000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2384
----------------------------------------------------------------------------------
| alpha                              | 0.21     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -540     |
| loss/alpha                         | 0.00841  |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.9     |
| timestep                           | 221000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2323
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -541     |
| loss/alpha                         | -0.017   |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.7     |
| timestep                           | 222000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2326
----------------------------------------------------------------------------------
| alpha                              | 0.212    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 8.53     |
| loss/actor                         | -541     |
| loss/alpha                         | 0.0622   |
| loss/critic1                       | 22.7     |
| loss/critic2                       | 22.6     |
| timestep                           | 223000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2407
----------------------------------------------------------------------------------
| alpha                              | 0.212    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.5     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -542     |
| loss/alpha                         | 0.0121   |
| loss/critic1                       | 23.2     |
| loss/critic2                       | 23.1     |
| timestep                           | 224000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2185
----------------------------------------------------------------------------------
| alpha                              | 0.214    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 30.7     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -543     |
| loss/alpha                         | 0.00856  |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 23.8     |
| timestep                           | 225000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2378
----------------------------------------------------------------------------------
| alpha                              | 0.215    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 4.1      |
| loss/actor                         | -543     |
| loss/alpha                         | 0.0829   |
| loss/critic1                       | 25.4     |
| loss/critic2                       | 25.4     |
| timestep                           | 226000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2250
----------------------------------------------------------------------------------
| alpha                              | 0.218    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -544     |
| loss/alpha                         | 0.0345   |
| loss/critic1                       | 25.1     |
| loss/critic2                       | 24.9     |
| timestep                           | 227000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2180
----------------------------------------------------------------------------------
| alpha                              | 0.217    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -544     |
| loss/alpha                         | -0.0884  |
| loss/critic1                       | 25.7     |
| loss/critic2                       | 25.7     |
| timestep                           | 228000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2399
----------------------------------------------------------------------------------
| alpha                              | 0.215    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -544     |
| loss/alpha                         | -0.00839 |
| loss/critic1                       | 24.7     |
| loss/critic2                       | 24.6     |
| timestep                           | 229000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2373
----------------------------------------------------------------------------------
| alpha                              | 0.215    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -544     |
| loss/alpha                         | 0.00679  |
| loss/critic1                       | 25.3     |
| loss/critic2                       | 25.1     |
| timestep                           | 230000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2484
----------------------------------------------------------------------------------
| alpha                              | 0.213    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -545     |
| loss/alpha                         | -0.093   |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 21.8     |
| timestep                           | 231000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2246
----------------------------------------------------------------------------------
| alpha                              | 0.211    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -545     |
| loss/alpha                         | -0.0378  |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.6     |
| timestep                           | 232000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2408
----------------------------------------------------------------------------------
| alpha                              | 0.209    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -545     |
| loss/alpha                         | 0.0326   |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.7     |
| timestep                           | 233000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2280
----------------------------------------------------------------------------------
| alpha                              | 0.21     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -546     |
| loss/alpha                         | -0.0226  |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.8     |
| timestep                           | 234000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2350
----------------------------------------------------------------------------------
| alpha                              | 0.209    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 45.3     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -547     |
| loss/alpha                         | -0.012   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.7     |
| timestep                           | 235000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2497
----------------------------------------------------------------------------------
| alpha                              | 0.21     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.1     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -547     |
| loss/alpha                         | 0.045    |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 20.8     |
| timestep                           | 236000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2235
----------------------------------------------------------------------------------
| alpha                              | 0.21     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.3     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -548     |
| loss/alpha                         | -0.05    |
| loss/critic1                       | 23.1     |
| loss/critic2                       | 23       |
| timestep                           | 237000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2359
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -548     |
| loss/alpha                         | -0.0633  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 21.9     |
| timestep                           | 238000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2493
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -548     |
| loss/alpha                         | -0.0568  |
| loss/critic1                       | 22.2     |
| loss/critic2                       | 22       |
| timestep                           | 239000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2322
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 4.83     |
| loss/actor                         | -549     |
| loss/alpha                         | 0.0211   |
| loss/critic1                       | 23.1     |
| loss/critic2                       | 22.9     |
| timestep                           | 240000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2411
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -549     |
| loss/alpha                         | -0.0371  |
| loss/critic1                       | 22.9     |
| loss/critic2                       | 22.8     |
| timestep                           | 241000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2679
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -550     |
| loss/alpha                         | -0.0273  |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.2     |
| timestep                           | 242000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2379
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -551     |
| loss/alpha                         | 0.0292   |
| loss/critic1                       | 23.2     |
| loss/critic2                       | 23.1     |
| timestep                           | 243000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2291
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 5.59     |
| loss/actor                         | -552     |
| loss/alpha                         | 0.0155   |
| loss/critic1                       | 22.8     |
| loss/critic2                       | 22.8     |
| timestep                           | 244000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2434
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 5.12     |
| loss/actor                         | -552     |
| loss/alpha                         | -0.016   |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22       |
| timestep                           | 245000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2302
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -553     |
| loss/alpha                         | 0.0183   |
| loss/critic1                       | 22.9     |
| loss/critic2                       | 22.8     |
| timestep                           | 246000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2426
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 6.39     |
| loss/actor                         | -553     |
| loss/alpha                         | 0.0106   |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.2     |
| timestep                           | 247000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2266
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -553     |
| loss/alpha                         | 0.0397   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.7     |
| timestep                           | 248000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2486
----------------------------------------------------------------------------------
| alpha                              | 0.207    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -554     |
| loss/alpha                         | 0.0426   |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.7     |
| timestep                           | 249000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2403
----------------------------------------------------------------------------------
| alpha                              | 0.209    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -554     |
| loss/alpha                         | 0.0287   |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.6     |
| timestep                           | 250000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2360
----------------------------------------------------------------------------------
| alpha                              | 0.208    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -555     |
| loss/alpha                         | -0.0197  |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.3     |
| timestep                           | 251000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2311
----------------------------------------------------------------------------------
| alpha                              | 0.207    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 3.68     |
| loss/actor                         | -556     |
| loss/alpha                         | -0.0309  |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.4     |
| timestep                           | 252000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2249
----------------------------------------------------------------------------------
| alpha                              | 0.207    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -556     |
| loss/alpha                         | 0.016    |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.5     |
| timestep                           | 253000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2470
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -557     |
| loss/alpha                         | -0.041   |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.2     |
| timestep                           | 254000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2453
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 8.32     |
| loss/actor                         | -558     |
| loss/alpha                         | -0.0137  |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.5     |
| timestep                           | 255000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2520
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.2     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -558     |
| loss/alpha                         | -0.0249  |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.4     |
| timestep                           | 256000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2458
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.7     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -559     |
| loss/alpha                         | -0.00367 |
| loss/critic1                       | 24.3     |
| loss/critic2                       | 24.2     |
| timestep                           | 257000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2521
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.6     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -559     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 22       |
| loss/critic2                       | 22.1     |
| timestep                           | 258000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2399
----------------------------------------------------------------------------------
| alpha                              | 0.205    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -559     |
| loss/alpha                         | 0.0491   |
| loss/critic1                       | 22.9     |
| loss/critic2                       | 22.6     |
| timestep                           | 259000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2517
----------------------------------------------------------------------------------
| alpha                              | 0.206    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 5.21     |
| loss/actor                         | -560     |
| loss/alpha                         | -0.0539  |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.6     |
| timestep                           | 260000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2342
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -559     |
| loss/alpha                         | -0.0327  |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.6     |
| timestep                           | 261000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2598
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -559     |
| loss/alpha                         | -0.138   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.5     |
| timestep                           | 262000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2323
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.4     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -560     |
| loss/alpha                         | -0.00887 |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 21.2     |
| timestep                           | 263000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2427
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 2.7      |
| loss/actor                         | -560     |
| loss/alpha                         | -0.0314  |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.8     |
| timestep                           | 264000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2349
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -560     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.5     |
| timestep                           | 265000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2381
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.2     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -561     |
| loss/alpha                         | -0.00649 |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 266000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2297
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.2     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -561     |
| loss/alpha                         | -0.00601 |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.6     |
| timestep                           | 267000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2553
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -562     |
| loss/alpha                         | -0.0517  |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.6     |
| timestep                           | 268000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2331
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53       |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -562     |
| loss/alpha                         | 0.085    |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 21.2     |
| timestep                           | 269000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2424
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -562     |
| loss/alpha                         | 0.00154  |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.4     |
| timestep                           | 270000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2342
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.7     |
| eval/normalized_episode_reward_std | 28.4     |
| loss/actor                         | -563     |
| loss/alpha                         | 0.0435   |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.6     |
| timestep                           | 271000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2566
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.6     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -563     |
| loss/alpha                         | -0.0202  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.6     |
| timestep                           | 272000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2497
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 42.7     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -564     |
| loss/alpha                         | 0.0116   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.2     |
| timestep                           | 273000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2364
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -564     |
| loss/alpha                         | -0.0422  |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 21       |
| timestep                           | 274000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2564
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 8.93     |
| loss/actor                         | -565     |
| loss/alpha                         | -0.0233  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.9     |
| timestep                           | 275000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2321
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -565     |
| loss/alpha                         | -0.0414  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20.1     |
| timestep                           | 276000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2330
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64       |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -566     |
| loss/alpha                         | 0.0784   |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.7     |
| timestep                           | 277000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2484
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -566     |
| loss/alpha                         | -0.0528  |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.5     |
| timestep                           | 278000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2491
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.8     |
| eval/normalized_episode_reward_std | 25       |
| loss/actor                         | -567     |
| loss/alpha                         | 0.0467   |
| loss/critic1                       | 24.4     |
| loss/critic2                       | 24.1     |
| timestep                           | 279000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2247
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.6     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -567     |
| loss/alpha                         | 0.0384   |
| loss/critic1                       | 23.4     |
| loss/critic2                       | 23.3     |
| timestep                           | 280000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2218
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -567     |
| loss/alpha                         | 0.0291   |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 23.9     |
| timestep                           | 281000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2259
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.2     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -567     |
| loss/alpha                         | -0.0894  |
| loss/critic1                       | 23.9     |
| loss/critic2                       | 23.4     |
| timestep                           | 282000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2446
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.7     |
| eval/normalized_episode_reward_std | 25.8     |
| loss/actor                         | -568     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 21       |
| timestep                           | 283000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2482
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -568     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.1     |
| timestep                           | 284000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2482
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52       |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -568     |
| loss/alpha                         | 0.0475   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.6     |
| timestep                           | 285000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2506
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.9     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -569     |
| loss/alpha                         | 0.0028   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20       |
| timestep                           | 286000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2556
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -570     |
| loss/alpha                         | 0.0428   |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.4     |
| timestep                           | 287000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2167
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -570     |
| loss/alpha                         | 0.0255   |
| loss/critic1                       | 22.2     |
| loss/critic2                       | 22.2     |
| timestep                           | 288000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2400
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.9     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -570     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.7     |
| timestep                           | 289000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2489
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -571     |
| loss/alpha                         | -0.0587  |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.1     |
| timestep                           | 290000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2431
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -571     |
| loss/alpha                         | 0.0208   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.7     |
| timestep                           | 291000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2496
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -572     |
| loss/alpha                         | 0.0177   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.4     |
| timestep                           | 292000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2429
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -573     |
| loss/alpha                         | -0.0203  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.6     |
| timestep                           | 293000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2363
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -573     |
| loss/alpha                         | 0.0415   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.4     |
| timestep                           | 294000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2333
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.7     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -573     |
| loss/alpha                         | -0.0861  |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.3     |
| timestep                           | 295000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2539
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -574     |
| loss/alpha                         | -0.095   |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.7     |
| timestep                           | 296000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2386
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.5     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -574     |
| loss/alpha                         | -0.0126  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.4     |
| timestep                           | 297000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2425
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.2     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -575     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.2     |
| timestep                           | 298000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2449
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -576     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.4     |
| timestep                           | 299000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2341
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -576     |
| loss/alpha                         | 0.0829   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 20       |
| timestep                           | 300000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2271
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -577     |
| loss/alpha                         | 0.0699   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.4     |
| timestep                           | 301000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2422
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 6.03     |
| loss/actor                         | -577     |
| loss/alpha                         | -0.0181  |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 20.8     |
| timestep                           | 302000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2505
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.5     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -578     |
| loss/alpha                         | 0.0481   |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.4     |
| timestep                           | 303000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2454
----------------------------------------------------------------------------------
| alpha                              | 0.204    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -578     |
| loss/alpha                         | -0.00732 |
| loss/critic1                       | 22.8     |
| loss/critic2                       | 22.5     |
| timestep                           | 304000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2313
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 8.46     |
| loss/actor                         | -578     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.4     |
| timestep                           | 305000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2417
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47.2     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -578     |
| loss/alpha                         | 0.00883  |
| loss/critic1                       | 22.5     |
| loss/critic2                       | 22.3     |
| timestep                           | 306000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2244
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -578     |
| loss/alpha                         | 0.0419   |
| loss/critic1                       | 23.9     |
| loss/critic2                       | 23.7     |
| timestep                           | 307000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2517
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -578     |
| loss/alpha                         | 0.00861  |
| loss/critic1                       | 22.9     |
| loss/critic2                       | 22.5     |
| timestep                           | 308000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2383
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -578     |
| loss/alpha                         | -0.0463  |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.4     |
| timestep                           | 309000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2454
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -579     |
| loss/alpha                         | -0.0771  |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.4     |
| timestep                           | 310000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2470
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.5     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -579     |
| loss/alpha                         | -0.0614  |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.2     |
| timestep                           | 311000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2680
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -579     |
| loss/alpha                         | -0.00375 |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 312000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2532
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -580     |
| loss/alpha                         | -0.0484  |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.9     |
| timestep                           | 313000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2403
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.4     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -580     |
| loss/alpha                         | 0.0534   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.7     |
| timestep                           | 314000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2432
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 40.9     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -581     |
| loss/alpha                         | 0.117    |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 315000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2364
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.1     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -581     |
| loss/alpha                         | 0.0925   |
| loss/critic1                       | 24.8     |
| loss/critic2                       | 24.6     |
| timestep                           | 316000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2253
----------------------------------------------------------------------------------
| alpha                              | 0.203    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65       |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -581     |
| loss/alpha                         | 0.0137   |
| loss/critic1                       | 26       |
| loss/critic2                       | 25.7     |
| timestep                           | 317000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2238
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.8     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -581     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 24.1     |
| loss/critic2                       | 24       |
| timestep                           | 318000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2415
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -581     |
| loss/alpha                         | -0.00492 |
| loss/critic1                       | 24.2     |
| loss/critic2                       | 23.9     |
| timestep                           | 319000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2524
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 9.56     |
| loss/actor                         | -581     |
| loss/alpha                         | -0.0721  |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.3     |
| timestep                           | 320000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2519
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.8     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -581     |
| loss/alpha                         | -0.104   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.4     |
| timestep                           | 321000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2484
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.1     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -581     |
| loss/alpha                         | 0.0135   |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.4     |
| timestep                           | 322000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2700
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.7     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -581     |
| loss/alpha                         | 0.072    |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.8     |
| timestep                           | 323000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2526
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53       |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -582     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.2     |
| timestep                           | 324000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2519
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.2     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -582     |
| loss/alpha                         | 0.0317   |
| loss/critic1                       | 22.9     |
| loss/critic2                       | 22.5     |
| timestep                           | 325000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2448
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.2     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -582     |
| loss/alpha                         | 0.0434   |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22       |
| timestep                           | 326000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2642
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -582     |
| loss/alpha                         | -0.0462  |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.6     |
| timestep                           | 327000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2588
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.7     |
| eval/normalized_episode_reward_std | 25.9     |
| loss/actor                         | -582     |
| loss/alpha                         | -0.0069  |
| loss/critic1                       | 23.3     |
| loss/critic2                       | 23       |
| timestep                           | 328000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2330
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -583     |
| loss/alpha                         | -0.00763 |
| loss/critic1                       | 23.2     |
| loss/critic2                       | 23.1     |
| timestep                           | 329000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2363
----------------------------------------------------------------------------------
| alpha                              | 0.201    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -583     |
| loss/alpha                         | 0.00828  |
| loss/critic1                       | 23.3     |
| loss/critic2                       | 23.1     |
| timestep                           | 330000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2345
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -583     |
| loss/alpha                         | -0.0333  |
| loss/critic1                       | 23.2     |
| loss/critic2                       | 23.1     |
| timestep                           | 331000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2400
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -583     |
| loss/alpha                         | 0.0367   |
| loss/critic1                       | 23.5     |
| loss/critic2                       | 23.1     |
| timestep                           | 332000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2451
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -584     |
| loss/alpha                         | 0.00628  |
| loss/critic1                       | 22.7     |
| loss/critic2                       | 22.5     |
| timestep                           | 333000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2523
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 6.13     |
| loss/actor                         | -584     |
| loss/alpha                         | 0.0296   |
| loss/critic1                       | 22.6     |
| loss/critic2                       | 22.4     |
| timestep                           | 334000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2381
----------------------------------------------------------------------------------
| alpha                              | 0.202    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -584     |
| loss/alpha                         | -0.0277  |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.1     |
| timestep                           | 335000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2539
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -584     |
| loss/alpha                         | -0.107   |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.3     |
| timestep                           | 336000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2510
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -585     |
| loss/alpha                         | -0.00549 |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.3     |
| timestep                           | 337000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2501
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -585     |
| loss/alpha                         | 0.009    |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 21       |
| timestep                           | 338000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2556
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -586     |
| loss/alpha                         | -0.00947 |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21       |
| timestep                           | 339000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2483
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.4     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -586     |
| loss/alpha                         | 0.0155   |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 21.1     |
| timestep                           | 340000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2283
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 5.81     |
| loss/actor                         | -586     |
| loss/alpha                         | 0.0312   |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.8     |
| timestep                           | 341000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2300
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -587     |
| loss/alpha                         | 0.0399   |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.6     |
| timestep                           | 342000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2473
----------------------------------------------------------------------------------
| alpha                              | 0.2      |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -587     |
| loss/alpha                         | -0.00169 |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.6     |
| timestep                           | 343000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2252
----------------------------------------------------------------------------------
| alpha                              | 0.198    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -587     |
| loss/alpha                         | -0.0753  |
| loss/critic1                       | 22.2     |
| loss/critic2                       | 21.9     |
| timestep                           | 344000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2462
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -587     |
| loss/alpha                         | 0.00711  |
| loss/critic1                       | 22.8     |
| loss/critic2                       | 22.4     |
| timestep                           | 345000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2517
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.7     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -588     |
| loss/alpha                         | 0.0589   |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.1     |
| timestep                           | 346000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2469
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -588     |
| loss/alpha                         | 0.00572  |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.7     |
| timestep                           | 347000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2497
----------------------------------------------------------------------------------
| alpha                              | 0.199    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 2.72     |
| loss/actor                         | -588     |
| loss/alpha                         | -0.0146  |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.2     |
| timestep                           | 348000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2494
----------------------------------------------------------------------------------
| alpha                              | 0.197    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -588     |
| loss/alpha                         | -0.0811  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.2     |
| timestep                           | 349000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2393
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47.2     |
| eval/normalized_episode_reward_std | 28.7     |
| loss/actor                         | -588     |
| loss/alpha                         | 0.00852  |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.8     |
| timestep                           | 350000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2151
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.0306  |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.7     |
| timestep                           | 351000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2460
----------------------------------------------------------------------------------
| alpha                              | 0.195    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.1     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.0329  |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.7     |
| timestep                           | 352000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2445
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.0583  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.8     |
| timestep                           | 353000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2434
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.00102 |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.5     |
| timestep                           | 354000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2428
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -589     |
| loss/alpha                         | 0.0372   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.3     |
| timestep                           | 355000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2482
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.6     |
| eval/normalized_episode_reward_std | 30.5     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.0417  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.4     |
| timestep                           | 356000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2654
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -589     |
| loss/alpha                         | -0.031   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.3     |
| timestep                           | 357000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2539
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -590     |
| loss/alpha                         | 0.0414   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.3     |
| timestep                           | 358000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2423
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -590     |
| loss/alpha                         | -0.007   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.5     |
| timestep                           | 359000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2646
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 7.94     |
| loss/actor                         | -591     |
| loss/alpha                         | -0.00845 |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.8     |
| timestep                           | 360000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2504
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -591     |
| loss/alpha                         | -0.0518  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.3     |
| timestep                           | 361000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2441
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -592     |
| loss/alpha                         | -0.0531  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.3     |
| timestep                           | 362000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2673
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -592     |
| loss/alpha                         | 0.0423   |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.5     |
| timestep                           | 363000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2509
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -593     |
| loss/alpha                         | 0.0409   |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20       |
| timestep                           | 364000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2592
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -594     |
| loss/alpha                         | -0.0273  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.2     |
| timestep                           | 365000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2228
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 46.6     |
| eval/normalized_episode_reward_std | 27       |
| loss/actor                         | -594     |
| loss/alpha                         | 0.0812   |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.6     |
| timestep                           | 366000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2092
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -594     |
| loss/alpha                         | 0.0441   |
| loss/critic1                       | 22.5     |
| loss/critic2                       | 22.1     |
| timestep                           | 367000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2653
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -594     |
| loss/alpha                         | -0.0501  |
| loss/critic1                       | 22.5     |
| loss/critic2                       | 22.1     |
| timestep                           | 368000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2519
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -594     |
| loss/alpha                         | -0.0178  |
| loss/critic1                       | 22.8     |
| loss/critic2                       | 22.6     |
| timestep                           | 369000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2678
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -593     |
| loss/alpha                         | -0.062   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.5     |
| timestep                           | 370000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2657
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -593     |
| loss/alpha                         | 0.0441   |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.5     |
| timestep                           | 371000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2644
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -593     |
| loss/alpha                         | -0.061   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.2     |
| timestep                           | 372000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2680
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.5     |
| eval/normalized_episode_reward_std | 29.4     |
| loss/actor                         | -594     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 18.9     |
| timestep                           | 373000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2544
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -594     |
| loss/alpha                         | 0.106    |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.1     |
| timestep                           | 374000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2655
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -595     |
| loss/alpha                         | -0.0769  |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.5     |
| timestep                           | 375000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2638
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.5     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -595     |
| loss/alpha                         | -0.00316 |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.2     |
| timestep                           | 376000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2560
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -595     |
| loss/alpha                         | 0.175    |
| loss/critic1                       | 23.4     |
| loss/critic2                       | 23       |
| timestep                           | 377000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2582
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -595     |
| loss/alpha                         | -0.0667  |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.3     |
| timestep                           | 378000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2525
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -595     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.8     |
| timestep                           | 379000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2735
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -595     |
| loss/alpha                         | 0.0142   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.1     |
| timestep                           | 380000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2618
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -596     |
| loss/alpha                         | -0.0313  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.7     |
| timestep                           | 381000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2462
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 24.5     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -596     |
| loss/alpha                         | -0.0866  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.6     |
| timestep                           | 382000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2396
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -597     |
| loss/alpha                         | 0.0477   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 19.8     |
| timestep                           | 383000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2403
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.68     |
| loss/actor                         | -597     |
| loss/alpha                         | -0.0361  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20       |
| timestep                           | 384000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2587
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -597     |
| loss/alpha                         | 0.058    |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.8     |
| timestep                           | 385000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2610
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.6     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -597     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.7     |
| timestep                           | 386000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2538
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -597     |
| loss/alpha                         | -0.0341  |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.9     |
| timestep                           | 387000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2689
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -598     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.5     |
| timestep                           | 388000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2512
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.3     |
| eval/normalized_episode_reward_std | 28.7     |
| loss/actor                         | -599     |
| loss/alpha                         | 0.0407   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.3     |
| timestep                           | 389000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2499
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -599     |
| loss/alpha                         | 0.0877   |
| loss/critic1                       | 21       |
| loss/critic2                       | 21       |
| timestep                           | 390000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2500
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -599     |
| loss/alpha                         | -0.0586  |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.9     |
| timestep                           | 391000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2377
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.5     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -600     |
| loss/alpha                         | 0.0368   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.5     |
| timestep                           | 392000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2566
----------------------------------------------------------------------------------
| alpha                              | 0.193    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -600     |
| loss/alpha                         | 0.107    |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.8     |
| timestep                           | 393000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2488
----------------------------------------------------------------------------------
| alpha                              | 0.196    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -600     |
| loss/alpha                         | 0.0472   |
| loss/critic1                       | 21.9     |
| loss/critic2                       | 21.8     |
| timestep                           | 394000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2571
----------------------------------------------------------------------------------
| alpha                              | 0.194    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 9.11     |
| loss/actor                         | -600     |
| loss/alpha                         | -0.0791  |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.7     |
| timestep                           | 395000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2458
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -601     |
| loss/alpha                         | -0.0123  |
| loss/critic1                       | 21.8     |
| loss/critic2                       | 21.6     |
| timestep                           | 396000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2583
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -601     |
| loss/alpha                         | 0.000738 |
| loss/critic1                       | 22.9     |
| loss/critic2                       | 22.8     |
| timestep                           | 397000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2602
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -601     |
| loss/alpha                         | -0.0418  |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.2     |
| timestep                           | 398000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2351
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -601     |
| loss/alpha                         | 0.0328   |
| loss/critic1                       | 22.3     |
| loss/critic2                       | 22.2     |
| timestep                           | 399000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2532
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65       |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -601     |
| loss/alpha                         | -0.00796 |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.2     |
| timestep                           | 400000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2565
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -602     |
| loss/alpha                         | -0.0424  |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 21.8     |
| timestep                           | 401000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2493
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -602     |
| loss/alpha                         | -0.00648 |
| loss/critic1                       | 22       |
| loss/critic2                       | 21.7     |
| timestep                           | 402000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2369
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.5     |
| eval/normalized_episode_reward_std | 26.2     |
| loss/actor                         | -602     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.1     |
| timestep                           | 403000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2427
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.8     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -603     |
| loss/alpha                         | 0.117    |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21.3     |
| timestep                           | 404000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2325
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -603     |
| loss/alpha                         | -0.0548  |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.3     |
| timestep                           | 405000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2607
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -602     |
| loss/alpha                         | 0.0262   |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.2     |
| timestep                           | 406000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2501
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | -603     |
| loss/alpha                         | -0.0263  |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.4     |
| timestep                           | 407000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2511
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -602     |
| loss/alpha                         | 0.0381   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.6     |
| timestep                           | 408000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2537
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 9.26     |
| loss/actor                         | -602     |
| loss/alpha                         | -0.0368  |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.9     |
| timestep                           | 409000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2701
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -603     |
| loss/alpha                         | -0.0936  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.5     |
| timestep                           | 410000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2587
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56       |
| eval/normalized_episode_reward_std | 28.8     |
| loss/actor                         | -603     |
| loss/alpha                         | 0.0666   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 411000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2362
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.2     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -603     |
| loss/alpha                         | -0.0743  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.1     |
| timestep                           | 412000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2373
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.00763  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.5     |
| timestep                           | 413000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2620
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 13.2     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.0361   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.4     |
| timestep                           | 414000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2635
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.0717   |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20.1     |
| timestep                           | 415000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2476
----------------------------------------------------------------------------------
| alpha                              | 0.192    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -604     |
| loss/alpha                         | 0.043    |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.4     |
| timestep                           | 416000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2499
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65       |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -605     |
| loss/alpha                         | -0.0697  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.9     |
| timestep                           | 417000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2434
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 2.58     |
| loss/actor                         | -605     |
| loss/alpha                         | 0.056    |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.6     |
| timestep                           | 418000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2644
----------------------------------------------------------------------------------
| alpha                              | 0.191    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -605     |
| loss/alpha                         | -0.0195  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 419000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2664
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 3.9      |
| loss/actor                         | -605     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.1     |
| timestep                           | 420000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2598
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -605     |
| loss/alpha                         | 0.0248   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.1     |
| timestep                           | 421000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2671
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -605     |
| loss/alpha                         | -0.125   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19       |
| timestep                           | 422000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2567
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 45       |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -605     |
| loss/alpha                         | -0.0262  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.1     |
| timestep                           | 423000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2544
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -605     |
| loss/alpha                         | 0.0594   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.8     |
| timestep                           | 424000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2467
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -605     |
| loss/alpha                         | 0.103    |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.1     |
| timestep                           | 425000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2542
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -605     |
| loss/alpha                         | 0.00298  |
| loss/critic1                       | 21.3     |
| loss/critic2                       | 21.2     |
| timestep                           | 426000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2586
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -605     |
| loss/alpha                         | -0.016   |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 21       |
| timestep                           | 427000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2571
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -605     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.7     |
| timestep                           | 428000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2663
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -605     |
| loss/alpha                         | -0.0556  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.5     |
| timestep                           | 429000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2422
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -606     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.3     |
| timestep                           | 430000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2440
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -606     |
| loss/alpha                         | 0.0253   |
| loss/critic1                       | 19       |
| loss/critic2                       | 19       |
| timestep                           | 431000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2383
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64       |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -607     |
| loss/alpha                         | 0.0455   |
| loss/critic1                       | 21.6     |
| loss/critic2                       | 21.4     |
| timestep                           | 432000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2482
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.9     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -607     |
| loss/alpha                         | -0.016   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.3     |
| timestep                           | 433000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2268
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -607     |
| loss/alpha                         | -0.00923 |
| loss/critic1                       | 21.2     |
| loss/critic2                       | 20.8     |
| timestep                           | 434000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2577
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -607     |
| loss/alpha                         | -0.0539  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.2     |
| timestep                           | 435000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2499
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -607     |
| loss/alpha                         | 0.0308   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20       |
| timestep                           | 436000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2367
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -607     |
| loss/alpha                         | -0.0121  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.2     |
| timestep                           | 437000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2529
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -607     |
| loss/alpha                         | 0.0276   |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.4     |
| timestep                           | 438000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2392
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.4     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -607     |
| loss/alpha                         | 0.0545   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.3     |
| timestep                           | 439000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2431
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 8.96     |
| loss/actor                         | -607     |
| loss/alpha                         | -0.00542 |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.4     |
| timestep                           | 440000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2402
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -607     |
| loss/alpha                         | 0.0442   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.7     |
| timestep                           | 441000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2372
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -608     |
| loss/alpha                         | -0.0451  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.2     |
| timestep                           | 442000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2423
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -608     |
| loss/alpha                         | -0.0846  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.3     |
| timestep                           | 443000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2394
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.4     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -608     |
| loss/alpha                         | 0.0323   |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.9     |
| timestep                           | 444000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2455
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60       |
| eval/normalized_episode_reward_std | 29.5     |
| loss/actor                         | -608     |
| loss/alpha                         | 0.0391   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.2     |
| timestep                           | 445000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2399
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -608     |
| loss/alpha                         | -0.0642  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.6     |
| timestep                           | 446000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2409
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -609     |
| loss/alpha                         | 0.0623   |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.9     |
| timestep                           | 447000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2529
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -609     |
| loss/alpha                         | 0.016    |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.2     |
| timestep                           | 448000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2442
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.3     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -609     |
| loss/alpha                         | 0.0132   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.4     |
| timestep                           | 449000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2540
----------------------------------------------------------------------------------
| alpha                              | 0.19     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -609     |
| loss/alpha                         | 0.000919 |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 20       |
| timestep                           | 450000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2412
----------------------------------------------------------------------------------
| alpha                              | 0.189    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.0447  |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.5     |
| timestep                           | 451000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2406
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.66     |
| loss/actor                         | -610     |
| loss/alpha                         | -0.0965  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.5     |
| timestep                           | 452000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2434
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55       |
| eval/normalized_episode_reward_std | 27.7     |
| loss/actor                         | -611     |
| loss/alpha                         | -0.00802 |
| loss/critic1                       | 19       |
| loss/critic2                       | 19       |
| timestep                           | 453000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2568
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0332   |
| loss/critic1                       | 22.1     |
| loss/critic2                       | 22       |
| timestep                           | 454000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2496
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.5     |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0352   |
| loss/critic1                       | 21.4     |
| loss/critic2                       | 21       |
| timestep                           | 455000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2409
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0126   |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.7     |
| timestep                           | 456000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2476
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 2.54     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0399   |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.2     |
| timestep                           | 457000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2410
----------------------------------------------------------------------------------
| alpha                              | 0.188    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 4.45     |
| loss/actor                         | -611     |
| loss/alpha                         | -0.00762 |
| loss/critic1                       | 21.5     |
| loss/critic2                       | 21.2     |
| timestep                           | 458000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2371
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.5     |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -611     |
| loss/alpha                         | -0.064   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.4     |
| timestep                           | 459000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2480
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -611     |
| loss/alpha                         | 0.0651   |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.6     |
| timestep                           | 460000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2490
----------------------------------------------------------------------------------
| alpha                              | 0.186    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 9.79     |
| loss/actor                         | -611     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.9     |
| timestep                           | 461000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2551
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 35.5     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.0286  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.7     |
| timestep                           | 462000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2421
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.00618 |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.6     |
| timestep                           | 463000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2433
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -612     |
| loss/alpha                         | 0.000336 |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 21       |
| timestep                           | 464000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2563
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 9.09     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.0116  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.3     |
| timestep                           | 465000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2468
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -612     |
| loss/alpha                         | 0.0214   |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.6     |
| timestep                           | 466000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2576
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.00871 |
| loss/critic1                       | 21.7     |
| loss/critic2                       | 21.4     |
| timestep                           | 467000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2566
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.4     |
| timestep                           | 468000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2516
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.0547  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 469000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2440
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.0229  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 470000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2453
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -613     |
| loss/alpha                         | 0.027    |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 471000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2361
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -612     |
| loss/alpha                         | -0.00701 |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 472000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2537
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -613     |
| loss/alpha                         | -0.00443 |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 473000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2520
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -613     |
| loss/alpha                         | 0.0152   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.6     |
| timestep                           | 474000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2521
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 8.35     |
| loss/actor                         | -613     |
| loss/alpha                         | 0.00228  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20       |
| timestep                           | 475000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2426
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -614     |
| loss/alpha                         | 0.000574 |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.2     |
| timestep                           | 476000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2366
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65       |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -614     |
| loss/alpha                         | -0.00947 |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.8     |
| timestep                           | 477000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2559
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.1     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -614     |
| loss/alpha                         | 0.00524  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.9     |
| timestep                           | 478000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2484
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.00352  |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.7     |
| timestep                           | 479000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2660
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.1     |
| eval/normalized_episode_reward_std | 27.9     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.0639  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.2     |
| timestep                           | 480000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2490
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.0588   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 481000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2424
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.00715 |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.6     |
| timestep                           | 482000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2447
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -614     |
| loss/alpha                         | 0.00641  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 483000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2670
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.0695   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.4     |
| timestep                           | 484000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2320
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -615     |
| loss/alpha                         | 0.00976  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.1     |
| timestep                           | 485000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2449
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.5     |
| eval/normalized_episode_reward_std | 26.5     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.104    |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20.1     |
| timestep                           | 486000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2717
----------------------------------------------------------------------------------
| alpha                              | 0.187    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.0347  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.1     |
| timestep                           | 487000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2657
----------------------------------------------------------------------------------
| alpha                              | 0.185    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 4.2      |
| loss/actor                         | -615     |
| loss/alpha                         | -0.0783  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.2     |
| timestep                           | 488000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2443
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.4     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.00561 |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.5     |
| timestep                           | 489000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2551
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.4     |
| eval/normalized_episode_reward_std | 27.4     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.025    |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20       |
| timestep                           | 490000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2525
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -615     |
| loss/alpha                         | 0.0102   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19       |
| timestep                           | 491000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2499
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -614     |
| loss/alpha                         | -0.0533  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.6     |
| timestep                           | 492000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2637
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 7.09     |
| loss/actor                         | -614     |
| loss/alpha                         | -0.0171  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.5     |
| timestep                           | 493000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2498
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -614     |
| loss/alpha                         | -0.116   |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.4     |
| timestep                           | 494000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2351
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -614     |
| loss/alpha                         | -0.0225  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.6     |
| timestep                           | 495000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2405
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -614     |
| loss/alpha                         | 0.0125   |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 496000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2482
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.53     |
| loss/actor                         | -614     |
| loss/alpha                         | 0.0414   |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.8     |
| timestep                           | 497000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2361
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -614     |
| loss/alpha                         | -0.0353  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.8     |
| timestep                           | 498000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2462
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.132    |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20       |
| timestep                           | 499000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2452
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.0423   |
| loss/critic1                       | 20.7     |
| loss/critic2                       | 20.6     |
| timestep                           | 500000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2639
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.0135  |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.9     |
| timestep                           | 501000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2596
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.0162   |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.3     |
| timestep                           | 502000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2529
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.0462  |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.7     |
| timestep                           | 503000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2628
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -615     |
| loss/alpha                         | -0.0124  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.9     |
| timestep                           | 504000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2472
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 7.41     |
| loss/actor                         | -615     |
| loss/alpha                         | 0.0428   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.1     |
| timestep                           | 505000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2408
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -616     |
| loss/alpha                         | -0.0573  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.4     |
| timestep                           | 506000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2591
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.1     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -616     |
| loss/alpha                         | 0.0421   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.8     |
| timestep                           | 507000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2302
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.6     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -616     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.7     |
| timestep                           | 508000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2483
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -617     |
| loss/alpha                         | -0.0689  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 509000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2620
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -617     |
| loss/alpha                         | 0.0133   |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.4     |
| timestep                           | 510000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2396
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.3     |
| eval/normalized_episode_reward_std | 27       |
| loss/actor                         | -617     |
| loss/alpha                         | -0.0394  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 511000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2535
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -618     |
| loss/alpha                         | 0.0989   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 512000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2427
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.2     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0357  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.5     |
| timestep                           | 513000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2501
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0554  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 514000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2536
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0513  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.5     |
| timestep                           | 515000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2499
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -618     |
| loss/alpha                         | 0.00736  |
| loss/critic1                       | 19       |
| loss/critic2                       | 19       |
| timestep                           | 516000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2467
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 7.44     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0147  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 517000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2566
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.5     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0758  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.1     |
| timestep                           | 518000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2443
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -618     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 519000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2542
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -618     |
| loss/alpha                         | 0.0496   |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 520000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2404
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0465  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.3     |
| timestep                           | 521000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2524
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 8.82     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.00878 |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 522000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2559
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0487  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 523000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2518
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0201  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.1     |
| timestep                           | 524000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2521
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.00489 |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.3     |
| timestep                           | 525000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2620
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0137  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.5     |
| timestep                           | 526000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2554
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.4     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -618     |
| loss/alpha                         | 0.0645   |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.5     |
| timestep                           | 527000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2671
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 11.9     |
| loss/actor                         | -618     |
| loss/alpha                         | 0.045    |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20       |
| timestep                           | 528000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2593
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -618     |
| loss/alpha                         | -0.0223  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.4     |
| timestep                           | 529000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2496
-----------------------------------------------------------------------------------
| alpha                              | 0.179     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 66.9      |
| eval/normalized_episode_reward_std | 19.7      |
| loss/actor                         | -619      |
| loss/alpha                         | -0.000454 |
| loss/critic1                       | 19.9      |
| loss/critic2                       | 19.8      |
| timestep                           | 530000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2521
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0246  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.1     |
| timestep                           | 531000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2684
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0975   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 532000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2470
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 5.38     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0712  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.1     |
| timestep                           | 533000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2316
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0321  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.7     |
| timestep                           | 534000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2425
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0617   |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.8     |
| timestep                           | 535000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2639
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 7.24     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0394  |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.2     |
| timestep                           | 536000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2650
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.2      |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20       |
| timestep                           | 537000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2610
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0277   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.2     |
| timestep                           | 538000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2594
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.2     |
| eval/normalized_episode_reward_std | 26.4     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0543  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.4     |
| timestep                           | 539000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2561
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.00627  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.5     |
| timestep                           | 540000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2468
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 9.2      |
| loss/actor                         | -619     |
| loss/alpha                         | 0.082    |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.4     |
| timestep                           | 541000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2494
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0314   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.2     |
| timestep                           | 542000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2516
----------------------------------------------------------------------------------
| alpha                              | 0.184    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0179   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20.2     |
| timestep                           | 543000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2549
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.58     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0482  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.5     |
| timestep                           | 544000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2534
----------------------------------------------------------------------------------
| alpha                              | 0.183    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.00692  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.4     |
| timestep                           | 545000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2667
----------------------------------------------------------------------------------
| alpha                              | 0.182    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -620     |
| loss/alpha                         | -0.079   |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.2     |
| timestep                           | 546000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2516
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0521  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 547000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2547
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.00884 |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 21       |
| timestep                           | 548000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2331
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0426  |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 21       |
| timestep                           | 549000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2650
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60       |
| eval/normalized_episode_reward_std | 27.1     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0135  |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.3     |
| timestep                           | 550000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2571
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.5     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.033    |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.3     |
| timestep                           | 551000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2505
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.7     |
| timestep                           | 552000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2690
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0194  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.8     |
| timestep                           | 553000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2498
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -619     |
| loss/alpha                         | 0.0347   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 554000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2337
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0236   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 555000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2566
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0411  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.2     |
| timestep                           | 556000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2594
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.9     |
| eval/normalized_episode_reward_std | 32       |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0217  |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.8     |
| timestep                           | 557000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2482
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0614   |
| loss/critic1                       | 21.1     |
| loss/critic2                       | 20.9     |
| timestep                           | 558000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2588
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0146   |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.2     |
| timestep                           | 559000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2583
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0136   |
| loss/critic1                       | 21       |
| loss/critic2                       | 20.7     |
| timestep                           | 560000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2760
----------------------------------------------------------------------------------
| alpha                              | 0.18     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0527  |
| loss/critic1                       | 20.9     |
| loss/critic2                       | 20.7     |
| timestep                           | 561000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2669
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -619     |
| loss/alpha                         | -0.0593  |
| loss/critic1                       | 20.3     |
| loss/critic2                       | 20.2     |
| timestep                           | 562000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2499
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 5.77     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0793  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 563000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2724
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.3     |
| eval/normalized_episode_reward_std | 27.8     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0226   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 564000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2669
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -621     |
| loss/alpha                         | 0.155    |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.6     |
| timestep                           | 565000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2522
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0433   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.9     |
| timestep                           | 566000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2557
----------------------------------------------------------------------------------
| alpha                              | 0.181    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0548  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.6     |
| timestep                           | 567000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2838
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.046   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.4     |
| timestep                           | 568000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2568
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.016    |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 569000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2511
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -620     |
| loss/alpha                         | 0.0071   |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 20       |
| timestep                           | 570000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2436
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -620     |
| loss/alpha                         | -0.0734  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 571000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2731
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.1     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -621     |
| loss/alpha                         | -0.0323  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.6     |
| timestep                           | 572000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2715
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -621     |
| loss/alpha                         | 0.000391 |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 573000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2842
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -621     |
| loss/alpha                         | -0.0758  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.7     |
| timestep                           | 574000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2653
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -621     |
| loss/alpha                         | -0.105   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.4     |
| timestep                           | 575000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2629
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -621     |
| loss/alpha                         | -0.00925 |
| loss/critic1                       | 19.6     |
| loss/critic2                       | 19.3     |
| timestep                           | 576000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2644
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -621     |
| loss/alpha                         | 0.175    |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.4     |
| timestep                           | 577000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2757
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -622     |
| loss/alpha                         | 0.0747   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 578000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2657
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -622     |
| loss/alpha                         | 0.0112   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 579000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2604
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -622     |
| loss/alpha                         | 0.000361 |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.3     |
| timestep                           | 580000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2651
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 5.4      |
| loss/actor                         | -622     |
| loss/alpha                         | -0.0849  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.4     |
| timestep                           | 581000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2433
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.69     |
| loss/actor                         | -623     |
| loss/alpha                         | -0.0561  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.1     |
| timestep                           | 582000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2704
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -623     |
| loss/alpha                         | 0.0305   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 583000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2424
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -624     |
| loss/alpha                         | -0.0327  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 584000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2446
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -624     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.8     |
| timestep                           | 585000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2532
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -625     |
| loss/alpha                         | 0.00495  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.9     |
| timestep                           | 586000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2578
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -625     |
| loss/alpha                         | -0.056   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 587000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2445
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -625     |
| loss/alpha                         | 0.0531   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.5     |
| timestep                           | 588000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2681
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0454  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.7     |
| timestep                           | 589000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2579
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0567  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 590000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2617
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0668  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.3     |
| timestep                           | 591000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2776
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -626     |
| loss/alpha                         | -0.0452  |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 592000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2790
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -627     |
| loss/alpha                         | -0.00836 |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 593000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2633
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -627     |
| loss/alpha                         | 0.0122   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.8     |
| timestep                           | 594000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2565
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -627     |
| loss/alpha                         | 0.0191   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 595000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2597
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.023    |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.6     |
| timestep                           | 596000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2683
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.0226   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 597000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2612
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.0623   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.8     |
| timestep                           | 598000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2569
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.00121  |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.1     |
| timestep                           | 599000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2672
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.0291   |
| loss/critic1                       | 20       |
| loss/critic2                       | 19.8     |
| timestep                           | 600000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2471
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.0206   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 601000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2587
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.48     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.7     |
| timestep                           | 602000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2534
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -629     |
| loss/alpha                         | 0.062    |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.6     |
| timestep                           | 603000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2598
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0384  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 604000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2479
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 5.16     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0162  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.3     |
| timestep                           | 605000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2783
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.1      |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 606000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2552
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 6.52     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.044   |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 607000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2597
----------------------------------------------------------------------------------
| alpha                              | 0.179    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0389   |
| loss/critic1                       | 20.6     |
| loss/critic2                       | 20.4     |
| timestep                           | 608000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2489
----------------------------------------------------------------------------------
| alpha                              | 0.178    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 7.33     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0699  |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.9     |
| timestep                           | 609000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2366
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 6.77     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0371   |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.5     |
| timestep                           | 610000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2656
----------------------------------------------------------------------------------
| alpha                              | 0.177    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -629     |
| loss/alpha                         | -0.059   |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.7     |
| timestep                           | 611000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2597
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.8     |
| timestep                           | 612000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2777
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0283  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.3     |
| timestep                           | 613000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2669
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0437   |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 19.9     |
| timestep                           | 614000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0296   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.2     |
| timestep                           | 615000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2580
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.019   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 616000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2580
----------------------------------------------------------------------------------
| alpha                              | 0.176    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 2.64     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.00565 |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 617000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2658
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0301  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.5     |
| timestep                           | 618000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2559
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0403  |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 619000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2593
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0694  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 620000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2780
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.0474   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18       |
| timestep                           | 621000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2573
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0063  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 622000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2573
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.000534 |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 623000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2806
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -628     |
| loss/alpha                         | -0.00893 |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 624000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2650
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0322  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.4     |
| timestep                           | 625000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2567
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.00597  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.5     |
| timestep                           | 626000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2630
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.00627 |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.1     |
| timestep                           | 627000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2563
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -627     |
| loss/alpha                         | -0.0636  |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.7     |
| timestep                           | 628000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2566
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -627     |
| loss/alpha                         | 0.0751   |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 629000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2516
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 7.2      |
| loss/actor                         | -627     |
| loss/alpha                         | -0.0302  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 630000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2632
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.0227   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.6     |
| timestep                           | 631000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2720
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0193  |
| loss/critic1                       | 19       |
| loss/critic2                       | 19       |
| timestep                           | 632000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2620
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61       |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.017   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 633000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2735
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0416  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 634000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2774
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 26.3     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0129  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 635000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2594
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.7     |
| eval/normalized_episode_reward_std | 26.3     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.0538   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.5     |
| timestep                           | 636000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2611
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0363  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.3     |
| timestep                           | 637000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2630
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.7     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0224   |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.9     |
| timestep                           | 638000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2597
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.115    |
| loss/critic1                       | 19.9     |
| loss/critic2                       | 19.7     |
| timestep                           | 639000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2515
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.8     |
| timestep                           | 640000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2575
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0594  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 641000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2663
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0717  |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.1     |
| timestep                           | 642000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2498
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 5.37     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0149  |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.4     |
| timestep                           | 643000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2611
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -628     |
| loss/alpha                         | 0.0892   |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.4     |
| timestep                           | 644000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2680
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0163  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 645000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2622
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -629     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.6     |
| timestep                           | 646000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2460
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 7.16     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0343   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.3     |
| timestep                           | 647000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2709
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0269   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.8     |
| timestep                           | 648000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2570
----------------------------------------------------------------------------------
| alpha                              | 0.174    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0238   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.2     |
| timestep                           | 649000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2715
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0903  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.1     |
| timestep                           | 650000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2756
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0551  |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19       |
| timestep                           | 651000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2623
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0832   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.4     |
| timestep                           | 652000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2610
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.063    |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 653000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2546
----------------------------------------------------------------------------------
| alpha                              | 0.175    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.00615 |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.4     |
| timestep                           | 654000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2669
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0854  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 655000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2718
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0608  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 656000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2677
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 657000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2607
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.098   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.7     |
| timestep                           | 658000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2530
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 2.85     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0189   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 659000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2606
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0105   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 660000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2594
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.00326 |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 661000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2627
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0912   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 662000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2595
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0648   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 663000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2658
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.00283 |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.5     |
| timestep                           | 664000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2787
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0111  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.1     |
| timestep                           | 665000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2670
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0188  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.7     |
| timestep                           | 666000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2538
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0275  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 667000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2577
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0708   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 668000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2533
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.00631  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 669000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2666
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 2.81     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0995  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 670000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2712
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.9     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0767   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 671000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2650
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 8.2      |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0208  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18       |
| timestep                           | 672000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2708
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0214  |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 673000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2428
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0972   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.4     |
| timestep                           | 674000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2593
----------------------------------------------------------------------------------
| alpha                              | 0.173    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0156   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.8     |
| timestep                           | 675000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2481
----------------------------------------------------------------------------------
| alpha                              | 0.172    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0693  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.8     |
| timestep                           | 676000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2665
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0888  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 677000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2527
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 3.78     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.107   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 678000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2421
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.84     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0131   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 679000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2674
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0709   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 680000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2740
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0115  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 681000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2680
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0786   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 682000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2533
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0308   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.4     |
| timestep                           | 683000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2621
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0395   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18       |
| timestep                           | 684000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2644
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0447  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.6     |
| timestep                           | 685000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2600
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0129  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 686000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2631
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0263  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.1     |
| timestep                           | 687000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2674
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.00442 |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 688000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2653
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 9.77     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0126   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.1     |
| timestep                           | 689000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2738
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 32.1     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0384  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 690000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2415
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.114    |
| loss/critic1                       | 22.4     |
| loss/critic2                       | 22.4     |
| timestep                           | 691000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2541
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0322  |
| loss/critic1                       | 20.5     |
| loss/critic2                       | 20.5     |
| timestep                           | 692000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2661
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0301   |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.8     |
| timestep                           | 693000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2721
-----------------------------------------------------------------------------------
| alpha                              | 0.171     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 70        |
| eval/normalized_episode_reward_std | 3.11      |
| loss/actor                         | -629      |
| loss/alpha                         | -0.000322 |
| loss/critic1                       | 20.4      |
| loss/critic2                       | 20.3      |
| timestep                           | 694000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2529
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -628     |
| loss/alpha                         | -0.0205  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20       |
| timestep                           | 695000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2576
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 4.61     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0537  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 696000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2691
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0118   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 697000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2603
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0462  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 698000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2720
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0621   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 699000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2638
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.8     |
| eval/normalized_episode_reward_std | 31.7     |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0424  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.4     |
| timestep                           | 700000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2704
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -629     |
| loss/alpha                         | -0.0427  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.7     |
| timestep                           | 701000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2657
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 2.79     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0106   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 702000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2742
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.9      |
| loss/actor                         | -629     |
| loss/alpha                         | -0.152   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 703000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2578
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -629     |
| loss/alpha                         | 0.0841   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 704000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2767
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0259   |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 705000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2697
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0645  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 706000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2724
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.5     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0431   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 707000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2539
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0467   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 708000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2574
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0647   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 709000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2745
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 2.66     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0158  |
| loss/critic1                       | 20.2     |
| loss/critic2                       | 20       |
| timestep                           | 710000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2587
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 8.46     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.00282  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 711000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2701
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0878  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 712000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2721
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -630     |
| loss/alpha                         | 0.04     |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 713000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2680
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -630     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.8     |
| timestep                           | 714000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -630     |
| loss/alpha                         | 0.0325   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 715000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2557
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0385  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 716000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2743
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.00524 |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 717000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2507
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.058    |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.1     |
| timestep                           | 718000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2713
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -631     |
| loss/alpha                         | -0.00909 |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 719000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0931  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 720000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2643
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0426   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 721000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2716
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0305  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 722000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2645
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -631     |
| loss/alpha                         | 0.00357  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 723000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2711
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.57     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.00418 |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 724000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0596   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 725000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2571
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0151  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18       |
| timestep                           | 726000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2700
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.00574  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.3     |
| timestep                           | 727000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2662
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0161  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 728000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2534
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0469  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 729000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2781
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.0198   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 730000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2677
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.0275   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.5     |
| timestep                           | 731000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2581
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0796  |
| loss/critic1                       | 19       |
| loss/critic2                       | 19.1     |
| timestep                           | 732000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0288  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 733000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2758
-----------------------------------------------------------------------------------
| alpha                              | 0.163     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 77.8      |
| eval/normalized_episode_reward_std | 3.03      |
| loss/actor                         | -632      |
| loss/alpha                         | -0.000354 |
| loss/critic1                       | 16.9      |
| loss/critic2                       | 16.9      |
| timestep                           | 734000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2833
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0206  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.3     |
| timestep                           | 735000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2718
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.2     |
| eval/normalized_episode_reward_std | 29.7     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.054   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.9     |
| timestep                           | 736000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2617
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.0222   |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 737000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2818
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0105  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 738000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2723
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.0599   |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.5     |
| timestep                           | 739000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2570
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.1      |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.6     |
| timestep                           | 740000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2571
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 4.87     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.0142   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.3     |
| timestep                           | 741000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2604
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0227   |
| loss/critic1                       | 19.2     |
| loss/critic2                       | 19.2     |
| timestep                           | 742000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2594
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0277  |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.4     |
| timestep                           | 743000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2705
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0329   |
| loss/critic1                       | 19.7     |
| loss/critic2                       | 19.7     |
| timestep                           | 744000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2679
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0768  |
| loss/critic1                       | 19       |
| loss/critic2                       | 19       |
| timestep                           | 745000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2599
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 5.11     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0639  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.8     |
| timestep                           | 746000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2661
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0946  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 747000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2507
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 6.9      |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 748000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2664
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.9     |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0616   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 749000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2633
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.0325   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.4     |
| timestep                           | 750000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2668
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0502   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 751000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2619
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0714   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 752000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2722
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0205  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 753000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2665
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0237  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 754000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 3.74     |
| loss/actor                         | -631     |
| loss/alpha                         | 0.0797   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 755000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2617
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -631     |
| loss/alpha                         | -0.0545  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 756000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2755
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0194  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 757000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2461
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.0202   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 758000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2524
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 8.83     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0395  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 759000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2756
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.163   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 760000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2691
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.0546   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 761000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2702
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0186  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 17.9     |
| timestep                           | 762000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2761
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 8.23     |
| loss/actor                         | -632     |
| loss/alpha                         | 0.0677   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 763000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2727
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -632     |
| loss/alpha                         | -0.0181  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 764000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2517
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.122    |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 765000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2690
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0212   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.6     |
| timestep                           | 766000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2706
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.93     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0118   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 767000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2668
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0634  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 768000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2603
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0795   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.4     |
| timestep                           | 769000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2630
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0603  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.4     |
| timestep                           | 770000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2792
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -633     |
| loss/alpha                         | -0.00915 |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 771000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2730
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -633     |
| loss/alpha                         | -0.0243  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 772000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2768
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -633     |
| loss/alpha                         | 0.0118   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 773000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2646
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.081   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 774000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2938
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -634     |
| loss/alpha                         | -0.0334  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 775000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2607
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.7     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -634     |
| loss/alpha                         | 0.0528   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 776000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2771
-----------------------------------------------------------------------------------
| alpha                              | 0.163     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 68.5      |
| eval/normalized_episode_reward_std | 2.8       |
| loss/actor                         | -634      |
| loss/alpha                         | -0.000662 |
| loss/critic1                       | 17.9      |
| loss/critic2                       | 17.9      |
| timestep                           | 777000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2681
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 10       |
| loss/actor                         | -635     |
| loss/alpha                         | -0.0297  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 778000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2571
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -635     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.6     |
| timestep                           | 779000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2623
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -635     |
| loss/alpha                         | 0.0141   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.8     |
| timestep                           | 780000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2650
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -635     |
| loss/alpha                         | -0.0281  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 781000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2590
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 7.3      |
| loss/actor                         | -635     |
| loss/alpha                         | 0.0524   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 782000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2706
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.0165   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 783000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2669
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -635     |
| loss/alpha                         | 0.00361  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 784000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2588
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.89     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.00613 |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.8     |
| timestep                           | 785000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2756
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.00518 |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 786000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.000759 |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 787000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2683
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 5.47     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.00951  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 788000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2717
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 8.29     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.11    |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 789000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2689
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.0264  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 790000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2709
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.0218  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 791000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2685
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.77     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.0345   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 792000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2820
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.00778 |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 793000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2724
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.0333  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 794000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2575
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.0497   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 795000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2761
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 6.92     |
| loss/actor                         | -636     |
| loss/alpha                         | 0.0383   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 796000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2566
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0229  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 797000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2501
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0207   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.5     |
| timestep                           | 798000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2594
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.00356 |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.3     |
| timestep                           | 799000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2689
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0642   |
| loss/critic1                       | 19.3     |
| loss/critic2                       | 19.3     |
| timestep                           | 800000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2702
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0554  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.9     |
| timestep                           | 801000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2631
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 6.61     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0432   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 802000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2718
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.0252  |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 18.9     |
| timestep                           | 803000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2598
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.2     |
| eval/normalized_episode_reward_std | 26.7     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.0224  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 804000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2798
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0789   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 805000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2678
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0239  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 806000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2741
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0656   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 807000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0842  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.2     |
| timestep                           | 808000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2654
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0306  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 809000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2628
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.031    |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 810000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2736
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0259   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.8     |
| timestep                           | 811000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2711
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0354   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 812000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2723
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -636     |
| loss/alpha                         | -0.0551  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 813000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2681
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -637     |
| loss/alpha                         | 0.107    |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.3     |
| timestep                           | 814000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2744
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 10       |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0399  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 815000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2663
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 9.56     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0188   |
| loss/critic1                       | 19       |
| loss/critic2                       | 19       |
| timestep                           | 816000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2517
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.2     |
| eval/normalized_episode_reward_std | 30.2     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0588   |
| loss/critic1                       | 20.1     |
| loss/critic2                       | 19.8     |
| timestep                           | 817000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2580
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0708  |
| loss/critic1                       | 20.4     |
| loss/critic2                       | 20.3     |
| timestep                           | 818000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2807
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 9.04     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.00946 |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 819000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2785
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.00582 |
| loss/critic1                       | 19.8     |
| loss/critic2                       | 19.8     |
| timestep                           | 820000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2741
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0443  |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.3     |
| timestep                           | 821000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2731
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0565  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 822000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2679
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0227  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 823000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2727
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -638     |
| loss/alpha                         | -0.0319  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 824000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2713
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -638     |
| loss/alpha                         | -0.0114  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 825000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2582
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.6     |
| eval/normalized_episode_reward_std | 28       |
| loss/actor                         | -638     |
| loss/alpha                         | -0.0017  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 826000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2591
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.9      |
| loss/actor                         | -638     |
| loss/alpha                         | 0.0944   |
| loss/critic1                       | 19.4     |
| loss/critic2                       | 19.3     |
| timestep                           | 827000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2676
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -638     |
| loss/alpha                         | -0.052   |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 828000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2746
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -638     |
| loss/alpha                         | 0.00833  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18       |
| timestep                           | 829000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2612
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.8     |
| eval/normalized_episode_reward_std | 27.9     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.038    |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.8     |
| timestep                           | 830000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2748
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -637     |
| loss/alpha                         | 0.0411   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 831000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2617
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -637     |
| loss/alpha                         | -0.0713  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.7     |
| timestep                           | 832000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -638     |
| loss/alpha                         | -0.0945  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 833000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -638     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 834000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2581
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 26.2     |
| loss/actor                         | -638     |
| loss/alpha                         | 0.0282   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 835000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2620
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -638     |
| loss/alpha                         | -0.0598  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 836000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2701
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -638     |
| loss/alpha                         | 0.0333   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.8     |
| timestep                           | 837000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2674
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0193  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 838000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2668
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0324   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 839000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2586
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0785   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 840000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2520
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -639     |
| loss/alpha                         | 0.0171   |
| loss/critic1                       | 18.5     |
| loss/critic2                       | 18.5     |
| timestep                           | 841000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2497
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0223  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 842000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2614
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.0423  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.5     |
| timestep                           | 843000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2607
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.072    |
| loss/critic1                       | 20.8     |
| loss/critic2                       | 20.8     |
| timestep                           | 844000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2805
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0231  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.1     |
| timestep                           | 845000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2483
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -639     |
| loss/alpha                         | -0.126   |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.9     |
| timestep                           | 846000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2603
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 5.86     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0503  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 847000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2641
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.75     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.1     |
| timestep                           | 848000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2744
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.0278   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 849000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2748
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -640     |
| loss/alpha                         | -0.0211  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 850000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2841
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -640     |
| loss/alpha                         | 0.00786  |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 851000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2915
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 852000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2617
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 4.56     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.00546 |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 853000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2753
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.00418 |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.8     |
| timestep                           | 854000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2731
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0162   |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 855000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2724
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0993   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 856000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2660
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.07     |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.7     |
| timestep                           | 857000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2661
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 4.52     |
| loss/actor                         | -641     |
| loss/alpha                         | -0.0204  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 858000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2703
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.00926  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 859000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2610
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -641     |
| loss/alpha                         | 0.0276   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 860000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2709
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0564  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 861000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2735
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0128   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 862000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2521
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 26.6     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0135  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 863000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2845
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0451  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 864000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2665
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.7     |
| eval/normalized_episode_reward_std | 27.3     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.123   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 865000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2804
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0108   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 866000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.00674 |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17       |
| timestep                           | 867000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2812
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0143   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 868000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2693
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.2     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -642     |
| loss/alpha                         | 0.0757   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 869000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2904
-----------------------------------------------------------------------------------
| alpha                              | 0.165     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 72.2      |
| eval/normalized_episode_reward_std | 10.7      |
| loss/actor                         | -643      |
| loss/alpha                         | -0.000624 |
| loss/critic1                       | 16.6      |
| loss/critic2                       | 16.4      |
| timestep                           | 870000    |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2772
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.00698  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 871000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2862
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0684  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 872000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2640
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0815   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 873000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2653
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0672  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.9     |
| timestep                           | 874000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2697
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0211  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 875000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2610
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 10.2     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 876000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2638
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 2.75     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.118    |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.7     |
| timestep                           | 877000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2592
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 4.06     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0495  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.7     |
| timestep                           | 878000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2789
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0382  |
| loss/critic1                       | 18.8     |
| loss/critic2                       | 18.6     |
| timestep                           | 879000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2806
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.8     |
| timestep                           | 880000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2689
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 5.09     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0851   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 881000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2704
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.00988 |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 882000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2651
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 883000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2776
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0576  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 884000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2798
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.2     |
| eval/normalized_episode_reward_std | 29.2     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0964   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 885000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2643
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0138  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 886000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 4.8      |
| loss/actor                         | -643     |
| loss/alpha                         | 0.1      |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.3     |
| timestep                           | 887000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2526
----------------------------------------------------------------------------------
| alpha                              | 0.171    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0527   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 888000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2692
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.12    |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 889000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2599
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 2.63     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0701  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 890000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2774
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 8.1      |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0171  |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 18       |
| timestep                           | 891000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2714
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0656   |
| loss/critic1                       | 18       |
| loss/critic2                       | 18.1     |
| timestep                           | 892000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2680
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0635  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.2     |
| timestep                           | 893000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2615
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 4.57     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0369   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 894000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2638
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0922   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.2     |
| timestep                           | 895000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2555
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 896000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2483
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0498  |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.7     |
| timestep                           | 897000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2677
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0452  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.4     |
| timestep                           | 898000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2726
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0635   |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18       |
| timestep                           | 899000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2739
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 2.87     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0152  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 900000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2657
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0169   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 901000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2567
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -642     |
| loss/alpha                         | -0.0395  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 902000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2591
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 4.01     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0607   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.4     |
| timestep                           | 903000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2860
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63       |
| eval/normalized_episode_reward_std | 24       |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0733  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.5     |
| timestep                           | 904000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2610
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.96     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 905000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2650
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0533   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 906000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2549
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.061    |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.9     |
| timestep                           | 907000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2774
----------------------------------------------------------------------------------
| alpha                              | 0.17     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.00394 |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.9     |
| timestep                           | 908000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2650
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0673  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.1     |
| timestep                           | 909000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2703
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 47       |
| eval/normalized_episode_reward_std | 30.1     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0114  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 910000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2713
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0402  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.3     |
| timestep                           | 911000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2729
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.00807  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 912000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2687
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0152  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.3     |
| timestep                           | 913000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2584
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0387  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 914000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2747
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0617   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 915000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2726
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0388   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.5     |
| timestep                           | 916000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2797
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0236   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 917000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2794
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 9.84     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.00722 |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.9     |
| timestep                           | 918000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2577
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0487  |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.1     |
| timestep                           | 919000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2723
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0485  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 920000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2444
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0703   |
| loss/critic1                       | 19.5     |
| loss/critic2                       | 19.5     |
| timestep                           | 921000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2711
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.115   |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.3     |
| timestep                           | 922000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2671
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.002    |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 923000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2764
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.8     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0239   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.9     |
| timestep                           | 924000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2683
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0307  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 925000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2592
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0467   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 926000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0276   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 927000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2783
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.017   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 928000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2805
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0143   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 929000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2882
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.00102  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 930000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.3     |
| eval/normalized_episode_reward_std | 28.5     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.5     |
| timestep                           | 931000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2642
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.084    |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 932000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2594
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 4.1      |
| loss/actor                         | -646     |
| loss/alpha                         | 0.00227  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 933000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2702
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.00714 |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 934000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2692
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0309   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 935000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2518
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.1     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 936000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2643
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 6.21     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0771  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.4     |
| timestep                           | 937000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2687
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 48.7     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0175  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 938000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2712
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 28.6     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0075   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 939000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2826
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.2     |
| eval/normalized_episode_reward_std | 27.1     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.00462 |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 940000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2655
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0148  |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 941000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2725
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.00506  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.5     |
| timestep                           | 942000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2640
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.97     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.024   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.5     |
| timestep                           | 943000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0344  |
| loss/critic1                       | 18.4     |
| loss/critic2                       | 18.2     |
| timestep                           | 944000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2794
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.00469  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 945000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2706
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0646   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 946000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2764
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 7.28     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.00161  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 947000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2612
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 3.85     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0372   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 948000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2748
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.128   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 949000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2732
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 5.14     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0419   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.4     |
| timestep                           | 950000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2785
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0755   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 951000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2799
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.00251  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.7     |
| timestep                           | 952000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0181   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 953000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2540
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0113   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 954000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2686
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0958  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 955000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2757
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60       |
| eval/normalized_episode_reward_std | 30.3     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0446  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 956000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2784
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0109   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 957000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2840
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0269  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 958000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2732
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0278  |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.1     |
| timestep                           | 959000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2794
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0529   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 960000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2715
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.00753  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 961000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2665
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 4.26     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0329   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 962000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2771
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0234   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 963000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2728
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0593   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 964000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2689
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.00468 |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 965000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2742
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.05     |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.3     |
| timestep                           | 966000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2796
----------------------------------------------------------------------------------
| alpha                              | 0.169    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0305  |
| loss/critic1                       | 18.6     |
| loss/critic2                       | 18.5     |
| timestep                           | 967000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2855
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 2.84     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0173  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 968000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.3     |
| eval/normalized_episode_reward_std | 25       |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0202  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.4     |
| timestep                           | 969000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2733
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 6.82     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.159   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 970000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2871
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0346  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 971000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2813
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0565   |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 972000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2637
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0827   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 973000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2806
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0662  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 974000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2750
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 2.73     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0303  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 975000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2845
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0213   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 976000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2701
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.00853  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 977000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2766
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0466   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 978000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2788
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0153   |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 979000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2808
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 8.16     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.00499  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 980000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2847
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.84     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.00833  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 981000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2718
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.00673 |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 982000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2689
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0126   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 983000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0277  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 984000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2819
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0376  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 985000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3043
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 8.3      |
| loss/actor                         | -644     |
| loss/alpha                         | 0.00998  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 986000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2908
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0105  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 987000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2809
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -644     |
| loss/alpha                         | -0.00494 |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 988000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2768
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0472   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 989000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2737
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.00151 |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 990000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2716
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0407  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 991000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2774
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 4.33     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.00776  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 992000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2798
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0279   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 993000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2858
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0633  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 994000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2689
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.052   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 995000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2797
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 996000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2764
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0305   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 997000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2825
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 2.71     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0269  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 998000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2758
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52.1     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.037    |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 999000   |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2830
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.4     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0314   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1000000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2709
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0077   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17       |
| timestep                           | 1001000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2807
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0329  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1002000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2800
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.1     |
| eval/normalized_episode_reward_std | 29.9     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0169   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 1003000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2669
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 8.35     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0824  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 1004000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2722
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0833   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1005000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2676
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 27.9     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0427  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1006000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 7.39     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0228  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 1007000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2882
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 4.09     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0897  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 1008000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2683
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.161    |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 1009000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2768
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0264  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 1010000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2682
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0508  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 1011000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2635
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0719   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 1012000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2659
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -643     |
| loss/alpha                         | 0.0729   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17       |
| timestep                           | 1013000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2669
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -643     |
| loss/alpha                         | -0.0426  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1014000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2676
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.4     |
| eval/normalized_episode_reward_std | 32.5     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0311  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.7     |
| timestep                           | 1015000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2780
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.8     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -644     |
| loss/alpha                         | -0.0667  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1016000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2717
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.0803   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 1017000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2761
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -644     |
| loss/alpha                         | 0.000216 |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 1018000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2686
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.83     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 1019000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2605
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 26.4     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0976   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 1020000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2567
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -645     |
| loss/alpha                         | -0.0215  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 1021000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2774
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.00552  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.5     |
| timestep                           | 1022000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2703
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.3     |
| eval/normalized_episode_reward_std | 27.3     |
| loss/actor                         | -645     |
| loss/alpha                         | 0.0336   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 1023000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2620
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.79     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0508   |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.1     |
| timestep                           | 1024000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2577
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.033   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 1025000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2669
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0212  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.5     |
| timestep                           | 1026000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2592
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0766  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 1027000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2653
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0774   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1028000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2666
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 6.11     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0442   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1029000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2579
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64       |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.00495  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.3     |
| timestep                           | 1030000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2786
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.113   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1031000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2580
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1032000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2877
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 5.15     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0769   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1033000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2723
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.2     |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.163   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1034000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2611
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.7     |
| eval/normalized_episode_reward_std | 27.8     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0361   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1035000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2667
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 5.58     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.0773   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1036000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2738
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.109    |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1037000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2710
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.1     |
| eval/normalized_episode_reward_std | 26.7     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0522  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 1038000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2816
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.00874 |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.6     |
| timestep                           | 1039000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2861
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 4.72     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0342   |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 1040000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2649
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0594  |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.4     |
| timestep                           | 1041000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2903
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0158  |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.8     |
| timestep                           | 1042000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2750
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.038    |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 1043000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2918
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0556  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 1044000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2552
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 30.3     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0466  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1045000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2796
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.00772 |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 1046000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2894
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.00146 |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 1047000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2872
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0344   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 1048000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2789
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60       |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.029   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1049000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2714
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0728   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1050000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2917
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0335   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1051000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2814
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0311   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1052000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2700
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0768   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 1053000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2664
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0743  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1054000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2556
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0079   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17       |
| timestep                           | 1055000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2801
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.00757 |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.3     |
| timestep                           | 1056000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2667
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.00667 |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1057000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3015
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0313  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1058000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2766
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0458  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1059000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2880
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0156  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1060000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2680
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 9.77     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.00177  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1061000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2901
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0222   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1062000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2824
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0536   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1063000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2847
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 6.32     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0157  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1064000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 5.98     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.041   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1065000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2676
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51       |
| eval/normalized_episode_reward_std | 29.9     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.018    |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.2     |
| timestep                           | 1066000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2850
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.9     |
| timestep                           | 1067000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2712
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0135  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1068000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2675
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.123   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.4     |
| timestep                           | 1069000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2750
-----------------------------------------------------------------------------------
| alpha                              | 0.16      |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 59.7      |
| eval/normalized_episode_reward_std | 22.7      |
| loss/actor                         | -650      |
| loss/alpha                         | -0.000924 |
| loss/critic1                       | 15.7      |
| loss/critic2                       | 15.7      |
| timestep                           | 1070000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2831
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.098    |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1071000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2792
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.9     |
| eval/normalized_episode_reward_std | 29.2     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.018    |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1072000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2715
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 10       |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0552   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1073000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2543
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.9     |
| eval/normalized_episode_reward_std | 30.1     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0158  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 1074000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2766
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 46.2     |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0131  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.3     |
| timestep                           | 1075000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2615
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0144  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1076000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2834
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 9.27     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0375   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.5     |
| timestep                           | 1077000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2689
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.00558 |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 1078000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2771
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58       |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.00182 |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1079000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2641
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 5.22     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.00469  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1080000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2893
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0626  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 1081000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2728
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 6.71     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0208  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1082000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2822
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 28.9     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0488   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.2     |
| timestep                           | 1083000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2733
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 8.39     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0999  |
| loss/critic1                       | 17       |
| loss/critic2                       | 17.1     |
| timestep                           | 1084000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2700
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0868   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1085000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2742
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.7     |
| eval/normalized_episode_reward_std | 27.7     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0376   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1086000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2751
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.00807 |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1087000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2764
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -650     |
| loss/alpha                         | -0.00266 |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 1088000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2710
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.02    |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 1089000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2616
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0899   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 1090000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.6     |
| eval/normalized_episode_reward_std | 27.8     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.00303 |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 1091000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2759
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 4.7      |
| loss/actor                         | -650     |
| loss/alpha                         | -0.00868 |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1092000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2701
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0606  |
| loss/critic1                       | 18.1     |
| loss/critic2                       | 18.2     |
| timestep                           | 1093000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2668
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.0214  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 1094000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2708
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 9.41     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.093   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 1095000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2819
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.00478 |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 1096000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2800
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0307   |
| loss/critic1                       | 18.9     |
| loss/critic2                       | 18.7     |
| timestep                           | 1097000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2805
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0442   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.6     |
| timestep                           | 1098000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2823
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -649     |
| loss/alpha                         | 0.042    |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1099000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2709
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0528   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.1     |
| timestep                           | 1100000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2703
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.00662  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 1101000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.4     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0308  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1102000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2639
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.6     |
| eval/normalized_episode_reward_std | 30.5     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0296   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 1103000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2733
----------------------------------------------------------------------------------
| alpha                              | 0.168    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.74     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0445   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1104000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2813
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 26.7     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.104   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1105000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2781
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 7.06     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0518  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.3     |
| timestep                           | 1106000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2785
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0388   |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 1107000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2811
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0482  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1108000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0689  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 1109000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2761
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 26       |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0373   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1110000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2897
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.6     |
| eval/normalized_episode_reward_std | 31.9     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0465   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1111000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2898
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.4     |
| eval/normalized_episode_reward_std | 27       |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0537  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.4     |
| timestep                           | 1112000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2639
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 8.66     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0464   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1113000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2615
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0281  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1114000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0317   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1115000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2715
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 4.09     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0727  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1116000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0498  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 1117000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0669  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 1118000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2780
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 6.35     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0262   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.9     |
| timestep                           | 1119000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0698   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1120000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2597
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.042    |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.3     |
| timestep                           | 1121000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2861
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.00368  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1122000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2925
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.00145 |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1123000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.143   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16       |
| timestep                           | 1124000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2688
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.2     |
| eval/normalized_episode_reward_std | 25       |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0104   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1125000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2631
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.000119 |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1126000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2780
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0323   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1127000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2878
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.3     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0148  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.1     |
| timestep                           | 1128000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0158   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1129000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2730
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0703   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1130000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2864
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0641  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1131000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2810
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0403  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1132000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2716
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.3     |
| timestep                           | 1133000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2705
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.1     |
| eval/normalized_episode_reward_std | 29.7     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0136  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1134000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2804
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0363   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1135000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2810
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.001    |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 1136000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2856
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 28.8     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.085   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 1137000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.6     |
| eval/normalized_episode_reward_std | 27.8     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0863   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1138000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0899  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1139000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2965
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.3     |
| timestep                           | 1140000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2740
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0398   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1141000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2882
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0383   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1142000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2736
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.123   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1143000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0367   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1144000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2849
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.4     |
| eval/normalized_episode_reward_std | 28.9     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.00545  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1145000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2731
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0622   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1146000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2695
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.5     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0547  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 1147000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0105  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1148000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0343   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1149000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2682
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.083    |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1150000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2632
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.1     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0594  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1151000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2562
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 7.82     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.00288 |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1152000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2784
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0477   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1153000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2811
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.1     |
| eval/normalized_episode_reward_std | 29.6     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0176  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1154000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2578
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0332   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1155000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2547
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0246  |
| loss/critic1                       | 19       |
| loss/critic2                       | 18.9     |
| timestep                           | 1156000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2721
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.6     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0788   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.5     |
| timestep                           | 1157000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2908
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.00765  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1158000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2788
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.00591 |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.8     |
| timestep                           | 1159000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2607
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0962  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1160000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2718
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -646     |
| loss/alpha                         | -0.0124  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1161000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2714
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.00762  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1162000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2861
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.3     |
| eval/normalized_episode_reward_std | 26.2     |
| loss/actor                         | -646     |
| loss/alpha                         | 0.00363  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1163000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2808
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 46.5     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0248   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1164000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2809
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.5     |
| eval/normalized_episode_reward_std | 30.7     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0237   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1165000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2754
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.038   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1166000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2838
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0547   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1167000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2765
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0876  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1168000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2749
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 26.4     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0358   |
| loss/critic1                       | 17.6     |
| loss/critic2                       | 17.4     |
| timestep                           | 1169000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2795
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 28.6     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.00779  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1170000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2764
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.035    |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1171000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2851
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0229   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1172000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2781
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.7     |
| eval/normalized_episode_reward_std | 29.5     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.037   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1173000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2862
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1174000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2617
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0244  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1175000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2770
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 36.5     |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.091   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1176000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2747
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0479   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1177000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2800
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0581   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1178000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2743
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 11.9     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.00176  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 1179000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2720
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 43.4     |
| eval/normalized_episode_reward_std | 31.3     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0356   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.9     |
| timestep                           | 1180000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63       |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.0522  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 1181000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2813
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0791  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1182000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2747
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.1     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -647     |
| loss/alpha                         | 0.0138   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1183000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2750
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -647     |
| loss/alpha                         | -0.00113 |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1184000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2809
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 26.7     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0263   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1185000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0613   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1186000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2871
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.015   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1187000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -648     |
| loss/alpha                         | 7.99e-05 |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1188000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2830
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.1     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0406  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1189000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2825
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.0142  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1190000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.3     |
| eval/normalized_episode_reward_std | 29.3     |
| loss/actor                         | -648     |
| loss/alpha                         | -0.00463 |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1191000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2778
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -648     |
| loss/alpha                         | 0.0738   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1192000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.8     |
| eval/normalized_episode_reward_std | 27.8     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.00752 |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1193000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2739
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0448   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1194000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2792
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.4     |
| eval/normalized_episode_reward_std | 32.9     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.00621 |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 1195000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2736
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.4     |
| eval/normalized_episode_reward_std | 30.2     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0573  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1196000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2736
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.7     |
| eval/normalized_episode_reward_std | 27.7     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0432   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1197000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2702
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0416   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17       |
| timestep                           | 1198000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65       |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.049   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.9     |
| timestep                           | 1199000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.2     |
| eval/normalized_episode_reward_std | 28.5     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.023    |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 1200000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2677
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.02    |
| loss/critic1                       | 18       |
| loss/critic2                       | 18       |
| timestep                           | 1201000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 42.7     |
| eval/normalized_episode_reward_std | 26       |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0387   |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 1202000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2548
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -649     |
| loss/alpha                         | 0.0592   |
| loss/critic1                       | 18.3     |
| loss/critic2                       | 18.2     |
| timestep                           | 1203000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.167    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.015   |
| loss/critic1                       | 19.1     |
| loss/critic2                       | 19.3     |
| timestep                           | 1204000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2738
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0645  |
| loss/critic1                       | 18.2     |
| loss/critic2                       | 18.2     |
| timestep                           | 1205000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2765
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 27.5     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.00154 |
| loss/critic1                       | 18       |
| loss/critic2                       | 17.9     |
| timestep                           | 1206000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2772
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.0825  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.2     |
| timestep                           | 1207000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -649     |
| loss/alpha                         | -0.00612 |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1208000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2714
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.8     |
| eval/normalized_episode_reward_std | 29.2     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0663   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1209000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.025    |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1210000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2891
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -650     |
| loss/alpha                         | 0.0136   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1211000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2744
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -650     |
| loss/alpha                         | -0.064   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 16       |
| timestep                           | 1212000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2857
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 44.8     |
| eval/normalized_episode_reward_std | 28.4     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0244  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1213000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2789
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59       |
| eval/normalized_episode_reward_std | 27.4     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.00774  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 1214000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2716
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -651     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1215000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2887
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0138  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1216000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0353   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1217000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0239   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1218000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2853
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 26.5     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0799   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1219000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2728
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0644   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1220000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2828
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0617   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 1221000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.069   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 1222000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 9.68     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0482  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1223000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0765  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 1224000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 27.6     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0283  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1225000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.5     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0236  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1226000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2821
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 27.4     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0592   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1227000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2802
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.00767  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1228000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2818
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.7     |
| eval/normalized_episode_reward_std | 30.4     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0832   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1229000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 26.4     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.102   |
| loss/critic1                       | 17       |
| loss/critic2                       | 17       |
| timestep                           | 1230000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2853
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.112    |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1231000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2820
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.4     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0563   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1232000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0112   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1233000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2879
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.00514 |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1234000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2820
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0852  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1235000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2504
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 9.23     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0617  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1236000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.00532  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1237000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2833
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0752   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1238000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2678
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0334   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.4     |
| timestep                           | 1239000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.1     |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1240000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2665
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0912  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1241000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.4     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0835   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1242000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2859
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1243000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2812
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 26.2     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0967  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1244000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.126    |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1245000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2996
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0562   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.7     |
| timestep                           | 1246000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2784
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0467   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1247000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 1248000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2930
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0434  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1249000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2817
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 41.1     |
| eval/normalized_episode_reward_std | 29       |
| loss/actor                         | -652     |
| loss/alpha                         | 0.00881  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1250000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2547
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 8.13     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0512  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1251000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2773
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 27.6     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0202  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 1252000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2845
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.1      |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1253000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2872
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0472   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.7     |
| timestep                           | 1254000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2650
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0465  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1255000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2726
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0508   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1256000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2762
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0622   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1257000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2752
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0715  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 1258000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2850
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0332  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1259000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2598
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.111   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 1260000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2842
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.4     |
| eval/normalized_episode_reward_std | 31.7     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0873   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1261000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2699
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0219  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1262000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2723
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1263000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2781
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0226  |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 1264000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2770
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 7.92     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.00491 |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1265000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2812
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0851   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1266000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2700
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0716   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1267000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2764
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 3.92     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.054   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1268000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2786
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0184  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1269000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2693
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0027  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 1270000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.5     |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0835  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1271000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2829
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 49.7     |
| eval/normalized_episode_reward_std | 30.5     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0272  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1272000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2788
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 1273000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2684
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 7.38     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0584  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 1274000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2877
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0548   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1275000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2712
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0713   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 1276000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2855
----------------------------------------------------------------------------------
| alpha                              | 0.166    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0265   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.7     |
| timestep                           | 1277000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0743  |
| loss/critic1                       | 17.4     |
| loss/critic2                       | 17.4     |
| timestep                           | 1278000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2688
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0521  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.3     |
| timestep                           | 1279000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2761
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -651     |
| loss/alpha                         | -0.00814 |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1280000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2842
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.4     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.077   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1281000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -651     |
| loss/alpha                         | 0.0436   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.2     |
| timestep                           | 1282000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.7     |
| eval/normalized_episode_reward_std | 27.9     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.11    |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1283000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1284000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 7.75     |
| loss/actor                         | -651     |
| loss/alpha                         | -0.0249  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.3     |
| timestep                           | 1285000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 4.4      |
| loss/actor                         | -651     |
| loss/alpha                         | 0.00125  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 1286000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2719
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.00273 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1287000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 4.28     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.1      |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1288000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2877
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 9.61     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0938   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1289000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.8     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.023   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1290000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2759
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.6     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0142   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 1291000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2914
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 1292000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2797
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0811  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1293000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2859
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0153  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 1294000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2889
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0879  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.2     |
| timestep                           | 1295000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2964
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 17       |
| timestep                           | 1296000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3067
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0313  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 1297000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 4.07     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0961   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 1298000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2692
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0553  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1299000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2960
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.71     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0985   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1300000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 26.4     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0817   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.6     |
| timestep                           | 1301000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2858
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0364   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1302000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2850
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 26.5     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0591  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.4     |
| timestep                           | 1303000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2841
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0048   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1304000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2686
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0338  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1305000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0154   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1306000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2909
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.7     |
| timestep                           | 1307000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2702
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0344  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1308000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2874
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1309000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2766
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63       |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00146  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1310000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2805
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0207  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1311000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.00297 |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17.1     |
| timestep                           | 1312000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2851
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0833  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.9     |
| timestep                           | 1313000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2922
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0842   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1314000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2814
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 5.95     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0752   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1315000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.067   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1316000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2815
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.00149  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1317000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2889
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60       |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.066    |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1318000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3002
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.115   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1319000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0369  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1320000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2842
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 8.37     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0446  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1321000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2727
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 11       |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0654  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1322000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2697
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.6      |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0916   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1323000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2794
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0366  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1324000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3082
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 25       |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0392   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1325000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0975   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1326000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2778
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0225  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 1327000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2696
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0253  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1328000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2887
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0475   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1329000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2897
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0675   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1330000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0812   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1331000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0869  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1332000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3020
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 8.78     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00574  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.3     |
| timestep                           | 1333000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2979
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 2.88     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0372  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1334000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3033
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0499  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17.1     |
| timestep                           | 1335000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0488  |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 1336000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2756
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0854   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.6     |
| timestep                           | 1337000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2930
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -653     |
| loss/alpha                         | -0.019   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.6     |
| timestep                           | 1338000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2750
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0607   |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.5     |
| timestep                           | 1339000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2732
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 11.9     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.054    |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1340000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2838
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0206  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1341000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2777
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 28.2     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0131   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1342000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2732
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 9.94     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.118    |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1343000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2850
----------------------------------------------------------------------------------
| alpha                              | 0.165    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.059   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.9     |
| timestep                           | 1344000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.2     |
| eval/normalized_episode_reward_std | 26.3     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0605  |
| loss/critic1                       | 17       |
| loss/critic2                       | 17.1     |
| timestep                           | 1345000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2779
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0591  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.9     |
| timestep                           | 1346000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0619   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16       |
| timestep                           | 1347000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2894
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0034  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1348000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2857
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.021   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1349000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2768
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0779  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1350000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2790
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0328  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1351000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2739
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 9.63     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0123  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1352000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2668
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0955   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1353000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2676
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0488  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1354000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2870
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0349   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1355000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2850
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00328  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1356000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2894
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00158  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1357000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0205  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1358000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2913
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0487   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1359000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2745
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 7.92     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0245   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1360000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2901
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 7.05     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0397   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1361000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0123  |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 16.9     |
| timestep                           | 1362000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 7.45     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0994  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1363000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2774
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 51.6     |
| eval/normalized_episode_reward_std | 31.7     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0663  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1364000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2917
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00378  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1365000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00286  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1366000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2802
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0209   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1367000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2936
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0056   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1368000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2823
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 8.61     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1369000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2784
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0711   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1370000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2837
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0116   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1371000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2776
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0175   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1372000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2886
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 4.27     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0741  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1373000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.86     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0112  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1374000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2881
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.2     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00621  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 1375000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2791
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.5     |
| eval/normalized_episode_reward_std | 26.7     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1376000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2822
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0956  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1377000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2695
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0126   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1378000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2773
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0104  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1379000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2847
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1380000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2829
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0684   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1381000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2804
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.1     |
| eval/normalized_episode_reward_std | 27.1     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0528  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1382000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2805
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0349   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.5     |
| timestep                           | 1383000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2925
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0256  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.8     |
| timestep                           | 1384000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2717
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0336  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1385000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2792
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00456 |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1386000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2809
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.1     |
| eval/normalized_episode_reward_std | 25.9     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.053    |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1387000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2961
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0641  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1388000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2865
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1389000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2748
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0294  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1390000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2845
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0746   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1391000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2743
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 10.2     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.109   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1392000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2768
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0416   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1393000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2776
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0495   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1394000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2852
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 30.2     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0841   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1395000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.1     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0168   |
| loss/critic1                       | 17.8     |
| loss/critic2                       | 17.8     |
| timestep                           | 1396000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3004
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0295  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1397000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2842
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 28       |
| loss/actor                         | -652     |
| loss/alpha                         | -0.113   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1398000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.033   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1399000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2858
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0131   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1400000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2992
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 4.77     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0749  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1401000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2758
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.000369 |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1402000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2874
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 3.39     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0581   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1403000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2679
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1404000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2766
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0383  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1405000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2849
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.4     |
| eval/normalized_episode_reward_std | 29.8     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0408  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 1406000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2764
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0675   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1407000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2726
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -652     |
| loss/alpha                         | 0.0358   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1408000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2803
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 4.04     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0552  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1409000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.0492  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1410000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2804
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.00168 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1411000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -652     |
| loss/alpha                         | -0.00441 |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1412000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 28.3     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0703  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1413000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2841
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 7.12     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0617   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1414000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2837
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.8     |
| eval/normalized_episode_reward_std | 27       |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0199  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1415000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0555  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 1416000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2943
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 7.39     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0538   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1417000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2875
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0613   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1418000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2631
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0495  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1419000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2817
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 2.9      |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0081   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.5     |
| timestep                           | 1420000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 11.9     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00144  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1421000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2797
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0258  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1422000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2784
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1423000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2823
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64       |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0348   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1424000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2965
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.049   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 16       |
| timestep                           | 1425000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2806
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0246   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1426000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.3     |
| eval/normalized_episode_reward_std | 27       |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0745   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.2     |
| timestep                           | 1427000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2838
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -654     |
| loss/alpha                         | 0.118    |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1428000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2811
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 7.82     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00682  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1429000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2711
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0181  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1430000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2829
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00845 |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1431000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3008
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0555  |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.6     |
| timestep                           | 1432000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2703
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1433000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2769
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0173  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1434000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2874
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0195  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1435000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2811
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53.7     |
| eval/normalized_episode_reward_std | 31.1     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.018   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1436000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2746
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 9.11     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0363   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 1437000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2797
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0331   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1438000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2584
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0273  |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.8     |
| timestep                           | 1439000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0888   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1440000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2804
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0248  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1441000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0561  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1442000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2803
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0443  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1443000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2858
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0158  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1444000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2888
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1445000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2736
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0342  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1446000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2852
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 5.94     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0161   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.5     |
| timestep                           | 1447000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2822
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0392  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1448000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2930
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79       |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.8     |
| timestep                           | 1449000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2854
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.3     |
| eval/normalized_episode_reward_std | 28.7     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0685   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1450000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.6     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00688  |
| loss/critic1                       | 17.5     |
| loss/critic2                       | 17.4     |
| timestep                           | 1451000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2815
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0515   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 1452000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2816
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0568  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1453000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2787
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00717  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1454000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2769
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0346   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.6     |
| timestep                           | 1455000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00191  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1456000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.136   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1457000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2740
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0507   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1458000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2858
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0349  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1459000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2921
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 7.52     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0139   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1460000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2802
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0271  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1461000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2836
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 3        |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0764   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1462000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2790
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0469  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1463000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2831
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0956   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1464000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2834
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.81     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0294   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1465000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0589  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1466000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2818
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.00565 |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 1467000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2779
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 28.1     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.024   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1468000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2905
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00575  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1469000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -655     |
| loss/alpha                         | -0.12    |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1470000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2842
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1471000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2777
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0276   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 1472000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0118  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 1473000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2738
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.049    |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1474000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2756
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0303  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1475000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2680
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0189   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1476000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2861
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0605  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1477000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0682   |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1478000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 6.53     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0689   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1479000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2913
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0823  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1480000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2905
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.8     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0978   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1481000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2826
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0182   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1482000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2851
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00706 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1483000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3044
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0312   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1484000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0463  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1485000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2770
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 7.47     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0865  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1486000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3028
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 28.8     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0854  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1487000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00805  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1488000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2784
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.087    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1489000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2897
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0482  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1490000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3024
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0296  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1491000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1492000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2724
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0358  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1493000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2824
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0462   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1494000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3117
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0526   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1495000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2835
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00145  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1496000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 8.72     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0329  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1497000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2918
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0294  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1498000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2748
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0414  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1499000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2795
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 2.89     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0726   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 1500000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2712
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0213  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 1501000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2776
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0498  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1502000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0125   |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.8     |
| timestep                           | 1503000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0395   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1504000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2760
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 10.2     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0255  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.7     |
| timestep                           | 1505000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0423  |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1506000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0717   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 16       |
| timestep                           | 1507000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2737
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 26.2     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0227  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 1508000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2692
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 10.2     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0488  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 1509000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2681
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0456   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1510000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2855
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.058    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1511000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0742  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1512000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0216  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1513000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2728
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0174   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1514000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2845
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.79     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0376   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1515000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2838
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0993  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1516000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3073
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 8.53     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00887 |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1517000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0336   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1518000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0105   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1519000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 8.74     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0349   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.2     |
| timestep                           | 1520000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2819
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0193  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1521000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2938
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00266 |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1522000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2833
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.149   |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1523000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2804
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0165  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1524000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.8     |
| eval/normalized_episode_reward_std | 28.4     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1525000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2898
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.029   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.7     |
| timestep                           | 1526000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3031
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0646   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1527000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2728
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0961   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.3     |
| timestep                           | 1528000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2938
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 52       |
| eval/normalized_episode_reward_std | 30.1     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.124   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1529000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2915
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0138  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1530000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2808
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0799   |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.2     |
| timestep                           | 1531000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2712
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0543  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1532000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2904
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0531  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.2     |
| timestep                           | 1533000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2834
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0291   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1534000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2567
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0283   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 1535000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2797
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 5.87     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0787   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.2     |
| timestep                           | 1536000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0812  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1537000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2925
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.8     |
| eval/normalized_episode_reward_std | 29.3     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0761   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1538000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2888
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0551  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 1539000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0273  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1540000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2817
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 1541000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2826
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0119  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1542000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2815
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0339   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1543000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 9.61     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1544000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2802
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 9.69     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0763  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1545000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2826
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0772   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1546000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0149   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 1547000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2847
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.0388  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1548000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2859
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.00698 |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1549000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3042
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -653     |
| loss/alpha                         | -0.02    |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1550000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2724
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.00248  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1551000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2741
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -653     |
| loss/alpha                         | 0.0717   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1552000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3024
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.00591  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1553000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2831
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.00932 |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1554000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0424   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1555000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2981
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0271  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1556000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3058
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 3.97     |
| loss/actor                         | -654     |
| loss/alpha                         | 0.0331   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1557000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0413  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1558000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2749
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0237   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1559000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2815
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.2     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00895  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1560000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0573   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1561000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2865
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.00355 |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1562000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2724
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -654     |
| loss/alpha                         | -0.0257  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1563000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2888
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 7.34     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1564000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0519  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1565000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0121  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15.1     |
| timestep                           | 1566000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2823
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0134   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 1567000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2691
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.072    |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1568000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2874
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1569000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2686
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0212   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1570000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2811
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0314  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1571000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2738
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0163  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 1572000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2777
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0582  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1573000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2736
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0316  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1574000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2720
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0315   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1575000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0532  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1576000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00204  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1577000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2855
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00256  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1578000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2886
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.2     |
| eval/normalized_episode_reward_std | 25.9     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0268   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1579000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2880
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0888  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1580000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2881
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 4.04     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0202  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1581000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2852
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0271   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1582000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2785
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0944   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1583000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0774   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1584000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2849
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 28.6     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0186  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.8     |
| timestep                           | 1585000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0751  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.8     |
| timestep                           | 1586000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00308  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1587000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3053
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.4     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0706  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1588000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2806
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.00932  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1589000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2851
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0573   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1590000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.12     |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1591000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 38.3     |
| eval/normalized_episode_reward_std | 26.7     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0635  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.7     |
| timestep                           | 1592000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2598
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0297   |
| loss/critic1                       | 17.9     |
| loss/critic2                       | 17.9     |
| timestep                           | 1593000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2935
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.3     |
| timestep                           | 1594000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2959
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0159   |
| loss/critic1                       | 17.7     |
| loss/critic2                       | 17.7     |
| timestep                           | 1595000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2824
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.132   |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 1596000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2867
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 8.7      |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0773  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1597000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2856
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0279  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1598000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 7.24     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0121   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1599000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2887
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.7     |
| eval/normalized_episode_reward_std | 29.5     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.115    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1600000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2755
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0237  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1601000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0186  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1602000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2864
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 25.2     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0374   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1603000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2872
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.02    |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1604000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2829
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 7.69     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1605000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
-----------------------------------------------------------------------------------
| alpha                              | 0.162     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 76.1      |
| eval/normalized_episode_reward_std | 6.9       |
| loss/actor                         | -659      |
| loss/alpha                         | -0.000226 |
| loss/critic1                       | 15.5      |
| loss/critic2                       | 15.6      |
| timestep                           | 1606000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2749
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0736  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1607000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2780
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 27.8     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0659  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1608000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2878
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0107  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1609000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2814
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 26.5     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0512  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1610000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 28.2     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0412   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1611000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2847
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0308  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1612000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2948
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.2     |
| eval/normalized_episode_reward_std | 29.6     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0441  |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.6     |
| timestep                           | 1613000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2809
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0146   |
| loss/critic1                       | 16.8     |
| loss/critic2                       | 16.7     |
| timestep                           | 1614000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2919
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0117   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1615000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2956
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0232   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 1616000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2879
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0357   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1617000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0104   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1618000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0159  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1619000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2738
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0897  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1620000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0631   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1621000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2927
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1622000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2925
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0117  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1623000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3050
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 4.73     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.00178 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1624000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3052
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0551   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1625000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2688
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0271  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1626000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2801
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0146   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1627000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0127   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1628000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2835
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.115    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1629000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2774
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.00975 |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1630000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3080
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0801  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 1631000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2908
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.5     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0906   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1632000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2977
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0667  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1633000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0392  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1634000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2766
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0307   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.9     |
| timestep                           | 1635000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2909
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 6.01     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0288   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1636000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2950
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0161  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1637000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0601   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1638000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2706
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.00459 |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1639000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.115   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1640000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0127  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 1641000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0644   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1642000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2730
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 8.65     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0504   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1643000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2771
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64       |
| eval/normalized_episode_reward_std | 25.2     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0635  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1644000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2725
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0221   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 1645000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2881
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.8     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.162   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1646000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.3     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.118    |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1647000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2838
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65       |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.00334 |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1648000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 11       |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0221   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1649000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2738
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0104  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1650000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 6.72     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0137   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 1651000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2887
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 24       |
| loss/actor                         | -655     |
| loss/alpha                         | -0.088   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1652000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2881
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 27.8     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00523  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1653000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0557   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1654000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2823
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0462   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1655000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3003
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0262   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1656000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2842
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0743  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1657000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 26       |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0059  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1658000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2758
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 9.63     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.00217  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1659000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0639  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1660000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.134    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1661000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2821
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.8     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0122   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 1662000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2768
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0643   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1663000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2837
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0574  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1664000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2788
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 5.72     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0525  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1665000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3133
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -655     |
| loss/alpha                         | 0.0699   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1666000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -655     |
| loss/alpha                         | -0.0516  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1667000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2935
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 4.79     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0247   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1668000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2938
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1669000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2973
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.04    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 1670000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2878
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0421   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1671000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
-----------------------------------------------------------------------------------
| alpha                              | 0.158     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 72.3      |
| eval/normalized_episode_reward_std | 22.2      |
| loss/actor                         | -657      |
| loss/alpha                         | -0.000706 |
| loss/critic1                       | 14.7      |
| loss/critic2                       | 14.6      |
| timestep                           | 1672000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2868
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0225  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1673000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3002
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0941  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1674000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2913
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 25.5     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0549   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1675000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
-----------------------------------------------------------------------------------
| alpha                              | 0.156     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 63.4      |
| eval/normalized_episode_reward_std | 29.6      |
| loss/actor                         | -657      |
| loss/alpha                         | -0.000859 |
| loss/critic1                       | 15.3      |
| loss/critic2                       | 15.2      |
| timestep                           | 1676000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2822
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.96     |
| loss/actor                         | -656     |
| loss/alpha                         | -0.00184 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1677000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0305   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1678000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2891
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.00365  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1679000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3024
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.84     |
| loss/actor                         | -656     |
| loss/alpha                         | 0.0602   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1680000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2980
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0285  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1681000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2886
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0357  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1682000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2861
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0574  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1683000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3015
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0155   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1684000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2903
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.1     |
| eval/normalized_episode_reward_std | 26.2     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0541   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1685000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2812
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.026    |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 1686000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2836
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.8     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0083   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1687000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 10       |
| loss/actor                         | -658     |
| loss/alpha                         | 0.043    |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1688000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2919
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0326  |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 1689000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2812
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0323   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1690000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2832
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 12.9     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0749  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1691000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2918
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0236  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1692000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.00915  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1693000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2871
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -657     |
| loss/alpha                         | 0.0091   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1694000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3015
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 27.8     |
| loss/actor                         | -657     |
| loss/alpha                         | -0.0716  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 1695000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 8.94     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0436   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1696000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2872
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -658     |
| loss/alpha                         | -0.0608  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1697000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2795
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0577   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1698000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2855
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0528   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1699000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.6     |
| eval/normalized_episode_reward_std | 31.8     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0834   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1700000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2808
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -658     |
| loss/alpha                         | 0.00908  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1701000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0149   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1702000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -658     |
| loss/alpha                         | 0.0731   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1703000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0999  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1704000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0549  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1705000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1706000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2741
----------------------------------------------------------------------------------
| alpha                              | 0.162    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60       |
| eval/normalized_episode_reward_std | 26       |
| loss/actor                         | -659     |
| loss/alpha                         | 0.126    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1707000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2858
----------------------------------------------------------------------------------
| alpha                              | 0.164    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0153  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1708000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2963
----------------------------------------------------------------------------------
| alpha                              | 0.163    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0511  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1709000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0871  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1710000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0685  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1711000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2797
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0523   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1712000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.4     |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0707  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1713000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0307  |
| loss/critic1                       | 16       |
| loss/critic2                       | 16       |
| timestep                           | 1714000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2871
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 6.98     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0259   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.8     |
| timestep                           | 1715000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2896
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0274   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 16       |
| timestep                           | 1716000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2956
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0329   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1717000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2830
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0351  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.4     |
| timestep                           | 1718000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2776
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0573   |
| loss/critic1                       | 17.3     |
| loss/critic2                       | 17.2     |
| timestep                           | 1719000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2886
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0142  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1720000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2764
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.00288  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16       |
| timestep                           | 1721000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2860
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.5     |
| eval/normalized_episode_reward_std | 28.8     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.00147  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1722000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2705
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0217   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1723000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2816
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0313   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1724000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2830
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.159   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1725000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3022
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 24       |
| loss/actor                         | -660     |
| loss/alpha                         | -0.00688 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1726000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0837  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1727000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2808
-----------------------------------------------------------------------------------
| alpha                              | 0.153     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 79.2      |
| eval/normalized_episode_reward_std | 2.96      |
| loss/actor                         | -660      |
| loss/alpha                         | -0.000638 |
| loss/critic1                       | 16.1      |
| loss/critic2                       | 16.1      |
| timestep                           | 1728000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3032
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0687   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 1729000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2949
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 3.06     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0176   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.2     |
| timestep                           | 1730000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2776
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 3.79     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0041  |
| loss/critic1                       | 16.6     |
| loss/critic2                       | 16.6     |
| timestep                           | 1731000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3037
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0444  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1732000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0558  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1733000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2880
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0705   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1734000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3045
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 24       |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0814   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1735000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2977
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0161   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1736000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2715
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0994   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 16       |
| timestep                           | 1737000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2950
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.00934  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 1738000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0369  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1739000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3024
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0289  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1740000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3069
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.123   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1741000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0747  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1742000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0493   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1743000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3019
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 15.5     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0913   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1744000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2784
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.037   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1745000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2879
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0299  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1746000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2943
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.3     |
| eval/normalized_episode_reward_std | 29.6     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0323   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1747000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0473  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.6     |
| timestep                           | 1748000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3021
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0311  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1749000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3028
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0143   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1750000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3075
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 5.52     |
| loss/actor                         | -659     |
| loss/alpha                         | 0.0776   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1751000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3091
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 10.2     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0519  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 1752000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0115  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1753000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2799
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0467   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1754000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2837
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0668   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1755000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2872
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -659     |
| loss/alpha                         | -0.0592  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1756000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3059
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0432  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1757000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0164   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1758000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 6.28     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0406  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1759000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2762
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0812   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1760000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2727
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.00116  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1761000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0281   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1762000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.04     |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1763000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2860
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 8.15     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0602   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 1764000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2798
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0466  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1765000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2853
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0496  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1766000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2853
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 2.67     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0195   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1767000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0082  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1768000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2894
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0153  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1769000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.00398 |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1770000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2908
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0409  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1771000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0818  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1772000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3005
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0674   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1773000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2738
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0552   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 1774000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2944
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0648   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1775000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2813
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0465  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1776000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0721  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 1777000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2756
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 4.31     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0139  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 15.9     |
| timestep                           | 1778000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2770
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0369  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1779000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2816
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0997   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1780000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79       |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0275  |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1781000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2921
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0479  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1782000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0353  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1783000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2784
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.00253  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1784000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.061   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1785000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2903
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0385   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1786000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2737
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0485   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1787000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0504   |
| loss/critic1                       | 17.1     |
| loss/critic2                       | 17       |
| timestep                           | 1788000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0475  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.2     |
| timestep                           | 1789000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 32.5     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0185  |
| loss/critic1                       | 17.2     |
| loss/critic2                       | 17       |
| timestep                           | 1790000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2981
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0229   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1791000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 25.8     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0456   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1792000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 53       |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.116   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1793000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2858
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 26.4     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0112  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1794000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3015
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.7     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0953   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.2     |
| timestep                           | 1795000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2740
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0621   |
| loss/critic1                       | 16.3     |
| loss/critic2                       | 16.1     |
| timestep                           | 1796000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2767
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0487  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1797000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2828
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0522  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1798000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2981
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 6.81     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0347   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1799000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3003
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0532   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 15.9     |
| timestep                           | 1800000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2975
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0453  |
| loss/critic1                       | 16.4     |
| loss/critic2                       | 16.5     |
| timestep                           | 1801000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2819
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0342   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1802000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2867
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0639   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1803000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3084
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.00579 |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1804000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2888
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0243   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1805000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2960
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.8     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.027    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 1806000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2773
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0635  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1807000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0502  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1808000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.7     |
| eval/normalized_episode_reward_std | 32.4     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.145    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 1809000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0355  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.6     |
| timestep                           | 1810000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2985
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.8     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0958  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 16.1     |
| timestep                           | 1811000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2879
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0012   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1812000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 3.92     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.052   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1813000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2917
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1814000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2898
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0195   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1815000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2872
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00878 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1816000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2928
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0266   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1817000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.7     |
| timestep                           | 1818000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2817
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0696   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1819000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 30.1     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0219  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 1820000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 28.4     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.1     |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1821000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2995
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0522   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1822000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 9.91     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0555   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1823000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2871
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 25.6     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00045  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1824000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0315  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1825000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2821
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 17       |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0122   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1826000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.1     |
| eval/normalized_episode_reward_std | 27       |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0248   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1827000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2729
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0128  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1828000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.72     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0451   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1829000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2737
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0312  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.8     |
| timestep                           | 1830000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2891
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0113   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1831000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3101
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 3.59     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0404  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1832000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 10.2     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0694  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1833000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 9.31     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.067    |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.1     |
| timestep                           | 1834000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3004
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 4        |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00285  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.7     |
| timestep                           | 1835000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0425   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1836000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2871
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80       |
| eval/normalized_episode_reward_std | 3.91     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0281  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1837000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0245   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 1838000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.00596 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1839000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2852
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 9.71     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0821  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1840000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 9.07     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0247   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 1841000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2833
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 2.76     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0546   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1842000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0251   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1843000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 9.28     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0563   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1844000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2834
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.05    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1845000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0293  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15.1     |
| timestep                           | 1846000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.123    |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1847000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2814
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1848000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2887
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.79     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0866  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1849000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2853
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 2.69     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00221  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1850000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2943
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 28       |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0181   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1851000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3042
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 13.5     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0419   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1852000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3018
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0327   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1853000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2812
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.3     |
| eval/normalized_episode_reward_std | 28.5     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0321   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1854000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2772
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0283  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1855000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3021
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 26.8     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0735  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1856000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3007
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 7.97     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0123   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1857000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3041
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 6.57     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0072   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1858000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2840
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61       |
| eval/normalized_episode_reward_std | 26.5     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0919   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 1859000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2870
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 4.6      |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0238   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1860000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0591  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 1861000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3027
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0621  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1862000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 31.3     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0927  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1863000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2891
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.127    |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 1864000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2964
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 8.42     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0535  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1865000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0273  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 1866000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0352   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1867000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2816
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0802   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 1868000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2783
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.00936 |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1869000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3079
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0452  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1870000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0127  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1871000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2887
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 19.8     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0561  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1872000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2785
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.023    |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1873000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2845
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0402   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1874000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2925
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0566   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1875000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 28       |
| loss/actor                         | -662     |
| loss/alpha                         | -0.131   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1876000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2956
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.045   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 1877000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3085
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 6.24     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0287   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1878000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2731
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 7.14     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0264  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1879000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 6.35     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0259   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 1880000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 9.74     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0351  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 1881000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.2     |
| eval/normalized_episode_reward_std | 32.5     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1882000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2943
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -662     |
| loss/alpha                         | 0.18     |
| loss/critic1                       | 16.7     |
| loss/critic2                       | 16.7     |
| timestep                           | 1883000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0482   |
| loss/critic1                       | 16.5     |
| loss/critic2                       | 16.4     |
| timestep                           | 1884000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0544  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1885000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2734
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0212  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1886000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2824
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.7     |
| eval/normalized_episode_reward_std | 29.8     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.073    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1887000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0129  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 1888000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3016
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.2     |
| eval/normalized_episode_reward_std | 32.8     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.051   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1889000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3048
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0223   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.1     |
| timestep                           | 1890000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2807
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0422  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1891000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0459  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1892000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2965
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0512  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1893000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0281  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 1894000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0135  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.2     |
| timestep                           | 1895000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2767
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0904   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1896000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2938
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0297  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1897000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2784
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 9.29     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.113    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1898000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0229  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1899000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2821
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.062   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1900000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.00311  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1901000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2879
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 25.2     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0593  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1902000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3040
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79       |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0428  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 1903000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 2.8      |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0403  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1904000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0377   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 1905000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2829
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.1     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0803   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 1906000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2772
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0525   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1907000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2734
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 27.4     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0916  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1908000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.1     |
| eval/normalized_episode_reward_std | 28.3     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0269   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 1909000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0276   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 1910000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.0167  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 1911000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2861
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 10.3     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.146   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1912000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2919
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 9.47     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1913000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2849
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0711   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 1914000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2915
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79       |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -660     |
| loss/alpha                         | 0.0313   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 1915000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2718
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -660     |
| loss/alpha                         | -0.069   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 1916000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2961
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 28       |
| loss/actor                         | -661     |
| loss/alpha                         | 0.034    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1917000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2889
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0778  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1918000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2714
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.045    |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 1919000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2872
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.3     |
| eval/normalized_episode_reward_std | 30.1     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0327   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1920000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2835
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.028   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1921000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2861
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 25.8     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0898   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 1922000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.133    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 1923000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2735
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00185 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1924000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2778
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.00615  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1925000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2840
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 5.2      |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0397  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1926000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2894
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0557  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1927000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2767
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0431   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1928000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2851
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -660     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1929000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2867
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0119  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1930000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2790
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 54.8     |
| eval/normalized_episode_reward_std | 34.4     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00566 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1931000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2787
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0337  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1932000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2847
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0104  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 1933000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00243 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1934000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0465  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 1935000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2823
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.112    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1936000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2826
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0419  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 1937000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0167  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1938000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3003
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.4     |
| eval/normalized_episode_reward_std | 3.78     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0665   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1939000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2764
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0137  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 1940000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00171 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1941000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0143  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 1942000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0332  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1943000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 12.1     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0383   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 1944000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2882
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0221  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 1945000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3138
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0828   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1946000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2764
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0303   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1947000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.5     |
| eval/normalized_episode_reward_std | 32.4     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.00557 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1948000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3050
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 9.47     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0596  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1949000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 16       |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0498  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 1950000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2930
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0252  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16.5     |
| timestep                           | 1951000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2791
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0666   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 1952000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.1     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.00462  |
| loss/critic1                       | 18.7     |
| loss/critic2                       | 18.6     |
| timestep                           | 1953000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0231  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 1954000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2959
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -661     |
| loss/alpha                         | -0.066   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 1955000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2958
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.045    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1956000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.045    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 1957000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2778
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0456  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 1958000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2913
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.1     |
| eval/normalized_episode_reward_std | 26.4     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0979   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1959000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2888
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0339  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1960000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2889
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 2.83     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0323  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 1961000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3035
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0241   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 1962000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3034
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0397   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 1963000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3013
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.028   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 1964000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2999
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.029   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 1965000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2975
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.3     |
| eval/normalized_episode_reward_std | 28.1     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0359  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 1966000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3005
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 26.5     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00498 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 1967000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2915
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.6     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0589  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 1968000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2981
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 1969000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2893
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0562   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 1970000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3012
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00267 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1971000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0393   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 1972000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2979
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 9.9      |
| loss/actor                         | -661     |
| loss/alpha                         | -0.079   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 1973000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2968
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 8.64     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.00949  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 1974000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0591  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 1975000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2913
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0214   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1976000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0957   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 1977000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.2     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0473  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 1978000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2695
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 30       |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0356  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 1979000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3091
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0517   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 1980000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 5.01     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0618  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1981000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -661     |
| loss/alpha                         | -0.023   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 1982000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0924   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 1983000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0227  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 1984000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2964
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 8.39     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0294  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 1985000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3024
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0134  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1986000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0288   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.4     |
| timestep                           | 1987000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2867
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 6.31     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0113  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.9     |
| timestep                           | 1988000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2788
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 7.04     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0124  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1989000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2966
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0225   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 1990000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2878
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0302   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.6     |
| timestep                           | 1991000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3030
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 28.6     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0572   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 1992000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0316  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 1993000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2870
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0196  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 1994000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3024
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0448  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 1995000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3020
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0504   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 1996000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2889
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.048    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 1997000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3010
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.3     |
| eval/normalized_episode_reward_std | 32.3     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00893 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 1998000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2778
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.00334  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 1999000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2960
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 13.6     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.114   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2000000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2944
-----------------------------------------------------------------------------------
| alpha                              | 0.153     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 70.2      |
| eval/normalized_episode_reward_std | 24.2      |
| loss/actor                         | -661      |
| loss/alpha                         | -0.000487 |
| loss/critic1                       | 13.9      |
| loss/critic2                       | 14        |
| timestep                           | 2001000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.0406   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2002000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00733 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2003000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2834
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0385  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2004000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2930
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.00621 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2005000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.209    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2006000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2820
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -661     |
| loss/alpha                         | 0.031    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2007000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -661     |
| loss/alpha                         | -0.0908  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2008000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0336  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2009000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2887
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0392   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2010000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2858
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0446  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2011000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0194   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2012000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -662     |
| loss/alpha                         | -0.0924  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2013000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3035
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -662     |
| loss/alpha                         | 0.0154   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2014000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2901
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -662     |
| loss/alpha                         | -0.00263 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2015000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2922
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0534   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2016000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2741
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 4.32     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.049    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2017000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2918
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0798   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2018000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00414  |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 2019000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2760
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 8.79     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0697  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2020000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00142  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2021000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 13.3     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.00143  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2022000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0405  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2023000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -662     |
| loss/alpha                         | 0.00331  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2024000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.11     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0147  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 2025000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0178   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2026000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2896
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0413  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2027000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.109    |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2028000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2833
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0104  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2029000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0261  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2030000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -663     |
| loss/alpha                         | 0.0219   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2031000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2834
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.4     |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -663     |
| loss/alpha                         | -0.0398  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2032000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0838  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2033000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2878
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0507   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2034000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2958
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0127  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2035000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2919
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0108   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2036000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2807
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 5.17     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0207   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2037000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.072    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2038000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2755
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.4     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0121   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2039000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 28.1     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0537  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 2040000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 16.9     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0606  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 2041000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2857
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0537   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.3     |
| timestep                           | 2042000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3091
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0903   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2043000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2842
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00404 |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2044000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2847
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0801  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2045000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2772
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 30.7     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0407  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2046000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 26.4     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0234   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2047000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2917
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0398   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.4     |
| timestep                           | 2048000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2049000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0661  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2050000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3014
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 5.45     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0166   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2051000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2782
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0315   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.5     |
| timestep                           | 2052000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0803  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 2053000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 9.12     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0231  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2054000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00885  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2055000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2868
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0356   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2056000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2057000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
-----------------------------------------------------------------------------------
| alpha                              | 0.157     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 79.6      |
| eval/normalized_episode_reward_std | 3.94      |
| loss/actor                         | -664      |
| loss/alpha                         | -0.000759 |
| loss/critic1                       | 14.4      |
| loss/critic2                       | 14.4      |
| timestep                           | 2058000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2878
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 4.41     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0196  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2059000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0133  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2060000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3029
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.024   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2061000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3022
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -664     |
| loss/alpha                         | 0.018    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2062000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 28.8     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0326  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2063000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2789
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 25.8     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0611   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2064000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2903
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 29.7     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0374  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2065000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0129   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2066000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 4.67     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0517   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 2067000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0875  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2068000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2943
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0642   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2069000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2918
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.103   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2070000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0799  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2071000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3087
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00277 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2072000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2936
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 9.99     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0529   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2073000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3007
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 30       |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0638  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2074000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2999
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0671   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2075000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2849
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 9.36     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0174  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2076000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2865
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 3.91     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.00797 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2077000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3105
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 8.53     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0591   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2078000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2981
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80       |
| eval/normalized_episode_reward_std | 4.23     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0182  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2079000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3061
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.4     |
| eval/normalized_episode_reward_std | 7.52     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.011    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2080000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3024
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.017   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 2081000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2977
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0714  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2082000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2930
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0139   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2083000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3113
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.0667   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2084000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2928
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00182  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2085000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3030
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.00386 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2086000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.143    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2087000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2956
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 25.2     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0323   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2088000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2879
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 27.9     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0359   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2089000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.112   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 2090000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3132
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.4     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0188   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2091000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2820
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2092000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3066
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0742  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2093000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2867
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65       |
| eval/normalized_episode_reward_std | 28.5     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0449   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2094000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 5.09     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.00652 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2095000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2778
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0571   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2096000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0334  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 2097000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2989
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0515  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2098000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3029
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0282   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2099000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0455  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2100000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0567   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.8     |
| timestep                           | 2101000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2991
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0862   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2102000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0359  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2103000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2771
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0804  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2104000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3028
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0124  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2105000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2823
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0343   |
| loss/critic1                       | 16       |
| loss/critic2                       | 16.9     |
| timestep                           | 2106000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2788
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.00021 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2107000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00528  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 2108000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00548  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2109000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 10.3     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0129  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2110000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3008
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 28.1     |
| loss/actor                         | -664     |
| loss/alpha                         | 0.00279  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2111000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3070
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 13.2     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.00534 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2112000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3012
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -664     |
| loss/alpha                         | -0.0533  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2113000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0673  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2114000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0772   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2115000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2888
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 11.2     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0658   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 2116000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0345   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 2117000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0587  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 2118000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0136   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2119000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00302  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2120000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2918
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00157 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 2121000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00818 |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 2122000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0306  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2123000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2921
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0662   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2124000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2850
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.026   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2125000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2830
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0279   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2126000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2966
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 6.77     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0565  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 2127000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0299   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2128000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0122  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2129000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0545   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2130000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 10.7     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0559  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2131000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2820
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00765 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2132000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0386   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2133000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2862
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0726  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2134000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2799
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.01    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2135000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0608   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2136000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2928
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.2     |
| eval/normalized_episode_reward_std | 32.2     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0226   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2137000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00811 |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2138000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2865
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 13.2     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0308   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 2139000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2754
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 3.55     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0812   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2140000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2791
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00237 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2141000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0473  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2142000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2851
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.12     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0596  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2143000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0492  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2144000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2898
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0103   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2145000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2988
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.000579 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2146000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3000
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0417  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2147000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2845
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -666     |
| loss/alpha                         | 0.116    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2148000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.6     |
| eval/normalized_episode_reward_std | 27.3     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.037   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2149000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2736
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0433  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2150000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2958
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.8     |
| eval/normalized_episode_reward_std | 30.4     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0323  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2151000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0145   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2152000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2825
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 13.2     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0539  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2153000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2947
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0361   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2154000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2155000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0863   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2156000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2862
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.108    |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2157000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2830
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.00678 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2158000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2982
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.0776   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2159000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3006
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 12       |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0481   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 2160000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2816
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 3.65     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.11    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2161000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3014
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -665     |
| loss/alpha                         | -0.0208  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2162000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -665     |
| loss/alpha                         | 0.00348  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2163000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2880
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 28.6     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.11    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.6     |
| timestep                           | 2164000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2889
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 8.66     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0126  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2165000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2867
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00772 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2166000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2860
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.8     |
| eval/normalized_episode_reward_std | 30.4     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0276   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2167000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2716
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 28.1     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.039    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2168000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2820
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0666   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2169000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2787
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 29.4     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00461 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2170000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0276  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2171000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2845
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 28.6     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0476   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2172000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0106   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 2173000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2917
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0445  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 2174000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.41     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.00364  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2175000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2968
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 9.22     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0182  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2176000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2928
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.27     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0388   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2177000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.5     |
| eval/normalized_episode_reward_std | 27.4     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00651 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2178000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2661
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.4     |
| eval/normalized_episode_reward_std | 27.3     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0561  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2179000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2809
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.3     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0331   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2180000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2761
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.00813 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2181000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0791   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2182000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2831
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 4.99     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0565  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2183000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2968
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0182   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2184000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.8     |
| eval/normalized_episode_reward_std | 27.3     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0442   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2185000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0259  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2186000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 26       |
| loss/actor                         | -666     |
| loss/alpha                         | -0.0295  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2187000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -666     |
| loss/alpha                         | 0.0139   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2188000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3086
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0487  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2189000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2755
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 25       |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0467   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2190000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00384 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2191000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3031
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.029   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 2192000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 4.05     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2193000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3042
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 4.48     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0136   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2194000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2840
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0305   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 2195000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 28.2     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.031   |
| loss/critic1                       | 16.1     |
| loss/critic2                       | 16       |
| timestep                           | 2196000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2913
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0613   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 2197000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2807
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 7.54     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0817  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2198000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 29.6     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0709   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2199000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0274  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2200000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -667     |
| loss/alpha                         | -0.085   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2201000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2890
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.00335 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2202000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2751
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.4     |
| eval/normalized_episode_reward_std | 33       |
| loss/actor                         | -667     |
| loss/alpha                         | 0.043    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2203000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0054   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2204000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2846
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.35     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0384  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2205000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.032    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2206000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 6.37     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0411  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2207000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2905
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.42     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0134  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2208000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2762
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.021   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2209000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0727  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2210000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.7     |
| eval/normalized_episode_reward_std | 28.4     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2211000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3036
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.00978  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2212000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3014
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.2     |
| eval/normalized_episode_reward_std | 30.2     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0997   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2213000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2999
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.4     |
| eval/normalized_episode_reward_std | 27.1     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0421   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2214000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2948
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 8.52     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.00643  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2215000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2890
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0904   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2216000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2779
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 26       |
| loss/actor                         | -667     |
| loss/alpha                         | -0.105   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2217000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2859
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0941  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2218000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3126
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 9.79     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0549   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2219000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 6.65     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.0941   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2220000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2713
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0137  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2221000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2982
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0773  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2222000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3037
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0314  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2223000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2922
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.6     |
| eval/normalized_episode_reward_std | 26.6     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0567   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2224000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2833
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0441   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2225000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0873  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2226000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3037
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.1     |
| eval/normalized_episode_reward_std | 8.54     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0389  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2227000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3041
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0396   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2228000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2847
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.8     |
| eval/normalized_episode_reward_std | 27.5     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0297  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2229000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -667     |
| loss/alpha                         | -0.0455  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2230000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3065
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.044    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2231000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3040
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.2     |
| eval/normalized_episode_reward_std | 5.06     |
| loss/actor                         | -667     |
| loss/alpha                         | 0.123    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2232000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2842
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -668     |
| loss/alpha                         | 0.0783   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2233000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0821  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2234000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0311  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2235000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.0902  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2236000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2864
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -668     |
| loss/alpha                         | -0.00712 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2237000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2812
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.0941   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2238000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.4     |
| eval/normalized_episode_reward_std | 6.57     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0982  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2239000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -669     |
| loss/alpha                         | -0.0106  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2240000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -669     |
| loss/alpha                         | 0.071    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2241000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2898
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.07     |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2242000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.00551  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2243000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0352   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2244000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2739
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.024    |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2245000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2949
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0448  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2246000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2954
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 27.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.063    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2247000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2897
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00424  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2248000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2881
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.5     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0686  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2249000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0657  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2250000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2778
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 28.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00994 |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2251000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2776
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.029    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2252000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.1     |
| eval/normalized_episode_reward_std | 27.7     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0111   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2253000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2888
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.4     |
| eval/normalized_episode_reward_std | 26.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0376  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2254000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.158    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2255000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
-----------------------------------------------------------------------------------
| alpha                              | 0.16      |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 64.5      |
| eval/normalized_episode_reward_std | 29.3      |
| loss/actor                         | -671      |
| loss/alpha                         | -0.000681 |
| loss/critic1                       | 14.8      |
| loss/critic2                       | 14.9      |
| timestep                           | 2256000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.4     |
| eval/normalized_episode_reward_std | 24       |
| loss/actor                         | -671     |
| loss/alpha                         | -0.105   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2257000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.3     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.4     |
| timestep                           | 2258000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2898
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0758  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 2259000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2833
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 10.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.025    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2260000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2820
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0425  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2261000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2985
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0473  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2262000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0379  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2263000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3061
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0634   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2264000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3003
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00568 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2265000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 29.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0312   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2266000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2897
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.2     |
| eval/normalized_episode_reward_std | 30.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00405  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2267000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0224   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 2268000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 28.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0421  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 2269000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.3     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0464   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2270000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.005    |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 2271000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0618  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15       |
| timestep                           | 2272000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2855
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0249  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 2273000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2964
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0463  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2274000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2814
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 2.82     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0598   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2275000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2949
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0343   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2276000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2947
-----------------------------------------------------------------------------------
| alpha                              | 0.156     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 72.1      |
| eval/normalized_episode_reward_std | 22.7      |
| loss/actor                         | -670      |
| loss/alpha                         | -0.000879 |
| loss/critic1                       | 15        |
| loss/critic2                       | 14.9      |
| timestep                           | 2277000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2804
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0249  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2278000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2860
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.048    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2279000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.02    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2280000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2936
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0483  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2281000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2859
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0176  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2282000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2905
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00947  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2283000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.2     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0852  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2284000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 6.95     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0996   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2285000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00122 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2286000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 13.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00777 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2287000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.2     |
| eval/normalized_episode_reward_std | 27.6     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0224  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2288000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2794
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 2.98     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0461   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2289000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2919
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2290000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0254   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2291000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2852
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0838  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2292000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3034
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 7.56     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0299  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2293000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0366   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2294000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2829
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0358   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2295000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2980
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 15.4     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0479  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2296000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2891
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0423  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2297000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2985
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.125    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2298000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0998   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2299000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0492  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.4     |
| timestep                           | 2300000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 8.01     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.032    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 2301000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00742 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2302000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2891
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.2     |
| eval/normalized_episode_reward_std | 31.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.108   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2303000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.4     |
| eval/normalized_episode_reward_std | 28.4     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0107  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2304000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0427   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2305000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 26.6     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0358   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 2306000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 8.26     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0387  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2307000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0077   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2308000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2800
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0068  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2309000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2857
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79       |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0805   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2310000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3018
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 25.6     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00741 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2311000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2841
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0468   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2312000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2927
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0768  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2313000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2866
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0385   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2314000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2829
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00197 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 2315000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2865
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0358   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2316000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2830
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0388  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 2317000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3048
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79       |
| eval/normalized_episode_reward_std | 3.95     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0625   |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 2318000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.4     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0378  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 2319000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2857
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 10.3     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.042   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.9     |
| timestep                           | 2320000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2859
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0797  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2321000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0972  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2322000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2887
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63       |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0502  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2323000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2919
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 8.72     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.106    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2324000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2807
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.075    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2325000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2928
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0477   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 2326000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2857
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0158  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 2327000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0628   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2328000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2948
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80       |
| eval/normalized_episode_reward_std | 3.54     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0564  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2329000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2894
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0915  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2330000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00511 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2331000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.208   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2332000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0404   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2333000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 20.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0809   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2334000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2996
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80       |
| eval/normalized_episode_reward_std | 5.23     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0162   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2335000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3020
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0707   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2336000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0357   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2337000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0937  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2338000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2921
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.032    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2339000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0603   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 2340000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3033
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0308  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2341000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2836
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00143 |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 2342000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2864
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 5.62     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0294  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2343000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 9.56     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0244   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2344000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0269   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2345000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0192   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15.1     |
| timestep                           | 2346000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2871
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 5.14     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0313   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2347000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2947
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00108  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2348000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.2     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0335   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2349000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0386   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2350000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 8.29     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0591  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2351000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2789
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0673  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2352000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0477   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2353000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3107
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0518  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2354000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0493   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2355000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2891
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.07    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2356000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2811
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0015   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2357000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0366   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2358000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2800
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0227  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2359000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00851 |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2360000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2828
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0409   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2361000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2762
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0251  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2362000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2935
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0202   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2363000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2915
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0229   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 2364000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3004
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0281   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2365000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0534  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2366000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0541   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 2367000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2746
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.9     |
| eval/normalized_episode_reward_std | 29.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0359   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2368000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2875
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64       |
| eval/normalized_episode_reward_std | 27       |
| loss/actor                         | -671     |
| loss/alpha                         | -0.105   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2369000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2881
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0744   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2370000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2842
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0853  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2371000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
-----------------------------------------------------------------------------------
| alpha                              | 0.155     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 70.4      |
| eval/normalized_episode_reward_std | 21        |
| loss/actor                         | -671      |
| loss/alpha                         | -0.000238 |
| loss/critic1                       | 14        |
| loss/critic2                       | 14        |
| timestep                           | 2372000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0846   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2373000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2963
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 26.4     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00143  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2374000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0434   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2375000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0476  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2376000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2936
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.121   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2377000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2915
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 24.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0206   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2378000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2877
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0644   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2379000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 25.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.049   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2380000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 26.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.115    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2381000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0841  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2382000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2947
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00731 |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 2383000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 25       |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0511  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2384000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0246   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2385000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0569   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2386000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2862
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 25.6     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0949  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2387000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0408   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2388000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0866   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2389000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2868
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0264  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2390000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2927
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 6.2      |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0468  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2391000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0202  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2392000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2914
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0428   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2393000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2815
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.107    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2394000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2844
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0416  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2395000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2827
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 12.6     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.059   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2396000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3018
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 55.5     |
| eval/normalized_episode_reward_std | 31.2     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00962 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2397000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2919
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.7     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0496  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2398000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2947
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0135  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2399000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2975
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0528  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2400000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3025
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.9     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0178   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2401000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3054
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0337  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2402000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.3     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0623   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2403000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0438  |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.3     |
| timestep                           | 2404000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2922
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0609   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.5     |
| timestep                           | 2405000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2909
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.7     |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.00419  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2406000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 7.69     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0552  |
| loss/critic1                       | 13.2     |
| loss/critic2                       | 13.2     |
| timestep                           | 2407000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2814
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0173   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2408000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2980
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00224 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2409000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2825
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80       |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0307   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2410000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0022   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2411000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3016
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.9     |
| eval/normalized_episode_reward_std | 33.6     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0156   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2412000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2966
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.2     |
| eval/normalized_episode_reward_std | 24.5     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00949 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2413000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.0236  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2414000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3028
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -670     |
| loss/alpha                         | 0.0208   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2415000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2958
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -670     |
| loss/alpha                         | -0.00708 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2416000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2894
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.8     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0828   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2417000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2821
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.2     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0907   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2418000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2849
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.6     |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00872 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14.1     |
| timestep                           | 2419000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2795
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80       |
| eval/normalized_episode_reward_std | 3.19     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0411  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2420000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 14.7     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0268  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2421000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2925
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0104  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 2422000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2824
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0498  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2423000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2898
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0351  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2424000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2936
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.3     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0745  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2425000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.076   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2426000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3034
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 27.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0389   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2427000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2897
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.158    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2428000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.00195 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2429000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2989
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0406  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2430000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2878
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0576   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2431000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2896
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.4     |
| eval/normalized_episode_reward_std | 29       |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0685   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2432000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2872
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0139   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2433000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2740
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 8.69     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0208  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2434000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2836
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.2     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.102    |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2435000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.161    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0703  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2436000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2965
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0195  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2437000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2874
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.5     |
| eval/normalized_episode_reward_std | 28.5     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0727   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2438000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2992
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0693  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2439000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2935
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 3.24     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0764  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2440000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.7      |
| loss/actor                         | -671     |
| loss/alpha                         | -0.02    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2441000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2919
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 25.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0486  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2442000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2894
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0803  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2443000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.1      |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00475  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2444000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2936
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 3.16     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.056    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2445000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2968
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0627   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2446000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2822
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 6.16     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0151   |
| loss/critic1                       | 13.3     |
| loss/critic2                       | 13.2     |
| timestep                           | 2447000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2820
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.4     |
| eval/normalized_episode_reward_std | 4.62     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00133 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2448000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2989
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0413  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2449000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0611  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2450000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2991
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0286   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2451000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3063
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.5     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0339   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2452000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2875
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.5     |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -672     |
| loss/alpha                         | 9.47e-05 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2453000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2839
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.051   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2454000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 27.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0406   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2455000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00884  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2456000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2927
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 9.13     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00624 |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2457000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2810
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.62     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0516  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 2458000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3040
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.007    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2459000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0151  |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 16       |
| timestep                           | 2460000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2999
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.31     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00263 |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2461000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2809
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 8.12     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0128   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2462000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3006
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.32     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0563   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2463000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3058
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 9.5      |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0131  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2464000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2903
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0247   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.6     |
| timestep                           | 2465000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3125
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.2     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00229  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2466000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3043
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0429  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2467000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3024
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 2.86     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00815 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2468000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00496 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2469000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2816
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.5     |
| eval/normalized_episode_reward_std | 31.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0137   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2470000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2959
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0392  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2471000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3002
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00163  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2472000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0264   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 14       |
| timestep                           | 2473000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3068
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0531  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2474000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0684  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2475000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.047    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2476000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 20.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0962   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2477000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2928
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0264   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2478000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2927
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.9     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0686   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2479000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 14.6     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0301  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2480000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 4.2      |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0588  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2481000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2975
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 12.3     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00699 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2482000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.1      |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2483000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0575  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2484000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2977
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0119  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2485000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0715  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2486000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 11       |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00425  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2487000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3018
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00945 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2488000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.9     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0834   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2489000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2960
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00894  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2490000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3049
-----------------------------------------------------------------------------------
| alpha                              | 0.155     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 73.6      |
| eval/normalized_episode_reward_std | 16.7      |
| loss/actor                         | -672      |
| loss/alpha                         | -0.000879 |
| loss/critic1                       | 14.4      |
| loss/critic2                       | 14.4      |
| timestep                           | 2491000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2992
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.1     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0653  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2492000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3070
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 16.7     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0273  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2493000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2987
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0918   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2494000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3005
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0669  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2495000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3094
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0786   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2496000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.6     |
| eval/normalized_episode_reward_std | 27.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0209   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2497000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3027
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 22.3     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0723  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2498000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3095
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.07     |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2499000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3073
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0618  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2500000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.132   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2501000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2948
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 24.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.00345  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2502000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2954
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.72     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0335  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2503000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3080
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.141    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 2504000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.171    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2505000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2790
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0704  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 2506000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 9.19     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0865  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2507000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2897
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 25.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0489   |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 2508000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2935
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0171  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2509000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 15.1     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0392  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2510000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3038
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0204  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2511000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2833
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0874   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2512000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.000157 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2513000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 8.26     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0634  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2514000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3000
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0176  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2515000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2903
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.1     |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0372   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2516000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2928
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0449  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2517000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 17.6     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0343   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2518000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 9.62     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0381   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2519000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2917
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 6.77     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0518   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2520000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3005
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 8.74     |
| loss/actor                         | -671     |
| loss/alpha                         | 0.0238   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2521000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -671     |
| loss/alpha                         | -0.0618  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2522000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62       |
| eval/normalized_episode_reward_std | 31.5     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.105   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2523000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3052
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.134    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2524000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0292   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2525000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.3     |
| eval/normalized_episode_reward_std | 4        |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0727  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2526000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2845
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.2     |
| eval/normalized_episode_reward_std | 3.61     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.062    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2527000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2793
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.4     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00343 |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15.1     |
| timestep                           | 2528000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2862
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.4     |
| eval/normalized_episode_reward_std | 33       |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0478  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2529000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2996
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0304  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2530000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3005
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00317  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2531000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3039
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.6     |
| eval/normalized_episode_reward_std | 29.7     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0956  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2532000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2860
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00217  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2533000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3062
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61       |
| eval/normalized_episode_reward_std | 28.1     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00509  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2534000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3029
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.6     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0133   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.5     |
| timestep                           | 2535000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 26.5     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.103    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2536000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 14.2     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0401   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2537000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2886
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.1     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00768 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2538000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2819
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 2.97     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.028   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2539000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0127   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2540000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 9.57     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0337   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2541000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2930
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 17.4     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0756  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2542000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2877
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00434 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2543000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0098   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2544000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0564  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2545000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0226  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2546000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.06     |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2547000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2841
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0358   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2548000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2859
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.5     |
| eval/normalized_episode_reward_std | 6.98     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.008    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2549000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2990
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 9.43     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0652  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.5     |
| timestep                           | 2550000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2989
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.8     |
| eval/normalized_episode_reward_std | 29.9     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0205   |
| loss/critic1                       | 16.2     |
| loss/critic2                       | 16.1     |
| timestep                           | 2551000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 4.17     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0186   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2552000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0299   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2553000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00323 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2554000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00714  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2555000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2944
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00769 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2556000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3003
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00678 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2557000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3014
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0228   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2558000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3012
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.3     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0353  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2559000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00729 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2560000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2791
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0144   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2561000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2963
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 19       |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0881  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2562000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00252 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2563000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2886
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.132    |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2564000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.08     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0149   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.1     |
| timestep                           | 2565000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2821
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 9.46     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0731  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2566000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.036   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2567000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2880
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0557  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2568000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2925
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0844   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2569000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3051
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0875   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2570000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.7     |
| eval/normalized_episode_reward_std | 26.7     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0348  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2571000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2944
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0103  |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.3     |
| timestep                           | 2572000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3071
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0937  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2573000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2904
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0031  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2574000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 6.64     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0119   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2575000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0435  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2576000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2989
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.3     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.000562 |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2577000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0562   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2578000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3033
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 11       |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0149   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2579000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.18     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.044   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2580000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2893
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 56.4     |
| eval/normalized_episode_reward_std | 28.6     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0318  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2581000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 13       |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00402  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2582000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2973
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.7     |
| eval/normalized_episode_reward_std | 25.8     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.129    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2583000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.1     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0186   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2584000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2961
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 4.51     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.116   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2585000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3073
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 5.8      |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00688 |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2586000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3053
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0319   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2587000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.8     |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0229  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2588000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3019
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0588   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2589000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2895
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0204  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2590000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2999
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0862  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2591000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 7.69     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00254  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2592000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2991
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0356   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2593000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0429  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2594000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3178
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0758   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2595000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2979
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60       |
| eval/normalized_episode_reward_std | 31.4     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0101  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2596000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 23.7     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0704   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2597000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2894
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0491   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2598000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3102
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67       |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0954  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2599000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 14       |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0471   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2600000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0472  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2601000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3009
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0618   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2602000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3112
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 5.23     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0362  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2603000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 13.8     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0302   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 2604000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2864
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 7.76     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0149  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2605000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2960
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.126   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2606000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3079
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0746   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2607000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3060
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0197   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2608000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2986
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 4.77     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0896   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2609000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.6     |
| eval/normalized_episode_reward_std | 2.94     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.022   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2610000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.1     |
| eval/normalized_episode_reward_std | 28       |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0728   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.8     |
| timestep                           | 2611000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0737  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2612000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 9.21     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0288   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2613000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0185   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2614000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00792 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 2615000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2855
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0996  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2616000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2815
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.3     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0154  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2617000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2860
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0463  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2618000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3142
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 10       |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0276   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2619000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2921
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0455   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2620000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2897
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0481   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.8     |
| timestep                           | 2621000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.1     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0523  |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 2622000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2947
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.1     |
| eval/normalized_episode_reward_std | 31       |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0335  |
| loss/critic1                       | 15.9     |
| loss/critic2                       | 15.8     |
| timestep                           | 2623000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 2.95     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.079    |
| loss/critic1                       | 16       |
| loss/critic2                       | 15.9     |
| timestep                           | 2624000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3030
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80       |
| eval/normalized_episode_reward_std | 3.23     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0699   |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.3     |
| timestep                           | 2625000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.7     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0779  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2626000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2877
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 25.6     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00255 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2627000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3028
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.4     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0792  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2628000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 4.98     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.124    |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2629000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2802
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 6.37     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0653   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 15       |
| timestep                           | 2630000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.4     |
| eval/normalized_episode_reward_std | 28.1     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0183  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 2631000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2989
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 4.14     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0432  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2632000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2990
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 4.21     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0791  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2633000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2814
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 24.8     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0196   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2634000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.2     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0642   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2635000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2880
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0637  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2636000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2992
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.1     |
| eval/normalized_episode_reward_std | 26       |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0298  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2637000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3040
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 18.9     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00107 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2638000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00591  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2639000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2857
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 17.5     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0218   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2640000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 16.1     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0069   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2641000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2999
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 14.5     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.052    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2642000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 27.7     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0191  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2643000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2995
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0153   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2644000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2901
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.7     |
| eval/normalized_episode_reward_std | 4.44     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0487  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2645000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2980
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 6.42     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.125   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2646000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0393   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.7     |
| timestep                           | 2647000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.1     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0549  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2648000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2909
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.2     |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0422  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2649000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2943
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0622  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2650000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2964
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -674     |
| loss/alpha                         | 0.118    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.3     |
| timestep                           | 2651000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2948
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0575  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 2652000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 16.4     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0519   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2653000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2874
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0113  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 2654000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2960
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.05     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.026   |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2655000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2966
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.73     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0524   |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.5     |
| timestep                           | 2656000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
-----------------------------------------------------------------------------------
| alpha                              | 0.153     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 72.4      |
| eval/normalized_episode_reward_std | 23.5      |
| loss/actor                         | -673      |
| loss/alpha                         | -0.000123 |
| loss/critic1                       | 14.1      |
| loss/critic2                       | 14        |
| timestep                           | 2657000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3080
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.8     |
| eval/normalized_episode_reward_std | 3.38     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0589  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2658000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3073
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.3     |
| eval/normalized_episode_reward_std | 3.28     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00272 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2659000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3086
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0104   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2660000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 3.64     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.033    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2661000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3027
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0727   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2662000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3043
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 58.1     |
| eval/normalized_episode_reward_std | 30.4     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0108   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2663000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3017
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.028   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2664000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2948
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0265  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2665000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3036
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 22.2     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.13    |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2666000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3043
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.8     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0976   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2667000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2668000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2851
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0343   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2669000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2961
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.4     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0235  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2670000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.7     |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.00365  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2671000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.9     |
| eval/normalized_episode_reward_std | 27.1     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0157  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2672000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2982
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00108 |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2673000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3038
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0263   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2674000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3002
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 11.2     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0171   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2675000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3001
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00977  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2676000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3071
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.5     |
| eval/normalized_episode_reward_std | 22.8     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0269  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2677000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2959
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.77     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0725  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2678000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2948
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.044    |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2679000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2875
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79       |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0119  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2680000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 21.1     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0414  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2681000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.3     |
| eval/normalized_episode_reward_std | 3.29     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0543  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2682000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 27.1     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0125  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2683000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.033   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.8     |
| timestep                           | 2684000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2852
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0668  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2685000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0912   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2686000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.00821 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2687000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.3     |
| eval/normalized_episode_reward_std | 25.9     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.119    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2688000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2992
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.8     |
| eval/normalized_episode_reward_std | 9.17     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0345  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2689000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 19.5     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0458   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2690000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2950
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 25.7     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.014   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2691000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2996
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 25.1     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.0184   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2692000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 20.4     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0215  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2693000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2837
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.3     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0296  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2694000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -672     |
| loss/alpha                         | 0.00827  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2695000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.3     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0332  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2696000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2938
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -672     |
| loss/alpha                         | -0.0305  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2697000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2947
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 9.8      |
| loss/actor                         | -672     |
| loss/alpha                         | 0.112    |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2698000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3030
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0304  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2699000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2912
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 57.8     |
| eval/normalized_episode_reward_std | 30.1     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0195   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2700000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3014
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.7     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.105    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2701000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2974
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.5     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00778 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2702000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2917
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.6     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00524 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2703000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2874
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 23.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0395   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2704000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2838
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0357  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2705000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2959
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 26       |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0547   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2706000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2855
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 18.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0109   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2707000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2954
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0468   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2708000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2709000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3045
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 11.6     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0203   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2710000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 18       |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0834  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2711000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2874
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0274   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2712000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0199   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2713000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2984
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.9     |
| eval/normalized_episode_reward_std | 30.6     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00821  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2714000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2798
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0255   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2715000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 12.7     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0571  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2716000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2919
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00639 |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2717000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2905
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 11.9     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00417 |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 2718000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2985
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.5     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00901 |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2719000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.3     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00446 |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.2     |
| timestep                           | 2720000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3070
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0677   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2721000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.72     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0508   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2722000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00605  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2723000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3064
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0378  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2724000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2927
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.7     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0465  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2725000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2964
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.4     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -675     |
| loss/alpha                         | -0.113   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2726000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0139   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2727000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2938
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.2     |
| eval/normalized_episode_reward_std | 21.9     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0605   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2728000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00436 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2729000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0541  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2730000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0165   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2731000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2979
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0369  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2732000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.112    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2733000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2880
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2734000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.6     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0137  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2735000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0362  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2736000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.7     |
| eval/normalized_episode_reward_std | 25.4     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.119   |
| loss/critic1                       | 13.4     |
| loss/critic2                       | 13.4     |
| timestep                           | 2737000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0415  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2738000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2981
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 3.22     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.132    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2739000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2979
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.032   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2740000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.2     |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00445 |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2741000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.8     |
| eval/normalized_episode_reward_std | 8        |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0298  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2742000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80       |
| eval/normalized_episode_reward_std | 3.34     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0493   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2743000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2915
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 3.57     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0242  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2744000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2928
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.6     |
| eval/normalized_episode_reward_std | 3.07     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0171   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2745000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.15     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.021    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2746000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2724
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.9     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0517   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2747000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.5     |
| eval/normalized_episode_reward_std | 3.99     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0881  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2748000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2952
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 9.33     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.026   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2749000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2982
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.8     |
| eval/normalized_episode_reward_std | 26.3     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0178  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2750000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 81.1     |
| eval/normalized_episode_reward_std | 3.26     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0302   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2751000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 3.4      |
| loss/actor                         | -674     |
| loss/alpha                         | 0.031    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 2752000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 6.25     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0321   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2753000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2902
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.7     |
| eval/normalized_episode_reward_std | 3.43     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0166  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15       |
| timestep                           | 2754000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.6     |
| eval/normalized_episode_reward_std | 10.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0291  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 2755000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.7     |
| eval/normalized_episode_reward_std | 11.7     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0215   |
| loss/critic1                       | 17       |
| loss/critic2                       | 16.8     |
| timestep                           | 2756000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2973
----------------------------------------------------------------------------------
| alpha                              | 0.159    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.8     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.107    |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 2757000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3016
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.6     |
| eval/normalized_episode_reward_std | 22       |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0307  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2758000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2863
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 7.48     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0668  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2759000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3018
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.8     |
| eval/normalized_episode_reward_std | 27.8     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0503  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2760000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.2     |
| eval/normalized_episode_reward_std | 31.6     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.036   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2761000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2989
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0324   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2762000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.4     |
| eval/normalized_episode_reward_std | 3.86     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0022   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2763000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2932
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 22.6     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.012    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2764000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3070
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 18.7     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0167  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2765000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.5     |
| eval/normalized_episode_reward_std | 26.6     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0166   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2766000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2959
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 14.8     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0391  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2767000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2950
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.6     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0548   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2768000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2947
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 5.29     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0643  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2769000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2860
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00995 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2770000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2949
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.2     |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0154   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2771000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3044
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.5     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0469   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2772000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2958
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 16.2     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0241  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2773000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2986
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00231 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2774000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 6.7      |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00417  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2775000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2901
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 23.4     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0145  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.8     |
| timestep                           | 2776000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.45     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0171   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2777000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0166   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2778000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2896
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 6.45     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00268  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2779000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 4.39     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.00726  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2780000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2808
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70       |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0715  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2781000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.9     |
| eval/normalized_episode_reward_std | 15.3     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0131  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2782000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 25.5     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0196  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2783000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2841
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0434   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2784000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2915
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0551  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2785000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2980
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 16.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0171   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2786000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2901
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0435   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2787000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2959
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0105  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2788000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3032
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.2     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0942   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2789000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2843
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 17.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0473  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2790000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0366  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2791000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2990
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 27.6     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.026    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2792000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2882
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.67     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0247  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2793000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2986
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00132 |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2794000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2813
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.81     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.125    |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.1     |
| timestep                           | 2795000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2847
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.8     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.086   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2796000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2877
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0804  |
| loss/critic1                       | 13.1     |
| loss/critic2                       | 13.1     |
| timestep                           | 2797000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3008
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 20.7     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0252  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2798000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0113   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.8     |
| timestep                           | 2799000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 24.4     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.066   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 2800000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.132    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2801000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2991
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.9     |
| eval/normalized_episode_reward_std | 5.81     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0764   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2802000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77       |
| eval/normalized_episode_reward_std | 9.25     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.124   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2803000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2982
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.6     |
| eval/normalized_episode_reward_std | 26       |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0458  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2804000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2991
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.09     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.132    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2805000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2950
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.3     |
| eval/normalized_episode_reward_std | 25.9     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0845   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2806000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3063
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 50.2     |
| eval/normalized_episode_reward_std | 33.4     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00948 |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2807000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 12.5     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.121   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2808000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.8     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.048   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.2     |
| timestep                           | 2809000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.6     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0182  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2810000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3006
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 11.5     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.013    |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2811000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3028
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.5     |
| eval/normalized_episode_reward_std | 24.2     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.168    |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2812000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2899
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.009   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2813000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2742
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.5     |
| eval/normalized_episode_reward_std | 12.8     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0283  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 2814000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 4.01     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.118   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2815000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2923
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 18.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0518  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2816000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2874
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.5     |
| eval/normalized_episode_reward_std | 21.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.129    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2817000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3028
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.8     |
| eval/normalized_episode_reward_std | 4.76     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00727 |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.7     |
| timestep                           | 2818000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2889
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.04     |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2819000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2961
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.8     |
| eval/normalized_episode_reward_std | 25.6     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0421   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2820000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2979
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0304  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2821000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2943
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.7     |
| eval/normalized_episode_reward_std | 11.8     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.122   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2822000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 11.9     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0846  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2823000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 19.3     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0284   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2824000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.5     |
| eval/normalized_episode_reward_std | 28.9     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0117   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2825000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.53     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0234   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2826000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.8     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0322  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.5     |
| timestep                           | 2827000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2954
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.9     |
| eval/normalized_episode_reward_std | 7.42     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0616   |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2828000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2934
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 13.1     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.03     |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2829000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3056
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 16.6     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0486  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2830000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 10.6     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0536   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2831000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3006
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 63.9     |
| eval/normalized_episode_reward_std | 27.9     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0201  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2832000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2956
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.4     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00834 |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2833000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2871
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.7     |
| eval/normalized_episode_reward_std | 3.01     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.00644 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2834000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 5.75     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.023    |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2835000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2973
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 10.9     |
| loss/actor                         | -673     |
| loss/alpha                         | 0.0533   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2836000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3054
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72       |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0413  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 2837000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2893
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61       |
| eval/normalized_episode_reward_std | 25.5     |
| loss/actor                         | -673     |
| loss/alpha                         | -0.0192  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2838000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2990
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 9.91     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0231  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2839000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2921
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66.4     |
| eval/normalized_episode_reward_std | 28.5     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0947   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2840000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2896
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.0312   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2841000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3011
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.3     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0948  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2842000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.2     |
| eval/normalized_episode_reward_std | 29.1     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.109   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2843000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3007
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0341  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.7     |
| timestep                           | 2844000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3055
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.33     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0242  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2845000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 19.2     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.111    |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.6     |
| timestep                           | 2846000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3089
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.7     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -674     |
| loss/alpha                         | 0.117    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2847000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.47     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0407  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2848000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2998
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.7     |
| eval/normalized_episode_reward_std | 3.51     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0591  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2849000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2883
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 9.24     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.0134  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2850000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2997
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 2.99     |
| loss/actor                         | -674     |
| loss/alpha                         | -0.00243 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2851000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69       |
| eval/normalized_episode_reward_std | 17.9     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0171  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2852000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2869
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 61.9     |
| eval/normalized_episode_reward_std | 26.8     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0556   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2853000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2861
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 5.95     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0923   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2854000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2876
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.5     |
| eval/normalized_episode_reward_std | 29.5     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.077   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2855000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2880
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 10.5     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.00953 |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2856000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2975
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.9     |
| eval/normalized_episode_reward_std | 27.9     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0127  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2857000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2943
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0303  |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.7     |
| timestep                           | 2858000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2911
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.3     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0356  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2859000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2879
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0412   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2860000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71       |
| eval/normalized_episode_reward_std | 22.5     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.005    |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2861000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2979
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 18.4     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00318 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2862000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.6     |
| eval/normalized_episode_reward_std | 11.1     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.129    |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2863000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2914
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 12.4     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0667  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2864000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2992
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0731   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2865000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2853
-----------------------------------------------------------------------------------
| alpha                              | 0.157     |
| eval/episode_length                | 1e+03     |
| eval/episode_length_std            | 0         |
| eval/normalized_episode_reward     | 65.3      |
| eval/normalized_episode_reward_std | 30.2      |
| loss/actor                         | -676      |
| loss/alpha                         | -0.000674 |
| loss/critic1                       | 13.9      |
| loss/critic2                       | 13.8      |
| timestep                           | 2866000   |
-----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0794  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2867000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 14.4     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0679  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.2     |
| timestep                           | 2868000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2929
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 19.7     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.034   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2869000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 5.31     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0495   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2870000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 15.6     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.00262  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2871000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2908
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.6     |
| eval/normalized_episode_reward_std | 31.7     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0413  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2872000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3023
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.25     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0423  |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.5     |
| timestep                           | 2873000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2893
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.00332  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2874000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3046
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.4     |
| eval/normalized_episode_reward_std | 3.02     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.028    |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2875000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2959
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.7     |
| eval/normalized_episode_reward_std | 19.1     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0508   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2876000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2903
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0768   |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 14.9     |
| timestep                           | 2877000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2849
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0756   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2878000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2848
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.9     |
| eval/normalized_episode_reward_std | 15.2     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0972  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2879000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2942
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.248   |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.2     |
| timestep                           | 2880000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2873
----------------------------------------------------------------------------------
| alpha                              | 0.145    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0903  |
| loss/critic1                       | 16.9     |
| loss/critic2                       | 16.8     |
| timestep                           | 2881000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2850
----------------------------------------------------------------------------------
| alpha                              | 0.143    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.3     |
| eval/normalized_episode_reward_std | 21.7     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0589  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 2882000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2930
----------------------------------------------------------------------------------
| alpha                              | 0.144    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 19.6     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.164    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.4     |
| timestep                           | 2883000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.9     |
| eval/normalized_episode_reward_std | 20.8     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.141    |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.6     |
| timestep                           | 2884000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2982
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 23.6     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.131    |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2885000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3009
----------------------------------------------------------------------------------
| alpha                              | 0.158    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 59.2     |
| eval/normalized_episode_reward_std | 28.7     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.101    |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2886000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3066
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 7.05     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0731   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2887000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2944
----------------------------------------------------------------------------------
| alpha                              | 0.16     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.14     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0861  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2888000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.4     |
| eval/normalized_episode_reward_std | 21.6     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.168   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2889000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2888
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 13.7     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0676  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2890000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2948
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.5     |
| eval/normalized_episode_reward_std | 21.8     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0426   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2891000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2986
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 26.1     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0403   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2892000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2973
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 13.4     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0151   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2893000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 3.58     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.000596 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2894000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2906
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.63     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0529  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2895000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3036
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75       |
| eval/normalized_episode_reward_std | 16.8     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0563  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2896000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2917
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.8     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0649  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2897000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2916
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.1     |
| eval/normalized_episode_reward_std | 21.2     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0359   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14       |
| timestep                           | 2898000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.1     |
| eval/normalized_episode_reward_std | 9.91     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0825   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2899000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.5     |
| eval/normalized_episode_reward_std | 9.99     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.0714   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.2     |
| timestep                           | 2900000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2877
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.3     |
| eval/normalized_episode_reward_std | 20       |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0129   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2901000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2978
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 24       |
| loss/actor                         | -675     |
| loss/alpha                         | -0.0777  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.3     |
| timestep                           | 2902000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2962
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 3.04     |
| loss/actor                         | -675     |
| loss/alpha                         | 0.00582  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2903000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2852
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.2     |
| eval/normalized_episode_reward_std | 3.21     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0152   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.6     |
| timestep                           | 2904000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2885
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 28.7     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.00113  |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2905000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 2.91     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.033   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2906000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2918
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 15.7     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.03     |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2907000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2985
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.7     |
| eval/normalized_episode_reward_std | 14.3     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0512   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2908000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.4     |
| eval/normalized_episode_reward_std | 2.92     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0115   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2909000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2964
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.6     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0144  |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2910000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2887
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.6     |
| eval/normalized_episode_reward_std | 28.7     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0311  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2911000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.6     |
| eval/normalized_episode_reward_std | 20.9     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.00345 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2912000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3047
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.1     |
| eval/normalized_episode_reward_std | 19.9     |
| loss/actor                         | -676     |
| loss/alpha                         | 0.0605   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2913000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2951
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.4     |
| eval/normalized_episode_reward_std | 17.1     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0383  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2914000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2917
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.3     |
| eval/normalized_episode_reward_std | 7.35     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.0309  |
| loss/critic1                       | 13.5     |
| loss/critic2                       | 13.4     |
| timestep                           | 2915000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3030
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74       |
| eval/normalized_episode_reward_std | 21.3     |
| loss/actor                         | -676     |
| loss/alpha                         | -0.093   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 13.9     |
| timestep                           | 2916000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2985
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.5     |
| eval/normalized_episode_reward_std | 14.1     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0102  |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2917000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3005
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.3     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0387   |
| loss/critic1                       | 13.7     |
| loss/critic2                       | 13.6     |
| timestep                           | 2918000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.3     |
| eval/normalized_episode_reward_std | 26.8     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0145   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2919000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2961
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.7     |
| eval/normalized_episode_reward_std | 21       |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00485 |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.7     |
| timestep                           | 2920000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2946
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.8     |
| eval/normalized_episode_reward_std | 18.3     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0575   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2921000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2904
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.6     |
| eval/normalized_episode_reward_std | 3.13     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0507   |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2922000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2894
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 10.4     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0172   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2923000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3046
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0175   |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2924000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.3     |
| eval/normalized_episode_reward_std | 8.14     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0416  |
| loss/critic1                       | 14       |
| loss/critic2                       | 13.9     |
| timestep                           | 2925000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2995
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 17.7     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0627  |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2926000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3013
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.2     |
| eval/normalized_episode_reward_std | 6.14     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0356  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2927000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3057
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.37     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0271  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2928000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0383   |
| loss/critic1                       | 13.8     |
| loss/critic2                       | 13.9     |
| timestep                           | 2929000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2949
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.2     |
| eval/normalized_episode_reward_std | 11.3     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0802   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.8     |
| timestep                           | 2930000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3051
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.1     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0384   |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14       |
| timestep                           | 2931000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2931
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.52     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0186   |
| loss/critic1                       | 13.6     |
| loss/critic2                       | 13.6     |
| timestep                           | 2932000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3009
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.9     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00845  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2933000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2864
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 5.56     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0294  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2934000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2983
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.1     |
| eval/normalized_episode_reward_std | 3.96     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0388   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2935000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2910
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.1     |
| eval/normalized_episode_reward_std | 10.1     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0285   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2936000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2985
----------------------------------------------------------------------------------
| alpha                              | 0.157    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.7     |
| eval/normalized_episode_reward_std | 3.44     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0461  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2937000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.03     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0753  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.7     |
| timestep                           | 2938000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0552  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.4     |
| timestep                           | 2939000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2834
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.2     |
| eval/normalized_episode_reward_std | 20.5     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0231  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2940000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2986
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.7     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00301  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2941000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3007
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78       |
| eval/normalized_episode_reward_std | 9        |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0466   |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2942000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2922
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 5.79     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0135  |
| loss/critic1                       | 14.1     |
| loss/critic2                       | 14.1     |
| timestep                           | 2943000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2945
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.5     |
| eval/normalized_episode_reward_std | 27.2     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0298   |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.5     |
| timestep                           | 2944000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2954
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.9     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0435   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2945000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2963
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.4     |
| eval/normalized_episode_reward_std | 4.31     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0347   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2946000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2922
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 17.2     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0149   |
| loss/critic1                       | 15.8     |
| loss/critic2                       | 15.7     |
| timestep                           | 2947000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2957
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.3      |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0309  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.6     |
| timestep                           | 2948000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.4     |
| eval/normalized_episode_reward_std | 3.56     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0318  |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.3     |
| timestep                           | 2949000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2867
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.2     |
| eval/normalized_episode_reward_std | 22.7     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0162  |
| loss/critic1                       | 15.7     |
| loss/critic2                       | 15.7     |
| timestep                           | 2950000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2956
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.1     |
| eval/normalized_episode_reward_std | 21.4     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0381   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 2951000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2971
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.4     |
| eval/normalized_episode_reward_std | 12.2     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00106  |
| loss/critic1                       | 15.6     |
| loss/critic2                       | 15.5     |
| timestep                           | 2952000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2981
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.2     |
| eval/normalized_episode_reward_std | 23.2     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00826 |
| loss/critic1                       | 15.5     |
| loss/critic2                       | 15.5     |
| timestep                           | 2953000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.5     |
| eval/normalized_episode_reward_std | 3.49     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.00296  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2954000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2919
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.6     |
| eval/normalized_episode_reward_std | 3.85     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.0218   |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.5     |
| timestep                           | 2955000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2970
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.9     |
| eval/normalized_episode_reward_std | 3.36     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0163  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.2     |
| timestep                           | 2956000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2955
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.5     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0464  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 2957000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3019
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 62.9     |
| eval/normalized_episode_reward_std | 29.5     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0347  |
| loss/critic1                       | 15.1     |
| loss/critic2                       | 15       |
| timestep                           | 2958000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3052
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0344  |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.3     |
| timestep                           | 2959000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2953
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76       |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0832  |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.6     |
| timestep                           | 2960000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2989
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.9     |
| eval/normalized_episode_reward_std | 22.1     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0502  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2961000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2969
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 22.4     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0364  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2962000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2896
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 18.6     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0425   |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.8     |
| timestep                           | 2963000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2908
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.8     |
| eval/normalized_episode_reward_std | 20.2     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.00934  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2964000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.5     |
| eval/normalized_episode_reward_std | 3.5      |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0589   |
| loss/critic1                       | 14.7     |
| loss/critic2                       | 14.7     |
| timestep                           | 2965000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2850
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.1     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0603   |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.5     |
| timestep                           | 2966000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2926
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 23.3     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.00864  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.8     |
| timestep                           | 2967000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2892
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60.4     |
| eval/normalized_episode_reward_std | 27.3     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.0293   |
| loss/critic1                       | 13.9     |
| loss/critic2                       | 13.9     |
| timestep                           | 2968000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3056
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.3     |
| eval/normalized_episode_reward_std | 15       |
| loss/actor                         | -679     |
| loss/alpha                         | 0.04     |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.6     |
| timestep                           | 2969000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2864
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 79.3     |
| eval/normalized_episode_reward_std | 5.07     |
| loss/actor                         | -679     |
| loss/alpha                         | 0.00382  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2970000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2927
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 64.5     |
| eval/normalized_episode_reward_std | 25.6     |
| loss/actor                         | -679     |
| loss/alpha                         | -0.0184  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2971000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2966
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.4     |
| eval/normalized_episode_reward_std | 23       |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0104   |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2972000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2915
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 66       |
| eval/normalized_episode_reward_std | 25.3     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.022    |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.1     |
| timestep                           | 2973000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2900
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 17.3     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0214   |
| loss/critic1                       | 14       |
| loss/critic2                       | 14.1     |
| timestep                           | 2974000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2861
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.2     |
| eval/normalized_episode_reward_std | 26.9     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0249   |
| loss/critic1                       | 15.2     |
| loss/critic2                       | 15.1     |
| timestep                           | 2975000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2994
----------------------------------------------------------------------------------
| alpha                              | 0.156    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.6     |
| eval/normalized_episode_reward_std | 14.9     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.00236 |
| loss/critic1                       | 15.4     |
| loss/critic2                       | 15.4     |
| timestep                           | 2976000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2972
----------------------------------------------------------------------------------
| alpha                              | 0.155    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.6     |
| eval/normalized_episode_reward_std | 15.9     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0292  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2977000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2924
----------------------------------------------------------------------------------
| alpha                              | 0.154    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.2     |
| eval/normalized_episode_reward_std | 8.97     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0319  |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.3     |
| timestep                           | 2978000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2940
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68       |
| eval/normalized_episode_reward_std | 26.2     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00872 |
| loss/critic1                       | 14.2     |
| loss/critic2                       | 14.2     |
| timestep                           | 2979000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2937
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 70.6     |
| eval/normalized_episode_reward_std | 23.9     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0349  |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.1     |
| timestep                           | 2980000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2939
----------------------------------------------------------------------------------
| alpha                              | 0.153    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 60       |
| eval/normalized_episode_reward_std | 28       |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00885  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2981000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2933
----------------------------------------------------------------------------------
| alpha                              | 0.152    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.9     |
| eval/normalized_episode_reward_std | 19.4     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0124  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2982000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3004
----------------------------------------------------------------------------------
| alpha                              | 0.151    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73.2     |
| eval/normalized_episode_reward_std | 22.9     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0474  |
| loss/critic1                       | 14.8     |
| loss/critic2                       | 14.9     |
| timestep                           | 2983000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3035
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 68.5     |
| eval/normalized_episode_reward_std | 23.1     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0278  |
| loss/critic1                       | 15       |
| loss/critic2                       | 14.9     |
| timestep                           | 2984000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3009
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.7     |
| eval/normalized_episode_reward_std | 13.9     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00425 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2985000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2920
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.2     |
| eval/normalized_episode_reward_std | 3.46     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0133  |
| loss/critic1                       | 14.9     |
| loss/critic2                       | 14.9     |
| timestep                           | 2986000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2907
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.8     |
| eval/normalized_episode_reward_std | 23.8     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0493  |
| loss/critic1                       | 15.3     |
| loss/critic2                       | 15.3     |
| timestep                           | 2987000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2964
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 78.6     |
| eval/normalized_episode_reward_std | 6.09     |
| loss/actor                         | -677     |
| loss/alpha                         | 0.00217  |
| loss/critic1                       | 14.5     |
| loss/critic2                       | 14.4     |
| timestep                           | 2988000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2967
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 72.5     |
| eval/normalized_episode_reward_std | 18.8     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.00325 |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.4     |
| timestep                           | 2989000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2993
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 71.8     |
| eval/normalized_episode_reward_std | 20.1     |
| loss/actor                         | -677     |
| loss/alpha                         | -0.0097  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2990000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3008
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 73       |
| eval/normalized_episode_reward_std | 24.1     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0132   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2991000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2944
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 76.4     |
| eval/normalized_episode_reward_std | 16.3     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0298   |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.6     |
| timestep                           | 2992000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.3036
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 74.4     |
| eval/normalized_episode_reward_std | 18.2     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.0363   |
| loss/critic1                       | 15       |
| loss/critic2                       | 15       |
| timestep                           | 2993000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2941
----------------------------------------------------------------------------------
| alpha                              | 0.15     |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 15.8     |
| loss/actor                         | -678     |
| loss/alpha                         | 0.000279 |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.4     |
| timestep                           | 2994000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2976
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 80.1     |
| eval/normalized_episode_reward_std | 3.17     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.04    |
| loss/critic1                       | 14.3     |
| loss/critic2                       | 14.3     |
| timestep                           | 2995000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2884
----------------------------------------------------------------------------------
| alpha                              | 0.149    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 69.4     |
| eval/normalized_episode_reward_std | 24.3     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0147  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.7     |
| timestep                           | 2996000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2960
----------------------------------------------------------------------------------
| alpha                              | 0.148    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 75.5     |
| eval/normalized_episode_reward_std | 11.9     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0238  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 2997000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2935
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 77.4     |
| eval/normalized_episode_reward_std | 11.4     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.00375 |
| loss/critic1                       | 14       |
| loss/critic2                       | 14       |
| timestep                           | 2998000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2833
----------------------------------------------------------------------------------
| alpha                              | 0.147    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 65.7     |
| eval/normalized_episode_reward_std | 26.6     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0282  |
| loss/critic1                       | 14.6     |
| loss/critic2                       | 14.5     |
| timestep                           | 2999000  |
----------------------------------------------------------------------------------
num rollout transitions: 250000, reward mean: 4.2913
----------------------------------------------------------------------------------
| alpha                              | 0.146    |
| eval/episode_length                | 1e+03    |
| eval/episode_length_std            | 0        |
| eval/normalized_episode_reward     | 67.7     |
| eval/normalized_episode_reward_std | 24.7     |
| loss/actor                         | -678     |
| loss/alpha                         | -0.0174  |
| loss/critic1                       | 14.4     |
| loss/critic2                       | 14.3     |
| timestep                           | 3000000  |
----------------------------------------------------------------------------------
total time: 119595.78s
